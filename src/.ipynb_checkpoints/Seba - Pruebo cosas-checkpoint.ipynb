{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#from sklearn.metrics import SCORERS\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "#from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "#from sklearn.datasets import make_classification\n",
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "#from sklearn.neighbors import DistanceMetric\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "#from imblearn.under_sampling import TomekLinks\n",
    "#from imblearn.under_sampling import ClusterCentroids\n",
    "#from imblearn.over_sampling import SMOTE\n",
    "#from imblearn.combine import SMOTETomek\n",
    "\n",
    "#from sklearn import preprocessing\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf = pd.read_csv('featuresMagui.csv')\n",
    "tf_seba = pd.read_csv('features_seba.csv')\n",
    "tf_santi = pd.read_csv('santi_timefeatures.csv')\n",
    "tf_santi_2 = pd.read_csv('Santi_FeaturesConEventos.csv')\n",
    "labels = pd.read_csv('../../data/labels_training_set.csv') #las personas de las cuales tengo Info\n",
    "personas =pd.read_csv('../../data/trocafone_kaggle_test.csv') #las personas a las que le tengo que predecir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datos a entregar\n",
    "santi_seba = pd.merge(tf_santi_2,tf_seba, on = 'person',how = 'inner')\n",
    "datos = pd.merge(personas, santi_seba, on = 'person', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datos para entrenar\n",
    "#labels_f = pd.merge(tf_santi_2,tf_seba, on = 'person',how = 'inner')\n",
    "labels_f = pd.merge(labels, santi_seba, on = 'person', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = labels_f.iloc[:,1:2]\n",
    "X = labels_f.iloc[:,3: 406]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2, random_state= 123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seleccion de features con RFE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando todos los features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "xg_reg = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, scale_pos_weight = 7, min_child_weight=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n =  43\n"
     ]
    }
   ],
   "source": [
    "n = 43\n",
    "rfe = RFE(xg_reg, n)\n",
    "rfe = rfe.fit(X, y['label'].ravel())\n",
    "   \n",
    "print('n = ', n)\n",
    "   \n",
    "# Selecciono los n features para entrenar\n",
    "mask = rfe.get_support()\n",
    "features_X = X.columns[mask]\n",
    "new_x = X.filter(items=features_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC auc score:  0.8626966186972823\n"
     ]
    }
   ],
   "source": [
    "# Entrenamos y predecimos\n",
    "X_train, X_test, y_train, y_test = train_test_split(new_x, y['label'], test_size=0.2, random_state=123)\n",
    "    \n",
    "xg_reg = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, scale_pos_weight = 7, min_child_weight=15)\n",
    "\n",
    "xg_reg.fit(X_train,y_train)\n",
    "proba = xg_reg.predict_proba(X_test)[:,1]\n",
    "print(\"ROC auc score: \", roc_auc_score(y_test, proba))\n",
    "# con tf_santi_2,tf_seba, y n=43 me da 0.8626966186972823 (Filtrando X) ESTE SUBI A KAGGLE Y DIO 0.86148"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Para subir a Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, scale_pos_weight = 7, min_child_weight=15)\n",
    "\n",
    "xg_reg.fit(new_x,y['label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = datos.filter(items= ['person'] + list(features_X))\n",
    "df_final_sin_persons= df_final.drop(columns='person')\n",
    "df_final.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proba = pd.Series(xg_reg.predict_proba(df_final_sin_persons)[:,1])\n",
    "\n",
    "predicciones = df_final[['person']]\n",
    "\n",
    "predicciones['label'] = proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones.to_csv('predicciones_kaggle.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predicciones.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seleccion de features con random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "preds = clf.predict(X_test)\n",
    "preds_prob = clf.predict_proba(X_test)[:,1]\n",
    "train_accuracy = accuracy_score(y_train, clf.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds_prob)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "print('train acurracy: ')\n",
    "print(train_accuracy)\n",
    "print('test acurracy: ')\n",
    "print(test_accuracy)\n",
    "print('Matriz de confusión: ')\n",
    "print(matriz_de_confusion)\n",
    "print('Área bajo la curva: ')\n",
    "print(area_debajo_de_curva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importancia = clf.feature_importances_\n",
    "len(importancia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importancia_con_nombre = {}\n",
    "features = X.columns\n",
    "for i in range(193):\n",
    "    importancia_con_nombre[features[i]] = importancia[i]\n",
    "importancia_con_nombre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atributos_importantes = []\n",
    "for clave in importancia_con_nombre.keys():\n",
    "    if importancia_con_nombre[clave] > 0:\n",
    "        atributos_importantes.append(clave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(atributos_importantes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atributos_importantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_imp = X.filter(items= atributos_importantes)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_imp, y, test_size= 0.2, random_state= 123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pruebo con XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xgboost(X_p, y_p, X_train_p, X_test_p, y_train_p, y_test_p):\n",
    "    xg_reg = xgb.XGBClassifier(learning_rate =0.1, n_estimators=6, max_depth=5, min_child_weight=12,\n",
    "                           colsample_bytree=0.8, objective= 'binary:logistic', scale_pos_weight = 5)\n",
    "    \n",
    "    xg_reg.fit(X_train_p,y_train_p, early_stopping_rounds = 5, eval_set=[(X_test, y_test)])\n",
    "    preds = xg_reg.predict(X_test_p)\n",
    "    preds_prob = xg_reg.predict_proba(X_test_p)[:,1]\n",
    "    train_accuracy = accuracy_score(y_train_p, xg_reg.predict(X_train_p))\n",
    "    test_accuracy = accuracy_score(y_test_p, preds)\n",
    "    area_debajo_de_curva = roc_auc_score(y_test_p, preds_prob)\n",
    "    matriz_de_confusion = confusion_matrix(y_test_p, preds)\n",
    "    print('train acurracy: ')\n",
    "    print(train_accuracy)\n",
    "    print('test acurracy: ')\n",
    "    print(test_accuracy)\n",
    "    print('Matriz de confusión: ')\n",
    "    print(matriz_de_confusion)\n",
    "    print('Área bajo la curva: ')\n",
    "    print(area_debajo_de_curva)\n",
    "    return(xg_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg =xgboost(X_imp, y, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seleccion de features con RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "# The \"accuracy\" scoring is proportional to the number of correct\n",
    "# classifications\n",
    "rfecv = RFECV(estimator=xg_reg, step=1, cv=StratifiedKFold(10),\n",
    "              scoring='roc_auc')\n",
    "rfecv.fit(X, y['label'].ravel())\n",
    "\n",
    "print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecciono los n features para entrenar\n",
    "mask = rfecv.get_support()\n",
    "features_X = X.columns[mask]\n",
    "new_x = X.filter(items=features_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos y predecimos\n",
    "X_train, X_test, y_train, y_test = train_test_split(new_x, y['label'], test_size=0.2, random_state=123)\n",
    "    \n",
    "xg_reg = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, scale_pos_weight = 7, min_child_weight=15)\n",
    "\n",
    "xg_reg.fit(X_train,y_train)\n",
    "proba = xg_reg.predict_proba(X_test)[:,1]\n",
    "print(\"ROC auc score: \", roc_auc_score(y_test, proba))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Con sampleo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kaggle_oversampling(df, cant_unos):\n",
    "   \n",
    "    df_train = pd.merge(df, labels, on=\"person\", how=\"inner\")\\\n",
    "            .drop(columns = ['person'])\n",
    "    \n",
    "    # Separamos la variable a predecir\n",
    "\n",
    "    y = labels_f.iloc[:,1:2]\n",
    "    X = labels_f.iloc[:,3: 406]\n",
    "    \n",
    "    datos = pd.merge(df, personas, on='person', how='inner').filter(items= list(df_train.columns) + ['person'])\n",
    "    df_final_sin_persons = datos.drop(columns='person')\n",
    "     \n",
    "    cant_ceros = np.sum(y == 0)\n",
    "    \n",
    "    ros = RandomOverSampler(random_state=2, sampling_strategy = {0: cant_ceros, 1: cant_unos})\n",
    "    X_res, y_res = ros.fit_sample(X, y)\n",
    "    X_res_df = pd.DataFrame(X_res)\n",
    "    X_res_df.columns = X_test.columns\n",
    "\n",
    "    xg_reg = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, scale_pos_weight = 7, min_child_weight=15)\n",
    "\n",
    "    #Entrenamos\n",
    "\n",
    "    xg_reg.fit(X_res_df, y_res)\n",
    "    \n",
    "    proba = pd.Series(xg_reg.predict_proba(df_final_sin_persons)[:,1])\n",
    "\n",
    "    predicciones = datos[['person']]\n",
    "    predicciones['label'] = proba\n",
    "    predicciones.to_csv('predicciones.csv', encoding='utf-8', index=False)\n",
    "\n",
    "    print(predicciones.shape[0] == 19415)\n",
    "\n",
    "    train_accuracy = accuracy_score(y_res, xg_reg.predict(X_res_df))\n",
    "\n",
    "    print(\"Train accuracy: \", train_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Para subir a Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cant_ceros = np.sum(y == 0)\n",
    "\n",
    "ros = RandomOverSampler(random_state=2, sampling_strategy = {0: 18434, 1: 1191})\n",
    "X_train_res, y_train_res = ros.fit_sample(X_train, y_train.ravel())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "xg_reg.fit(Xr_df, yr['label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = datos.filter(items= ['person'] + list(features_X))\n",
    "df_final_sin_persons= df_final.drop(columns='person')\n",
    "df_final.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preds = xg_reg.predict(X_test)\n",
    "proba = pd.Series(xg_reg.predict_proba(df_final_sin_persons)[:,1])\n",
    "\n",
    "predicciones = df_final[['person']]\n",
    "\n",
    "predicciones['label'] = proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones.to_csv('predicciones_oversamp.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predicciones.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predicciones.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probar_oversampling(df, cant_unos):\n",
    "    \n",
    "    labels_f = pd.merge(labels, df, on = 'person', how = 'inner')\n",
    "    y = labels_f.iloc[:,1:2]\n",
    "    X = labels_f.iloc[:,3: 406]\n",
    "    \n",
    "    xg_reg = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, scale_pos_weight = 7, min_child_weight=15)\n",
    "    n = 22\n",
    "    rfe = RFE(xg_reg, n)\n",
    "    rfe = rfe.fit(X, y['label'].ravel())\n",
    "   \n",
    "    print('n = ', n)\n",
    "   \n",
    "    # Selecciono los n features para entrenar\n",
    "    mask = rfe.get_support()\n",
    "    features_X = X.columns[mask]\n",
    "    new_x = X.filter(items=features_X)\n",
    "    \n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(new_x, y, test_size=0.2, random_state=123)\n",
    "    \n",
    "    cant_ceros = np.sum(y_train == 0)\n",
    "    \n",
    "    ros = RandomOverSampler(random_state=2, sampling_strategy = {0: cant_ceros, 1: cant_unos})\n",
    "    X_train_res, y_train_res = ros.fit_sample(X_train, y_train)\n",
    "    X_train_res_df = pd.DataFrame(X_train_res)\n",
    "    X_train_res_df.columns = X_test.columns\n",
    "\n",
    "\n",
    "    xg_reg.fit(X_train_res_df, y_train_res)\n",
    "\n",
    "    preds = xg_reg.predict(X_test)\n",
    "    proba = xg_reg.predict_proba(X_test)[:,1]\n",
    "    \n",
    "    train_accuracy = accuracy_score(y_train_res, xg_reg.predict(X_train_res_df))\n",
    "    test_accuracy = accuracy_score(y_test, preds)\n",
    "    matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "    area_debajo_de_curva = roc_auc_score(y_test, proba)\n",
    "\n",
    "    print(\"Train accuracy: \", train_accuracy)\n",
    "    print(\"Test acuracy: \", test_accuracy)\n",
    "    print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "    print(\"Confusion matrix: \")\n",
    "    print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### iterando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Con el seba_features.csv\n",
    "for n in range(40,100,5):\n",
    "    # create the RFE model and select n attributes\n",
    "    rfe = RFE(xg_reg, n)\n",
    "    rfe = rfe.fit(X, y['label'].ravel())\n",
    "    \n",
    "    print('n = ', n)\n",
    "    \n",
    "    # Selecciono los n features para entrenar\n",
    "    mask = rfe.get_support()\n",
    "    features_X = X.columns[mask]\n",
    "    new_x = X.filter(items=features_X)\n",
    "    \n",
    "    # Entrenamos y predecimos\n",
    "    X_train, X_test, y_train, y_test = train_test_split(new_x, y['label'], test_size=0.2, random_state=123)\n",
    "    \n",
    "    xg_reg = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, scale_pos_weight = 7, min_child_weight=15)\n",
    "\n",
    "    xg_reg.fit(X_train,y_train)\n",
    "    proba = xg_reg.predict_proba(X_test)[:,1]\n",
    "    print(\"ROC auc score: \", roc_auc_score(y_test, proba))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Con el seba_features.csv\n",
    "for n in range(85,90,1):\n",
    "    # create the RFE model and select n attributes\n",
    "    rfe = RFE(xg_reg, n)\n",
    "    rfe = rfe.fit(X, y['label'].ravel())\n",
    "    \n",
    "    print('n = ', n)\n",
    "    \n",
    "    # Selecciono los n features para entrenar\n",
    "    mask = rfe.get_support()\n",
    "    features_X = X.columns[mask]\n",
    "    new_x = X.filter(items=features_X)\n",
    "    \n",
    "    # Entrenamos y predecimos\n",
    "    X_train, X_test, y_train, y_test = train_test_split(new_x, y['label'], test_size=0.2, random_state=123)\n",
    "    \n",
    "    xg_reg = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, scale_pos_weight = 7, min_child_weight=15)\n",
    "\n",
    "    xg_reg.fit(X_train,y_train)\n",
    "    proba = xg_reg.predict_proba(X_test)[:,1]\n",
    "    print(\"ROC auc score: \", roc_auc_score(y_test, proba))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funciones CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, cross_val_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratifiedCVConRFE(data, n):\n",
    "    \n",
    "    df_train = pd.merge(data, labels,how = 'inner', on ='person')\n",
    "    df_train.drop(columns = ['person'],inplace = True)\n",
    "    \n",
    "    X = df_train.drop(columns = ['label'])\n",
    "    y = df_train['label']\n",
    "    \n",
    "    model = xgb.XGBRegressor(objective ='binary:logistic', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, scale_pos_weight = 7, min_child_weight=15)\n",
    "    \n",
    "    stratifiedKFold = StratifiedKFold(n_splits = 10, random_state = 7)\n",
    "    \n",
    "    #n = 22\n",
    "    rfe = RFE(model, n)\n",
    "    rfe = rfe.fit(X, y.ravel())\n",
    "\n",
    "    # Selecciono los n features para entrenar\n",
    "    mask = rfe.get_support()\n",
    "    features_X = X.columns[mask]\n",
    "    X = X.filter(items = features_X)\n",
    "    \n",
    "    results = cross_val_score(model, X, y, cv = stratifiedKFold, scoring = 'roc_auc')\n",
    "        \n",
    "    print(\"ROC AUC: \",results.mean())\n",
    "    return results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stratifiedCV(data):\n",
    "    \n",
    "    df_train = pd.merge(data,df_labels,how = 'inner', on ='person')\n",
    "    df_train.drop(columns = ['person'],inplace = True)\n",
    "    \n",
    "    X = df_train.drop(columns = ['label'])\n",
    "    y = df_train['label']\n",
    "    \n",
    "    model = xgb.XGBRegressor(objective ='binary:logistic', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, scale_pos_weight = 7, min_child_weight=15)\n",
    "    \n",
    "    stratifiedKFold = StratifiedKFold(n_splits = 10, random_state = 7)\n",
    "    \n",
    "    results = cross_val_score(model, X, y, cv = stratifiedKFold, scoring = 'roc_auc')\n",
    "    #results2 = cross_val_predict(model, X, y, cv = stratifiedKFold, method='predict_proba')\n",
    "    \n",
    "    print(\"ROC AUC: \",results.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratifiedCVConRFE(santi_seba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n= 43 da 0.8557534566892058\n",
    "stratifiedCVConRFE(santi_seba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterando con CV y RFE para obtener el mas optimo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestK = 0\n",
    "score = 0\n",
    "for i in range(17,193):\n",
    "    score_act = stratifiedCVConRFE(santi_seba, i)\n",
    "    if(score_act > score):\n",
    "        score = score_act\n",
    "        bestK = i\n",
    "        print(bestK)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando los features ''importantes'' del random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 43\n",
    "rfe = RFE(xg_reg, n)\n",
    "rfe = rfe.fit(X_imp, y['label'].ravel())\n",
    "   \n",
    "print('n = ', n)\n",
    "   \n",
    "# Selecciono los n features para entrenar\n",
    "mask = rfe.get_support()\n",
    "features_X = X_imp.columns[mask]\n",
    "new_x = X_imp.filter(items=features_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamos y predecimos\n",
    "X_train, X_test, y_train, y_test = train_test_split(new_x, y['label'], test_size=0.2, random_state=123)\n",
    "    \n",
    "xg_reg = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, scale_pos_weight = 7, min_child_weight=15)\n",
    "\n",
    "xg_reg.fit(X_train,y_train)\n",
    "proba = xg_reg.predict_proba(X_test)[:,1]\n",
    "print(\"ROC auc score: \", roc_auc_score(y_test, proba))\n",
    "# con tf_santi_2,tf_seba, y n=43 me da 0.8670756921715554 (con X_imp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Para subir a Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, scale_pos_weight = 7, min_child_weight=15)\n",
    "\n",
    "xg_reg.fit(new_x,y['label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = datos.filter(items= ['person'] + list(features_X))\n",
    "df_final_sin_persons= df_final.drop(columns='person')\n",
    "df_final.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preds = xg_reg.predict(X_test)\n",
    "proba = pd.Series(xg_reg.predict_proba(df_final_sin_persons)[:,1])\n",
    "\n",
    "predicciones = df_final[['person']]\n",
    "\n",
    "predicciones['label'] = proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones.to_csv('predicciones_p5.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predicciones.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Para subir a kaggle con los features 'importantes' de rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, scale_pos_weight = 7, min_child_weight=15)\n",
    "\n",
    "xg_reg.fit(new_x,y['label'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = datos.filter(items= ['person'] + list(features_X))\n",
    "df_final_sin_persons= df_final.drop(columns='person')\n",
    "df_final.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preds = xg_reg.predict(X_test)\n",
    "proba = pd.Series(xg_reg.predict_proba(df_final_sin_persons)[:,1])\n",
    "\n",
    "predicciones = df_final[['person']]\n",
    "\n",
    "predicciones['label'] = proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicciones.to_csv('predicciones_p3.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predicciones.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
