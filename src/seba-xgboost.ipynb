{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt \n",
    "from datetime import timedelta\n",
    "%matplotlib inline\n",
    "\n",
    "#from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seba\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3020: DtypeWarning: Columns (3,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "labels = pd.read_csv(\"../../data/labels_training_set.csv\")\n",
    "df = pd.read_csv(\"../../data/events_up_to_01062018.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_persons = pd.read_csv(\"../../data/trocafone_kaggle_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
    "df[\"month\"] = df[\"timestamp\"].dt.month\n",
    "df[\"day\"] = df[\"timestamp\"].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "todas_las_personas = df[[\"person\"]].drop_duplicates(subset=\"person\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df[\"event\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebo tsfresh.. no mirar por ahora esta parte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tsfresh import extract_relevant_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_para_probar = pd.merge(df, labels, on=\"person\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Feature Extraction:   0%|                                                                       | 0/10 [00:00<?, ?it/s]\n",
      "\n",
      "Feature Extraction:  10%|██████▏                                                       | 1/10 [05:08<46:12, 308.10s/it]\n",
      "\n",
      "Feature Extraction:  20%|████████████▍                                                 | 2/10 [05:50<30:26, 228.35s/it]\n",
      "\n",
      "Feature Extraction:  30%|██████████████████▌                                           | 3/10 [10:17<27:59, 239.88s/it]\n",
      "\n",
      "Feature Extraction:  40%|████████████████████████▊                                     | 4/10 [11:18<18:37, 186.21s/it]\n",
      "\n",
      "Feature Extraction:  50%|███████████████████████████████                               | 5/10 [15:33<17:14, 206.84s/it]\n",
      "\n",
      "Feature Extraction:  60%|█████████████████████████████████████▏                        | 6/10 [16:07<10:20, 155.12s/it]\n",
      "\n",
      "Feature Extraction:  70%|███████████████████████████████████████████▍                  | 7/10 [20:56<09:45, 195.33s/it]\n",
      "\n",
      "Feature Extraction:  80%|█████████████████████████████████████████████████▌            | 8/10 [21:29<04:52, 146.44s/it]\n",
      "\n",
      "Feature Extraction:  90%|███████████████████████████████████████████████████████▊      | 9/10 [25:51<03:01, 181.18s/it]\n",
      "\n",
      "Feature Extraction: 100%|█████████████████████████████████████████████████████████████| 10/10 [27:02<00:00, 148.33s/it]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tsfresh import extract_features\n",
    "from tsfresh import select_features\n",
    "from tsfresh.utilities.dataframe_functions import impute\n",
    "\n",
    "extracted_features = extract_features(df_para_probar, column_id=\"person\", column_sort=\"timestamp\", column_value=\"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>variable</th>\n",
       "      <th>label__abs_energy</th>\n",
       "      <th>label__absolute_sum_of_changes</th>\n",
       "      <th>label__agg_autocorrelation__f_agg_\"mean\"</th>\n",
       "      <th>label__agg_autocorrelation__f_agg_\"median\"</th>\n",
       "      <th>label__agg_autocorrelation__f_agg_\"var\"</th>\n",
       "      <th>label__agg_linear_trend__f_agg_\"max\"__chunk_len_10__attr_\"intercept\"</th>\n",
       "      <th>label__agg_linear_trend__f_agg_\"max\"__chunk_len_10__attr_\"rvalue\"</th>\n",
       "      <th>label__agg_linear_trend__f_agg_\"max\"__chunk_len_10__attr_\"slope\"</th>\n",
       "      <th>label__agg_linear_trend__f_agg_\"max\"__chunk_len_10__attr_\"stderr\"</th>\n",
       "      <th>label__agg_linear_trend__f_agg_\"max\"__chunk_len_50__attr_\"intercept\"</th>\n",
       "      <th>...</th>\n",
       "      <th>label__time_reversal_asymmetry_statistic__lag_1</th>\n",
       "      <th>label__time_reversal_asymmetry_statistic__lag_2</th>\n",
       "      <th>label__time_reversal_asymmetry_statistic__lag_3</th>\n",
       "      <th>label__value_count__value_-inf</th>\n",
       "      <th>label__value_count__value_0</th>\n",
       "      <th>label__value_count__value_1</th>\n",
       "      <th>label__value_count__value_inf</th>\n",
       "      <th>label__value_count__value_nan</th>\n",
       "      <th>label__variance</th>\n",
       "      <th>label__variance_larger_than_standard_deviation</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0008ed71</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000c79fe</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>001802e4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0019e639</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>471.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>001b0bf9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 794 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "variable  label__abs_energy  label__absolute_sum_of_changes  \\\n",
       "id                                                            \n",
       "0008ed71                0.0                             0.0   \n",
       "000c79fe                0.0                             0.0   \n",
       "001802e4                0.0                             0.0   \n",
       "0019e639                0.0                             0.0   \n",
       "001b0bf9                0.0                             0.0   \n",
       "\n",
       "variable  label__agg_autocorrelation__f_agg_\"mean\"  \\\n",
       "id                                                   \n",
       "0008ed71                                       0.0   \n",
       "000c79fe                                       0.0   \n",
       "001802e4                                       0.0   \n",
       "0019e639                                       0.0   \n",
       "001b0bf9                                       0.0   \n",
       "\n",
       "variable  label__agg_autocorrelation__f_agg_\"median\"  \\\n",
       "id                                                     \n",
       "0008ed71                                         0.0   \n",
       "000c79fe                                         0.0   \n",
       "001802e4                                         0.0   \n",
       "0019e639                                         0.0   \n",
       "001b0bf9                                         0.0   \n",
       "\n",
       "variable  label__agg_autocorrelation__f_agg_\"var\"  \\\n",
       "id                                                  \n",
       "0008ed71                                      0.0   \n",
       "000c79fe                                      0.0   \n",
       "001802e4                                      0.0   \n",
       "0019e639                                      0.0   \n",
       "001b0bf9                                      0.0   \n",
       "\n",
       "variable  label__agg_linear_trend__f_agg_\"max\"__chunk_len_10__attr_\"intercept\"  \\\n",
       "id                                                                               \n",
       "0008ed71                                                0.0                      \n",
       "000c79fe                                                0.0                      \n",
       "001802e4                                                0.0                      \n",
       "0019e639                                                0.0                      \n",
       "001b0bf9                                                0.0                      \n",
       "\n",
       "variable  label__agg_linear_trend__f_agg_\"max\"__chunk_len_10__attr_\"rvalue\"  \\\n",
       "id                                                                            \n",
       "0008ed71                                                0.0                   \n",
       "000c79fe                                                0.0                   \n",
       "001802e4                                                0.0                   \n",
       "0019e639                                                0.0                   \n",
       "001b0bf9                                                0.0                   \n",
       "\n",
       "variable  label__agg_linear_trend__f_agg_\"max\"__chunk_len_10__attr_\"slope\"  \\\n",
       "id                                                                           \n",
       "0008ed71                                                0.0                  \n",
       "000c79fe                                                0.0                  \n",
       "001802e4                                                0.0                  \n",
       "0019e639                                                0.0                  \n",
       "001b0bf9                                                0.0                  \n",
       "\n",
       "variable  label__agg_linear_trend__f_agg_\"max\"__chunk_len_10__attr_\"stderr\"  \\\n",
       "id                                                                            \n",
       "0008ed71                                                0.0                   \n",
       "000c79fe                                                0.0                   \n",
       "001802e4                                                0.0                   \n",
       "0019e639                                                0.0                   \n",
       "001b0bf9                                                0.0                   \n",
       "\n",
       "variable  label__agg_linear_trend__f_agg_\"max\"__chunk_len_50__attr_\"intercept\"  \\\n",
       "id                                                                               \n",
       "0008ed71                                                0.0                      \n",
       "000c79fe                                                0.0                      \n",
       "001802e4                                                0.0                      \n",
       "0019e639                                                0.0                      \n",
       "001b0bf9                                                0.0                      \n",
       "\n",
       "variable                       ...                        \\\n",
       "id                             ...                         \n",
       "0008ed71                       ...                         \n",
       "000c79fe                       ...                         \n",
       "001802e4                       ...                         \n",
       "0019e639                       ...                         \n",
       "001b0bf9                       ...                         \n",
       "\n",
       "variable  label__time_reversal_asymmetry_statistic__lag_1  \\\n",
       "id                                                          \n",
       "0008ed71                                              0.0   \n",
       "000c79fe                                              0.0   \n",
       "001802e4                                              0.0   \n",
       "0019e639                                              0.0   \n",
       "001b0bf9                                              0.0   \n",
       "\n",
       "variable  label__time_reversal_asymmetry_statistic__lag_2  \\\n",
       "id                                                          \n",
       "0008ed71                                              0.0   \n",
       "000c79fe                                              0.0   \n",
       "001802e4                                              0.0   \n",
       "0019e639                                              0.0   \n",
       "001b0bf9                                              0.0   \n",
       "\n",
       "variable  label__time_reversal_asymmetry_statistic__lag_3  \\\n",
       "id                                                          \n",
       "0008ed71                                              0.0   \n",
       "000c79fe                                              0.0   \n",
       "001802e4                                              0.0   \n",
       "0019e639                                              0.0   \n",
       "001b0bf9                                              0.0   \n",
       "\n",
       "variable  label__value_count__value_-inf  label__value_count__value_0  \\\n",
       "id                                                                      \n",
       "0008ed71                             0.0                          6.0   \n",
       "000c79fe                             0.0                         17.0   \n",
       "001802e4                             0.0                         19.0   \n",
       "0019e639                             0.0                        471.0   \n",
       "001b0bf9                             0.0                          7.0   \n",
       "\n",
       "variable  label__value_count__value_1  label__value_count__value_inf  \\\n",
       "id                                                                     \n",
       "0008ed71                          0.0                            0.0   \n",
       "000c79fe                          0.0                            0.0   \n",
       "001802e4                          0.0                            0.0   \n",
       "0019e639                          0.0                            0.0   \n",
       "001b0bf9                          0.0                            0.0   \n",
       "\n",
       "variable  label__value_count__value_nan  label__variance  \\\n",
       "id                                                         \n",
       "0008ed71                            0.0              0.0   \n",
       "000c79fe                            0.0              0.0   \n",
       "001802e4                            0.0              0.0   \n",
       "0019e639                            0.0              0.0   \n",
       "001b0bf9                            0.0              0.0   \n",
       "\n",
       "variable  label__variance_larger_than_standard_deviation  \n",
       "id                                                        \n",
       "0008ed71                                             0.0  \n",
       "000c79fe                                             0.0  \n",
       "001802e4                                             0.0  \n",
       "0019e639                                             0.0  \n",
       "001b0bf9                                             0.0  \n",
       "\n",
       "[5 rows x 794 columns]"
      ]
     },
     "execution_count": 512,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "person\n",
       "0566e9c1    0\n",
       "6ec7ee77    0\n",
       "abe7a2fb    0\n",
       "34728364    0\n",
       "87ed62de    0\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = labels.set_index(\"person\")[\"label\"]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tsfresh.feature_selection.relevance:Infered classification as machine learning task\n"
     ]
    }
   ],
   "source": [
    "impute(extracted_features)\n",
    "features_filtered = select_features(extracted_features, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>variable</th>\n",
       "      <th>label__abs_energy</th>\n",
       "      <th>label__fft_coefficient__coeff_4__attr_\"real\"</th>\n",
       "      <th>label__fft_coefficient__coeff_50__attr_\"abs\"</th>\n",
       "      <th>label__fft_coefficient__coeff_51__attr_\"abs\"</th>\n",
       "      <th>label__quantile__q_0.9</th>\n",
       "      <th>label__fft_coefficient__coeff_52__attr_\"abs\"</th>\n",
       "      <th>label__fft_coefficient__coeff_53__attr_\"abs\"</th>\n",
       "      <th>label__fft_coefficient__coeff_54__attr_\"abs\"</th>\n",
       "      <th>label__fft_coefficient__coeff_55__attr_\"abs\"</th>\n",
       "      <th>label__fft_coefficient__coeff_56__attr_\"abs\"</th>\n",
       "      <th>...</th>\n",
       "      <th>label__percentage_of_reoccurring_values_to_all_values</th>\n",
       "      <th>label__fft_coefficient__coeff_45__attr_\"angle\"</th>\n",
       "      <th>label__fft_coefficient__coeff_66__attr_\"angle\"</th>\n",
       "      <th>label__fft_coefficient__coeff_85__attr_\"imag\"</th>\n",
       "      <th>label__fft_coefficient__coeff_71__attr_\"angle\"</th>\n",
       "      <th>label__fft_coefficient__coeff_92__attr_\"imag\"</th>\n",
       "      <th>label__fft_coefficient__coeff_53__attr_\"imag\"</th>\n",
       "      <th>label__fft_coefficient__coeff_58__attr_\"imag\"</th>\n",
       "      <th>label__fft_coefficient__coeff_89__attr_\"angle\"</th>\n",
       "      <th>label__fft_coefficient__coeff_69__attr_\"imag\"</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0008ed71</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000c79fe</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>001802e4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0019e639</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>001b0bf9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>001ca5ee</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>001dfc31</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>001e9aea</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0020152e</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>002b0188</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>002e74b2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00317e49</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0031c75f</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>003476c0</th>\n",
       "      <td>43.0</td>\n",
       "      <td>-2.220446e-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>003847fc</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>003a7d49</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>003bdb4d</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>003d4cac</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>003dd965</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0042421c</th>\n",
       "      <td>22.0</td>\n",
       "      <td>6.285705e-16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>004b8d91</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>004ed8ba</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0050d971</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00546e55</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00665dda</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>006671fd</th>\n",
       "      <td>18.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00702e02</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00736d10</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>007537e8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>007ddac1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ff8a9723</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ff8af29b</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ff906750</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ff97d56f</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ff97e281</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ff9a58dd</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ff9b9954</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ff9da79b</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffa9ac98</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffae1445</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffaf0844</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffb598de</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffc51f07</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffc670b3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffcaae19</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffcaeaae</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffd9756a</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffde3628</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffe066cc</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffe7e848</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffeb80c5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffebdbc9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffecdf29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffed0342</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffed3d0e</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffee0f18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffef83e6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fff1659c</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fff2bdde</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fff78145</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19414 rows × 484 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "variable  label__abs_energy  label__fft_coefficient__coeff_4__attr_\"real\"  \\\n",
       "id                                                                          \n",
       "0008ed71                0.0                                  0.000000e+00   \n",
       "000c79fe                0.0                                  0.000000e+00   \n",
       "001802e4                0.0                                  0.000000e+00   \n",
       "0019e639                0.0                                  0.000000e+00   \n",
       "001b0bf9                0.0                                  0.000000e+00   \n",
       "001ca5ee                0.0                                  0.000000e+00   \n",
       "001dfc31                0.0                                  0.000000e+00   \n",
       "001e9aea                0.0                                  0.000000e+00   \n",
       "0020152e                0.0                                  0.000000e+00   \n",
       "002b0188                0.0                                  0.000000e+00   \n",
       "002e74b2                0.0                                  0.000000e+00   \n",
       "00317e49                0.0                                  0.000000e+00   \n",
       "0031c75f                0.0                                  0.000000e+00   \n",
       "003476c0               43.0                                 -2.220446e-16   \n",
       "003847fc                0.0                                  0.000000e+00   \n",
       "003a7d49                0.0                                  0.000000e+00   \n",
       "003bdb4d                0.0                                  0.000000e+00   \n",
       "003d4cac                8.0                                  0.000000e+00   \n",
       "003dd965                5.0                                  0.000000e+00   \n",
       "0042421c               22.0                                  6.285705e-16   \n",
       "004b8d91                0.0                                  0.000000e+00   \n",
       "004ed8ba                0.0                                  0.000000e+00   \n",
       "0050d971                0.0                                  0.000000e+00   \n",
       "00546e55                0.0                                  0.000000e+00   \n",
       "00665dda                0.0                                  0.000000e+00   \n",
       "006671fd               18.0                                  0.000000e+00   \n",
       "00702e02                0.0                                  0.000000e+00   \n",
       "00736d10                0.0                                  0.000000e+00   \n",
       "007537e8                0.0                                  0.000000e+00   \n",
       "007ddac1                0.0                                  0.000000e+00   \n",
       "...                     ...                                           ...   \n",
       "ff8a9723                0.0                                  0.000000e+00   \n",
       "ff8af29b                0.0                                  0.000000e+00   \n",
       "ff906750                0.0                                  0.000000e+00   \n",
       "ff97d56f                0.0                                  0.000000e+00   \n",
       "ff97e281                0.0                                  0.000000e+00   \n",
       "ff9a58dd                0.0                                  0.000000e+00   \n",
       "ff9b9954                0.0                                  0.000000e+00   \n",
       "ff9da79b                0.0                                  0.000000e+00   \n",
       "ffa9ac98                0.0                                  0.000000e+00   \n",
       "ffae1445                0.0                                  0.000000e+00   \n",
       "ffaf0844                0.0                                  0.000000e+00   \n",
       "ffb598de                0.0                                  0.000000e+00   \n",
       "ffc51f07                0.0                                  0.000000e+00   \n",
       "ffc670b3                0.0                                  0.000000e+00   \n",
       "ffcaae19                0.0                                  0.000000e+00   \n",
       "ffcaeaae                0.0                                  0.000000e+00   \n",
       "ffd9756a                0.0                                  0.000000e+00   \n",
       "ffde3628                0.0                                  0.000000e+00   \n",
       "ffe066cc                0.0                                  0.000000e+00   \n",
       "ffe7e848                0.0                                  0.000000e+00   \n",
       "ffeb80c5                0.0                                  0.000000e+00   \n",
       "ffebdbc9                0.0                                  0.000000e+00   \n",
       "ffecdf29                0.0                                  0.000000e+00   \n",
       "ffed0342                0.0                                  0.000000e+00   \n",
       "ffed3d0e                0.0                                  0.000000e+00   \n",
       "ffee0f18                0.0                                  0.000000e+00   \n",
       "ffef83e6                0.0                                  0.000000e+00   \n",
       "fff1659c                0.0                                  0.000000e+00   \n",
       "fff2bdde                0.0                                  0.000000e+00   \n",
       "fff78145                0.0                                  0.000000e+00   \n",
       "\n",
       "variable  label__fft_coefficient__coeff_50__attr_\"abs\"  \\\n",
       "id                                                       \n",
       "0008ed71                                           0.0   \n",
       "000c79fe                                           0.0   \n",
       "001802e4                                           0.0   \n",
       "0019e639                                           0.0   \n",
       "001b0bf9                                           0.0   \n",
       "001ca5ee                                           0.0   \n",
       "001dfc31                                           0.0   \n",
       "001e9aea                                           0.0   \n",
       "0020152e                                           0.0   \n",
       "002b0188                                           0.0   \n",
       "002e74b2                                           0.0   \n",
       "00317e49                                           0.0   \n",
       "0031c75f                                           0.0   \n",
       "003476c0                                           0.0   \n",
       "003847fc                                           0.0   \n",
       "003a7d49                                           0.0   \n",
       "003bdb4d                                           0.0   \n",
       "003d4cac                                           0.0   \n",
       "003dd965                                           0.0   \n",
       "0042421c                                           0.0   \n",
       "004b8d91                                           0.0   \n",
       "004ed8ba                                           0.0   \n",
       "0050d971                                           0.0   \n",
       "00546e55                                           0.0   \n",
       "00665dda                                           0.0   \n",
       "006671fd                                           0.0   \n",
       "00702e02                                           0.0   \n",
       "00736d10                                           0.0   \n",
       "007537e8                                           0.0   \n",
       "007ddac1                                           0.0   \n",
       "...                                                ...   \n",
       "ff8a9723                                           0.0   \n",
       "ff8af29b                                           0.0   \n",
       "ff906750                                           0.0   \n",
       "ff97d56f                                           0.0   \n",
       "ff97e281                                           0.0   \n",
       "ff9a58dd                                           0.0   \n",
       "ff9b9954                                           0.0   \n",
       "ff9da79b                                           0.0   \n",
       "ffa9ac98                                           0.0   \n",
       "ffae1445                                           0.0   \n",
       "ffaf0844                                           0.0   \n",
       "ffb598de                                           0.0   \n",
       "ffc51f07                                           0.0   \n",
       "ffc670b3                                           0.0   \n",
       "ffcaae19                                           0.0   \n",
       "ffcaeaae                                           0.0   \n",
       "ffd9756a                                           0.0   \n",
       "ffde3628                                           0.0   \n",
       "ffe066cc                                           0.0   \n",
       "ffe7e848                                           0.0   \n",
       "ffeb80c5                                           0.0   \n",
       "ffebdbc9                                           0.0   \n",
       "ffecdf29                                           0.0   \n",
       "ffed0342                                           0.0   \n",
       "ffed3d0e                                           0.0   \n",
       "ffee0f18                                           0.0   \n",
       "ffef83e6                                           0.0   \n",
       "fff1659c                                           0.0   \n",
       "fff2bdde                                           0.0   \n",
       "fff78145                                           0.0   \n",
       "\n",
       "variable  label__fft_coefficient__coeff_51__attr_\"abs\"  \\\n",
       "id                                                       \n",
       "0008ed71                                           0.0   \n",
       "000c79fe                                           0.0   \n",
       "001802e4                                           0.0   \n",
       "0019e639                                           0.0   \n",
       "001b0bf9                                           0.0   \n",
       "001ca5ee                                           0.0   \n",
       "001dfc31                                           0.0   \n",
       "001e9aea                                           0.0   \n",
       "0020152e                                           0.0   \n",
       "002b0188                                           0.0   \n",
       "002e74b2                                           0.0   \n",
       "00317e49                                           0.0   \n",
       "0031c75f                                           0.0   \n",
       "003476c0                                           0.0   \n",
       "003847fc                                           0.0   \n",
       "003a7d49                                           0.0   \n",
       "003bdb4d                                           0.0   \n",
       "003d4cac                                           0.0   \n",
       "003dd965                                           0.0   \n",
       "0042421c                                           0.0   \n",
       "004b8d91                                           0.0   \n",
       "004ed8ba                                           0.0   \n",
       "0050d971                                           0.0   \n",
       "00546e55                                           0.0   \n",
       "00665dda                                           0.0   \n",
       "006671fd                                           0.0   \n",
       "00702e02                                           0.0   \n",
       "00736d10                                           0.0   \n",
       "007537e8                                           0.0   \n",
       "007ddac1                                           0.0   \n",
       "...                                                ...   \n",
       "ff8a9723                                           0.0   \n",
       "ff8af29b                                           0.0   \n",
       "ff906750                                           0.0   \n",
       "ff97d56f                                           0.0   \n",
       "ff97e281                                           0.0   \n",
       "ff9a58dd                                           0.0   \n",
       "ff9b9954                                           0.0   \n",
       "ff9da79b                                           0.0   \n",
       "ffa9ac98                                           0.0   \n",
       "ffae1445                                           0.0   \n",
       "ffaf0844                                           0.0   \n",
       "ffb598de                                           0.0   \n",
       "ffc51f07                                           0.0   \n",
       "ffc670b3                                           0.0   \n",
       "ffcaae19                                           0.0   \n",
       "ffcaeaae                                           0.0   \n",
       "ffd9756a                                           0.0   \n",
       "ffde3628                                           0.0   \n",
       "ffe066cc                                           0.0   \n",
       "ffe7e848                                           0.0   \n",
       "ffeb80c5                                           0.0   \n",
       "ffebdbc9                                           0.0   \n",
       "ffecdf29                                           0.0   \n",
       "ffed0342                                           0.0   \n",
       "ffed3d0e                                           0.0   \n",
       "ffee0f18                                           0.0   \n",
       "ffef83e6                                           0.0   \n",
       "fff1659c                                           0.0   \n",
       "fff2bdde                                           0.0   \n",
       "fff78145                                           0.0   \n",
       "\n",
       "variable  label__quantile__q_0.9  \\\n",
       "id                                 \n",
       "0008ed71                     0.0   \n",
       "000c79fe                     0.0   \n",
       "001802e4                     0.0   \n",
       "0019e639                     0.0   \n",
       "001b0bf9                     0.0   \n",
       "001ca5ee                     0.0   \n",
       "001dfc31                     0.0   \n",
       "001e9aea                     0.0   \n",
       "0020152e                     0.0   \n",
       "002b0188                     0.0   \n",
       "002e74b2                     0.0   \n",
       "00317e49                     0.0   \n",
       "0031c75f                     0.0   \n",
       "003476c0                     1.0   \n",
       "003847fc                     0.0   \n",
       "003a7d49                     0.0   \n",
       "003bdb4d                     0.0   \n",
       "003d4cac                     1.0   \n",
       "003dd965                     1.0   \n",
       "0042421c                     1.0   \n",
       "004b8d91                     0.0   \n",
       "004ed8ba                     0.0   \n",
       "0050d971                     0.0   \n",
       "00546e55                     0.0   \n",
       "00665dda                     0.0   \n",
       "006671fd                     1.0   \n",
       "00702e02                     0.0   \n",
       "00736d10                     0.0   \n",
       "007537e8                     0.0   \n",
       "007ddac1                     0.0   \n",
       "...                          ...   \n",
       "ff8a9723                     0.0   \n",
       "ff8af29b                     0.0   \n",
       "ff906750                     0.0   \n",
       "ff97d56f                     0.0   \n",
       "ff97e281                     0.0   \n",
       "ff9a58dd                     0.0   \n",
       "ff9b9954                     0.0   \n",
       "ff9da79b                     0.0   \n",
       "ffa9ac98                     0.0   \n",
       "ffae1445                     0.0   \n",
       "ffaf0844                     0.0   \n",
       "ffb598de                     0.0   \n",
       "ffc51f07                     0.0   \n",
       "ffc670b3                     0.0   \n",
       "ffcaae19                     0.0   \n",
       "ffcaeaae                     0.0   \n",
       "ffd9756a                     0.0   \n",
       "ffde3628                     0.0   \n",
       "ffe066cc                     0.0   \n",
       "ffe7e848                     0.0   \n",
       "ffeb80c5                     0.0   \n",
       "ffebdbc9                     0.0   \n",
       "ffecdf29                     0.0   \n",
       "ffed0342                     0.0   \n",
       "ffed3d0e                     0.0   \n",
       "ffee0f18                     0.0   \n",
       "ffef83e6                     0.0   \n",
       "fff1659c                     0.0   \n",
       "fff2bdde                     0.0   \n",
       "fff78145                     0.0   \n",
       "\n",
       "variable  label__fft_coefficient__coeff_52__attr_\"abs\"  \\\n",
       "id                                                       \n",
       "0008ed71                                           0.0   \n",
       "000c79fe                                           0.0   \n",
       "001802e4                                           0.0   \n",
       "0019e639                                           0.0   \n",
       "001b0bf9                                           0.0   \n",
       "001ca5ee                                           0.0   \n",
       "001dfc31                                           0.0   \n",
       "001e9aea                                           0.0   \n",
       "0020152e                                           0.0   \n",
       "002b0188                                           0.0   \n",
       "002e74b2                                           0.0   \n",
       "00317e49                                           0.0   \n",
       "0031c75f                                           0.0   \n",
       "003476c0                                           0.0   \n",
       "003847fc                                           0.0   \n",
       "003a7d49                                           0.0   \n",
       "003bdb4d                                           0.0   \n",
       "003d4cac                                           0.0   \n",
       "003dd965                                           0.0   \n",
       "0042421c                                           0.0   \n",
       "004b8d91                                           0.0   \n",
       "004ed8ba                                           0.0   \n",
       "0050d971                                           0.0   \n",
       "00546e55                                           0.0   \n",
       "00665dda                                           0.0   \n",
       "006671fd                                           0.0   \n",
       "00702e02                                           0.0   \n",
       "00736d10                                           0.0   \n",
       "007537e8                                           0.0   \n",
       "007ddac1                                           0.0   \n",
       "...                                                ...   \n",
       "ff8a9723                                           0.0   \n",
       "ff8af29b                                           0.0   \n",
       "ff906750                                           0.0   \n",
       "ff97d56f                                           0.0   \n",
       "ff97e281                                           0.0   \n",
       "ff9a58dd                                           0.0   \n",
       "ff9b9954                                           0.0   \n",
       "ff9da79b                                           0.0   \n",
       "ffa9ac98                                           0.0   \n",
       "ffae1445                                           0.0   \n",
       "ffaf0844                                           0.0   \n",
       "ffb598de                                           0.0   \n",
       "ffc51f07                                           0.0   \n",
       "ffc670b3                                           0.0   \n",
       "ffcaae19                                           0.0   \n",
       "ffcaeaae                                           0.0   \n",
       "ffd9756a                                           0.0   \n",
       "ffde3628                                           0.0   \n",
       "ffe066cc                                           0.0   \n",
       "ffe7e848                                           0.0   \n",
       "ffeb80c5                                           0.0   \n",
       "ffebdbc9                                           0.0   \n",
       "ffecdf29                                           0.0   \n",
       "ffed0342                                           0.0   \n",
       "ffed3d0e                                           0.0   \n",
       "ffee0f18                                           0.0   \n",
       "ffef83e6                                           0.0   \n",
       "fff1659c                                           0.0   \n",
       "fff2bdde                                           0.0   \n",
       "fff78145                                           0.0   \n",
       "\n",
       "variable  label__fft_coefficient__coeff_53__attr_\"abs\"  \\\n",
       "id                                                       \n",
       "0008ed71                                           0.0   \n",
       "000c79fe                                           0.0   \n",
       "001802e4                                           0.0   \n",
       "0019e639                                           0.0   \n",
       "001b0bf9                                           0.0   \n",
       "001ca5ee                                           0.0   \n",
       "001dfc31                                           0.0   \n",
       "001e9aea                                           0.0   \n",
       "0020152e                                           0.0   \n",
       "002b0188                                           0.0   \n",
       "002e74b2                                           0.0   \n",
       "00317e49                                           0.0   \n",
       "0031c75f                                           0.0   \n",
       "003476c0                                           0.0   \n",
       "003847fc                                           0.0   \n",
       "003a7d49                                           0.0   \n",
       "003bdb4d                                           0.0   \n",
       "003d4cac                                           0.0   \n",
       "003dd965                                           0.0   \n",
       "0042421c                                           0.0   \n",
       "004b8d91                                           0.0   \n",
       "004ed8ba                                           0.0   \n",
       "0050d971                                           0.0   \n",
       "00546e55                                           0.0   \n",
       "00665dda                                           0.0   \n",
       "006671fd                                           0.0   \n",
       "00702e02                                           0.0   \n",
       "00736d10                                           0.0   \n",
       "007537e8                                           0.0   \n",
       "007ddac1                                           0.0   \n",
       "...                                                ...   \n",
       "ff8a9723                                           0.0   \n",
       "ff8af29b                                           0.0   \n",
       "ff906750                                           0.0   \n",
       "ff97d56f                                           0.0   \n",
       "ff97e281                                           0.0   \n",
       "ff9a58dd                                           0.0   \n",
       "ff9b9954                                           0.0   \n",
       "ff9da79b                                           0.0   \n",
       "ffa9ac98                                           0.0   \n",
       "ffae1445                                           0.0   \n",
       "ffaf0844                                           0.0   \n",
       "ffb598de                                           0.0   \n",
       "ffc51f07                                           0.0   \n",
       "ffc670b3                                           0.0   \n",
       "ffcaae19                                           0.0   \n",
       "ffcaeaae                                           0.0   \n",
       "ffd9756a                                           0.0   \n",
       "ffde3628                                           0.0   \n",
       "ffe066cc                                           0.0   \n",
       "ffe7e848                                           0.0   \n",
       "ffeb80c5                                           0.0   \n",
       "ffebdbc9                                           0.0   \n",
       "ffecdf29                                           0.0   \n",
       "ffed0342                                           0.0   \n",
       "ffed3d0e                                           0.0   \n",
       "ffee0f18                                           0.0   \n",
       "ffef83e6                                           0.0   \n",
       "fff1659c                                           0.0   \n",
       "fff2bdde                                           0.0   \n",
       "fff78145                                           0.0   \n",
       "\n",
       "variable  label__fft_coefficient__coeff_54__attr_\"abs\"  \\\n",
       "id                                                       \n",
       "0008ed71                                           0.0   \n",
       "000c79fe                                           0.0   \n",
       "001802e4                                           0.0   \n",
       "0019e639                                           0.0   \n",
       "001b0bf9                                           0.0   \n",
       "001ca5ee                                           0.0   \n",
       "001dfc31                                           0.0   \n",
       "001e9aea                                           0.0   \n",
       "0020152e                                           0.0   \n",
       "002b0188                                           0.0   \n",
       "002e74b2                                           0.0   \n",
       "00317e49                                           0.0   \n",
       "0031c75f                                           0.0   \n",
       "003476c0                                           0.0   \n",
       "003847fc                                           0.0   \n",
       "003a7d49                                           0.0   \n",
       "003bdb4d                                           0.0   \n",
       "003d4cac                                           0.0   \n",
       "003dd965                                           0.0   \n",
       "0042421c                                           0.0   \n",
       "004b8d91                                           0.0   \n",
       "004ed8ba                                           0.0   \n",
       "0050d971                                           0.0   \n",
       "00546e55                                           0.0   \n",
       "00665dda                                           0.0   \n",
       "006671fd                                           0.0   \n",
       "00702e02                                           0.0   \n",
       "00736d10                                           0.0   \n",
       "007537e8                                           0.0   \n",
       "007ddac1                                           0.0   \n",
       "...                                                ...   \n",
       "ff8a9723                                           0.0   \n",
       "ff8af29b                                           0.0   \n",
       "ff906750                                           0.0   \n",
       "ff97d56f                                           0.0   \n",
       "ff97e281                                           0.0   \n",
       "ff9a58dd                                           0.0   \n",
       "ff9b9954                                           0.0   \n",
       "ff9da79b                                           0.0   \n",
       "ffa9ac98                                           0.0   \n",
       "ffae1445                                           0.0   \n",
       "ffaf0844                                           0.0   \n",
       "ffb598de                                           0.0   \n",
       "ffc51f07                                           0.0   \n",
       "ffc670b3                                           0.0   \n",
       "ffcaae19                                           0.0   \n",
       "ffcaeaae                                           0.0   \n",
       "ffd9756a                                           0.0   \n",
       "ffde3628                                           0.0   \n",
       "ffe066cc                                           0.0   \n",
       "ffe7e848                                           0.0   \n",
       "ffeb80c5                                           0.0   \n",
       "ffebdbc9                                           0.0   \n",
       "ffecdf29                                           0.0   \n",
       "ffed0342                                           0.0   \n",
       "ffed3d0e                                           0.0   \n",
       "ffee0f18                                           0.0   \n",
       "ffef83e6                                           0.0   \n",
       "fff1659c                                           0.0   \n",
       "fff2bdde                                           0.0   \n",
       "fff78145                                           0.0   \n",
       "\n",
       "variable  label__fft_coefficient__coeff_55__attr_\"abs\"  \\\n",
       "id                                                       \n",
       "0008ed71                                           0.0   \n",
       "000c79fe                                           0.0   \n",
       "001802e4                                           0.0   \n",
       "0019e639                                           0.0   \n",
       "001b0bf9                                           0.0   \n",
       "001ca5ee                                           0.0   \n",
       "001dfc31                                           0.0   \n",
       "001e9aea                                           0.0   \n",
       "0020152e                                           0.0   \n",
       "002b0188                                           0.0   \n",
       "002e74b2                                           0.0   \n",
       "00317e49                                           0.0   \n",
       "0031c75f                                           0.0   \n",
       "003476c0                                           0.0   \n",
       "003847fc                                           0.0   \n",
       "003a7d49                                           0.0   \n",
       "003bdb4d                                           0.0   \n",
       "003d4cac                                           0.0   \n",
       "003dd965                                           0.0   \n",
       "0042421c                                           0.0   \n",
       "004b8d91                                           0.0   \n",
       "004ed8ba                                           0.0   \n",
       "0050d971                                           0.0   \n",
       "00546e55                                           0.0   \n",
       "00665dda                                           0.0   \n",
       "006671fd                                           0.0   \n",
       "00702e02                                           0.0   \n",
       "00736d10                                           0.0   \n",
       "007537e8                                           0.0   \n",
       "007ddac1                                           0.0   \n",
       "...                                                ...   \n",
       "ff8a9723                                           0.0   \n",
       "ff8af29b                                           0.0   \n",
       "ff906750                                           0.0   \n",
       "ff97d56f                                           0.0   \n",
       "ff97e281                                           0.0   \n",
       "ff9a58dd                                           0.0   \n",
       "ff9b9954                                           0.0   \n",
       "ff9da79b                                           0.0   \n",
       "ffa9ac98                                           0.0   \n",
       "ffae1445                                           0.0   \n",
       "ffaf0844                                           0.0   \n",
       "ffb598de                                           0.0   \n",
       "ffc51f07                                           0.0   \n",
       "ffc670b3                                           0.0   \n",
       "ffcaae19                                           0.0   \n",
       "ffcaeaae                                           0.0   \n",
       "ffd9756a                                           0.0   \n",
       "ffde3628                                           0.0   \n",
       "ffe066cc                                           0.0   \n",
       "ffe7e848                                           0.0   \n",
       "ffeb80c5                                           0.0   \n",
       "ffebdbc9                                           0.0   \n",
       "ffecdf29                                           0.0   \n",
       "ffed0342                                           0.0   \n",
       "ffed3d0e                                           0.0   \n",
       "ffee0f18                                           0.0   \n",
       "ffef83e6                                           0.0   \n",
       "fff1659c                                           0.0   \n",
       "fff2bdde                                           0.0   \n",
       "fff78145                                           0.0   \n",
       "\n",
       "variable  label__fft_coefficient__coeff_56__attr_\"abs\"  \\\n",
       "id                                                       \n",
       "0008ed71                                           0.0   \n",
       "000c79fe                                           0.0   \n",
       "001802e4                                           0.0   \n",
       "0019e639                                           0.0   \n",
       "001b0bf9                                           0.0   \n",
       "001ca5ee                                           0.0   \n",
       "001dfc31                                           0.0   \n",
       "001e9aea                                           0.0   \n",
       "0020152e                                           0.0   \n",
       "002b0188                                           0.0   \n",
       "002e74b2                                           0.0   \n",
       "00317e49                                           0.0   \n",
       "0031c75f                                           0.0   \n",
       "003476c0                                           0.0   \n",
       "003847fc                                           0.0   \n",
       "003a7d49                                           0.0   \n",
       "003bdb4d                                           0.0   \n",
       "003d4cac                                           0.0   \n",
       "003dd965                                           0.0   \n",
       "0042421c                                           0.0   \n",
       "004b8d91                                           0.0   \n",
       "004ed8ba                                           0.0   \n",
       "0050d971                                           0.0   \n",
       "00546e55                                           0.0   \n",
       "00665dda                                           0.0   \n",
       "006671fd                                           0.0   \n",
       "00702e02                                           0.0   \n",
       "00736d10                                           0.0   \n",
       "007537e8                                           0.0   \n",
       "007ddac1                                           0.0   \n",
       "...                                                ...   \n",
       "ff8a9723                                           0.0   \n",
       "ff8af29b                                           0.0   \n",
       "ff906750                                           0.0   \n",
       "ff97d56f                                           0.0   \n",
       "ff97e281                                           0.0   \n",
       "ff9a58dd                                           0.0   \n",
       "ff9b9954                                           0.0   \n",
       "ff9da79b                                           0.0   \n",
       "ffa9ac98                                           0.0   \n",
       "ffae1445                                           0.0   \n",
       "ffaf0844                                           0.0   \n",
       "ffb598de                                           0.0   \n",
       "ffc51f07                                           0.0   \n",
       "ffc670b3                                           0.0   \n",
       "ffcaae19                                           0.0   \n",
       "ffcaeaae                                           0.0   \n",
       "ffd9756a                                           0.0   \n",
       "ffde3628                                           0.0   \n",
       "ffe066cc                                           0.0   \n",
       "ffe7e848                                           0.0   \n",
       "ffeb80c5                                           0.0   \n",
       "ffebdbc9                                           0.0   \n",
       "ffecdf29                                           0.0   \n",
       "ffed0342                                           0.0   \n",
       "ffed3d0e                                           0.0   \n",
       "ffee0f18                                           0.0   \n",
       "ffef83e6                                           0.0   \n",
       "fff1659c                                           0.0   \n",
       "fff2bdde                                           0.0   \n",
       "fff78145                                           0.0   \n",
       "\n",
       "variable                      ...                        \\\n",
       "id                            ...                         \n",
       "0008ed71                      ...                         \n",
       "000c79fe                      ...                         \n",
       "001802e4                      ...                         \n",
       "0019e639                      ...                         \n",
       "001b0bf9                      ...                         \n",
       "001ca5ee                      ...                         \n",
       "001dfc31                      ...                         \n",
       "001e9aea                      ...                         \n",
       "0020152e                      ...                         \n",
       "002b0188                      ...                         \n",
       "002e74b2                      ...                         \n",
       "00317e49                      ...                         \n",
       "0031c75f                      ...                         \n",
       "003476c0                      ...                         \n",
       "003847fc                      ...                         \n",
       "003a7d49                      ...                         \n",
       "003bdb4d                      ...                         \n",
       "003d4cac                      ...                         \n",
       "003dd965                      ...                         \n",
       "0042421c                      ...                         \n",
       "004b8d91                      ...                         \n",
       "004ed8ba                      ...                         \n",
       "0050d971                      ...                         \n",
       "00546e55                      ...                         \n",
       "00665dda                      ...                         \n",
       "006671fd                      ...                         \n",
       "00702e02                      ...                         \n",
       "00736d10                      ...                         \n",
       "007537e8                      ...                         \n",
       "007ddac1                      ...                         \n",
       "...                           ...                         \n",
       "ff8a9723                      ...                         \n",
       "ff8af29b                      ...                         \n",
       "ff906750                      ...                         \n",
       "ff97d56f                      ...                         \n",
       "ff97e281                      ...                         \n",
       "ff9a58dd                      ...                         \n",
       "ff9b9954                      ...                         \n",
       "ff9da79b                      ...                         \n",
       "ffa9ac98                      ...                         \n",
       "ffae1445                      ...                         \n",
       "ffaf0844                      ...                         \n",
       "ffb598de                      ...                         \n",
       "ffc51f07                      ...                         \n",
       "ffc670b3                      ...                         \n",
       "ffcaae19                      ...                         \n",
       "ffcaeaae                      ...                         \n",
       "ffd9756a                      ...                         \n",
       "ffde3628                      ...                         \n",
       "ffe066cc                      ...                         \n",
       "ffe7e848                      ...                         \n",
       "ffeb80c5                      ...                         \n",
       "ffebdbc9                      ...                         \n",
       "ffecdf29                      ...                         \n",
       "ffed0342                      ...                         \n",
       "ffed3d0e                      ...                         \n",
       "ffee0f18                      ...                         \n",
       "ffef83e6                      ...                         \n",
       "fff1659c                      ...                         \n",
       "fff2bdde                      ...                         \n",
       "fff78145                      ...                         \n",
       "\n",
       "variable  label__percentage_of_reoccurring_values_to_all_values  \\\n",
       "id                                                                \n",
       "0008ed71                                                1.0       \n",
       "000c79fe                                                1.0       \n",
       "001802e4                                                1.0       \n",
       "0019e639                                                1.0       \n",
       "001b0bf9                                                1.0       \n",
       "001ca5ee                                                1.0       \n",
       "001dfc31                                                1.0       \n",
       "001e9aea                                                1.0       \n",
       "0020152e                                                1.0       \n",
       "002b0188                                                1.0       \n",
       "002e74b2                                                1.0       \n",
       "00317e49                                                1.0       \n",
       "0031c75f                                                1.0       \n",
       "003476c0                                                1.0       \n",
       "003847fc                                                1.0       \n",
       "003a7d49                                                1.0       \n",
       "003bdb4d                                                1.0       \n",
       "003d4cac                                                1.0       \n",
       "003dd965                                                1.0       \n",
       "0042421c                                                1.0       \n",
       "004b8d91                                                1.0       \n",
       "004ed8ba                                                1.0       \n",
       "0050d971                                                1.0       \n",
       "00546e55                                                1.0       \n",
       "00665dda                                                1.0       \n",
       "006671fd                                                1.0       \n",
       "00702e02                                                1.0       \n",
       "00736d10                                                1.0       \n",
       "007537e8                                                1.0       \n",
       "007ddac1                                                1.0       \n",
       "...                                                     ...       \n",
       "ff8a9723                                                1.0       \n",
       "ff8af29b                                                1.0       \n",
       "ff906750                                                1.0       \n",
       "ff97d56f                                                1.0       \n",
       "ff97e281                                                1.0       \n",
       "ff9a58dd                                                1.0       \n",
       "ff9b9954                                                1.0       \n",
       "ff9da79b                                                1.0       \n",
       "ffa9ac98                                                1.0       \n",
       "ffae1445                                                1.0       \n",
       "ffaf0844                                                1.0       \n",
       "ffb598de                                                1.0       \n",
       "ffc51f07                                                1.0       \n",
       "ffc670b3                                                1.0       \n",
       "ffcaae19                                                1.0       \n",
       "ffcaeaae                                                1.0       \n",
       "ffd9756a                                                1.0       \n",
       "ffde3628                                                1.0       \n",
       "ffe066cc                                                1.0       \n",
       "ffe7e848                                                1.0       \n",
       "ffeb80c5                                                1.0       \n",
       "ffebdbc9                                                1.0       \n",
       "ffecdf29                                                1.0       \n",
       "ffed0342                                                1.0       \n",
       "ffed3d0e                                                1.0       \n",
       "ffee0f18                                                1.0       \n",
       "ffef83e6                                                1.0       \n",
       "fff1659c                                                1.0       \n",
       "fff2bdde                                                1.0       \n",
       "fff78145                                                1.0       \n",
       "\n",
       "variable  label__fft_coefficient__coeff_45__attr_\"angle\"  \\\n",
       "id                                                         \n",
       "0008ed71                                             0.0   \n",
       "000c79fe                                             0.0   \n",
       "001802e4                                             0.0   \n",
       "0019e639                                             0.0   \n",
       "001b0bf9                                             0.0   \n",
       "001ca5ee                                             0.0   \n",
       "001dfc31                                             0.0   \n",
       "001e9aea                                             0.0   \n",
       "0020152e                                             0.0   \n",
       "002b0188                                             0.0   \n",
       "002e74b2                                             0.0   \n",
       "00317e49                                             0.0   \n",
       "0031c75f                                             0.0   \n",
       "003476c0                                             0.0   \n",
       "003847fc                                             0.0   \n",
       "003a7d49                                             0.0   \n",
       "003bdb4d                                             0.0   \n",
       "003d4cac                                             0.0   \n",
       "003dd965                                             0.0   \n",
       "0042421c                                             0.0   \n",
       "004b8d91                                             0.0   \n",
       "004ed8ba                                             0.0   \n",
       "0050d971                                             0.0   \n",
       "00546e55                                             0.0   \n",
       "00665dda                                             0.0   \n",
       "006671fd                                             0.0   \n",
       "00702e02                                             0.0   \n",
       "00736d10                                             0.0   \n",
       "007537e8                                             0.0   \n",
       "007ddac1                                             0.0   \n",
       "...                                                  ...   \n",
       "ff8a9723                                             0.0   \n",
       "ff8af29b                                             0.0   \n",
       "ff906750                                             0.0   \n",
       "ff97d56f                                             0.0   \n",
       "ff97e281                                             0.0   \n",
       "ff9a58dd                                             0.0   \n",
       "ff9b9954                                             0.0   \n",
       "ff9da79b                                             0.0   \n",
       "ffa9ac98                                             0.0   \n",
       "ffae1445                                             0.0   \n",
       "ffaf0844                                             0.0   \n",
       "ffb598de                                             0.0   \n",
       "ffc51f07                                             0.0   \n",
       "ffc670b3                                            -0.0   \n",
       "ffcaae19                                             0.0   \n",
       "ffcaeaae                                             0.0   \n",
       "ffd9756a                                             0.0   \n",
       "ffde3628                                             0.0   \n",
       "ffe066cc                                             0.0   \n",
       "ffe7e848                                            -0.0   \n",
       "ffeb80c5                                             0.0   \n",
       "ffebdbc9                                             0.0   \n",
       "ffecdf29                                             0.0   \n",
       "ffed0342                                             0.0   \n",
       "ffed3d0e                                             0.0   \n",
       "ffee0f18                                             0.0   \n",
       "ffef83e6                                             0.0   \n",
       "fff1659c                                             0.0   \n",
       "fff2bdde                                             0.0   \n",
       "fff78145                                             0.0   \n",
       "\n",
       "variable  label__fft_coefficient__coeff_66__attr_\"angle\"  \\\n",
       "id                                                         \n",
       "0008ed71                                             0.0   \n",
       "000c79fe                                             0.0   \n",
       "001802e4                                             0.0   \n",
       "0019e639                                           180.0   \n",
       "001b0bf9                                             0.0   \n",
       "001ca5ee                                             0.0   \n",
       "001dfc31                                             0.0   \n",
       "001e9aea                                             0.0   \n",
       "0020152e                                             0.0   \n",
       "002b0188                                             0.0   \n",
       "002e74b2                                             0.0   \n",
       "00317e49                                             0.0   \n",
       "0031c75f                                             0.0   \n",
       "003476c0                                             0.0   \n",
       "003847fc                                             0.0   \n",
       "003a7d49                                             0.0   \n",
       "003bdb4d                                             0.0   \n",
       "003d4cac                                             0.0   \n",
       "003dd965                                             0.0   \n",
       "0042421c                                             0.0   \n",
       "004b8d91                                             0.0   \n",
       "004ed8ba                                             0.0   \n",
       "0050d971                                             0.0   \n",
       "00546e55                                             0.0   \n",
       "00665dda                                             0.0   \n",
       "006671fd                                             0.0   \n",
       "00702e02                                             0.0   \n",
       "00736d10                                             0.0   \n",
       "007537e8                                             0.0   \n",
       "007ddac1                                             0.0   \n",
       "...                                                  ...   \n",
       "ff8a9723                                             0.0   \n",
       "ff8af29b                                             0.0   \n",
       "ff906750                                             0.0   \n",
       "ff97d56f                                             0.0   \n",
       "ff97e281                                             0.0   \n",
       "ff9a58dd                                             0.0   \n",
       "ff9b9954                                             0.0   \n",
       "ff9da79b                                             0.0   \n",
       "ffa9ac98                                             0.0   \n",
       "ffae1445                                             0.0   \n",
       "ffaf0844                                             0.0   \n",
       "ffb598de                                             0.0   \n",
       "ffc51f07                                             0.0   \n",
       "ffc670b3                                             0.0   \n",
       "ffcaae19                                             0.0   \n",
       "ffcaeaae                                             0.0   \n",
       "ffd9756a                                             0.0   \n",
       "ffde3628                                             0.0   \n",
       "ffe066cc                                             0.0   \n",
       "ffe7e848                                             0.0   \n",
       "ffeb80c5                                             0.0   \n",
       "ffebdbc9                                             0.0   \n",
       "ffecdf29                                             0.0   \n",
       "ffed0342                                             0.0   \n",
       "ffed3d0e                                             0.0   \n",
       "ffee0f18                                             0.0   \n",
       "ffef83e6                                             0.0   \n",
       "fff1659c                                             0.0   \n",
       "fff2bdde                                             0.0   \n",
       "fff78145                                             0.0   \n",
       "\n",
       "variable  label__fft_coefficient__coeff_85__attr_\"imag\"  \\\n",
       "id                                                        \n",
       "0008ed71                                            0.0   \n",
       "000c79fe                                            0.0   \n",
       "001802e4                                            0.0   \n",
       "0019e639                                            0.0   \n",
       "001b0bf9                                            0.0   \n",
       "001ca5ee                                            0.0   \n",
       "001dfc31                                            0.0   \n",
       "001e9aea                                            0.0   \n",
       "0020152e                                            0.0   \n",
       "002b0188                                            0.0   \n",
       "002e74b2                                            0.0   \n",
       "00317e49                                            0.0   \n",
       "0031c75f                                            0.0   \n",
       "003476c0                                            0.0   \n",
       "003847fc                                            0.0   \n",
       "003a7d49                                            0.0   \n",
       "003bdb4d                                            0.0   \n",
       "003d4cac                                            0.0   \n",
       "003dd965                                            0.0   \n",
       "0042421c                                            0.0   \n",
       "004b8d91                                            0.0   \n",
       "004ed8ba                                            0.0   \n",
       "0050d971                                            0.0   \n",
       "00546e55                                            0.0   \n",
       "00665dda                                            0.0   \n",
       "006671fd                                            0.0   \n",
       "00702e02                                            0.0   \n",
       "00736d10                                            0.0   \n",
       "007537e8                                            0.0   \n",
       "007ddac1                                            0.0   \n",
       "...                                                 ...   \n",
       "ff8a9723                                            0.0   \n",
       "ff8af29b                                            0.0   \n",
       "ff906750                                            0.0   \n",
       "ff97d56f                                            0.0   \n",
       "ff97e281                                            0.0   \n",
       "ff9a58dd                                            0.0   \n",
       "ff9b9954                                            0.0   \n",
       "ff9da79b                                           -0.0   \n",
       "ffa9ac98                                            0.0   \n",
       "ffae1445                                            0.0   \n",
       "ffaf0844                                            0.0   \n",
       "ffb598de                                            0.0   \n",
       "ffc51f07                                            0.0   \n",
       "ffc670b3                                            0.0   \n",
       "ffcaae19                                            0.0   \n",
       "ffcaeaae                                            0.0   \n",
       "ffd9756a                                            0.0   \n",
       "ffde3628                                            0.0   \n",
       "ffe066cc                                            0.0   \n",
       "ffe7e848                                            0.0   \n",
       "ffeb80c5                                            0.0   \n",
       "ffebdbc9                                            0.0   \n",
       "ffecdf29                                            0.0   \n",
       "ffed0342                                            0.0   \n",
       "ffed3d0e                                            0.0   \n",
       "ffee0f18                                            0.0   \n",
       "ffef83e6                                            0.0   \n",
       "fff1659c                                            0.0   \n",
       "fff2bdde                                            0.0   \n",
       "fff78145                                            0.0   \n",
       "\n",
       "variable  label__fft_coefficient__coeff_71__attr_\"angle\"  \\\n",
       "id                                                         \n",
       "0008ed71                                             0.0   \n",
       "000c79fe                                             0.0   \n",
       "001802e4                                             0.0   \n",
       "0019e639                                            -0.0   \n",
       "001b0bf9                                             0.0   \n",
       "001ca5ee                                             0.0   \n",
       "001dfc31                                             0.0   \n",
       "001e9aea                                             0.0   \n",
       "0020152e                                             0.0   \n",
       "002b0188                                             0.0   \n",
       "002e74b2                                             0.0   \n",
       "00317e49                                             0.0   \n",
       "0031c75f                                             0.0   \n",
       "003476c0                                             0.0   \n",
       "003847fc                                             0.0   \n",
       "003a7d49                                             0.0   \n",
       "003bdb4d                                             0.0   \n",
       "003d4cac                                             0.0   \n",
       "003dd965                                             0.0   \n",
       "0042421c                                             0.0   \n",
       "004b8d91                                             0.0   \n",
       "004ed8ba                                             0.0   \n",
       "0050d971                                             0.0   \n",
       "00546e55                                             0.0   \n",
       "00665dda                                             0.0   \n",
       "006671fd                                             0.0   \n",
       "00702e02                                             0.0   \n",
       "00736d10                                             0.0   \n",
       "007537e8                                             0.0   \n",
       "007ddac1                                             0.0   \n",
       "...                                                  ...   \n",
       "ff8a9723                                             0.0   \n",
       "ff8af29b                                             0.0   \n",
       "ff906750                                             0.0   \n",
       "ff97d56f                                             0.0   \n",
       "ff97e281                                             0.0   \n",
       "ff9a58dd                                             0.0   \n",
       "ff9b9954                                             0.0   \n",
       "ff9da79b                                             0.0   \n",
       "ffa9ac98                                             0.0   \n",
       "ffae1445                                             0.0   \n",
       "ffaf0844                                             0.0   \n",
       "ffb598de                                             0.0   \n",
       "ffc51f07                                             0.0   \n",
       "ffc670b3                                             0.0   \n",
       "ffcaae19                                             0.0   \n",
       "ffcaeaae                                             0.0   \n",
       "ffd9756a                                             0.0   \n",
       "ffde3628                                             0.0   \n",
       "ffe066cc                                             0.0   \n",
       "ffe7e848                                             0.0   \n",
       "ffeb80c5                                             0.0   \n",
       "ffebdbc9                                             0.0   \n",
       "ffecdf29                                             0.0   \n",
       "ffed0342                                             0.0   \n",
       "ffed3d0e                                             0.0   \n",
       "ffee0f18                                             0.0   \n",
       "ffef83e6                                             0.0   \n",
       "fff1659c                                             0.0   \n",
       "fff2bdde                                             0.0   \n",
       "fff78145                                             0.0   \n",
       "\n",
       "variable  label__fft_coefficient__coeff_92__attr_\"imag\"  \\\n",
       "id                                                        \n",
       "0008ed71                                            0.0   \n",
       "000c79fe                                            0.0   \n",
       "001802e4                                            0.0   \n",
       "0019e639                                            0.0   \n",
       "001b0bf9                                            0.0   \n",
       "001ca5ee                                            0.0   \n",
       "001dfc31                                            0.0   \n",
       "001e9aea                                            0.0   \n",
       "0020152e                                            0.0   \n",
       "002b0188                                            0.0   \n",
       "002e74b2                                            0.0   \n",
       "00317e49                                            0.0   \n",
       "0031c75f                                            0.0   \n",
       "003476c0                                            0.0   \n",
       "003847fc                                            0.0   \n",
       "003a7d49                                            0.0   \n",
       "003bdb4d                                            0.0   \n",
       "003d4cac                                            0.0   \n",
       "003dd965                                            0.0   \n",
       "0042421c                                            0.0   \n",
       "004b8d91                                            0.0   \n",
       "004ed8ba                                            0.0   \n",
       "0050d971                                            0.0   \n",
       "00546e55                                            0.0   \n",
       "00665dda                                            0.0   \n",
       "006671fd                                            0.0   \n",
       "00702e02                                            0.0   \n",
       "00736d10                                            0.0   \n",
       "007537e8                                            0.0   \n",
       "007ddac1                                            0.0   \n",
       "...                                                 ...   \n",
       "ff8a9723                                            0.0   \n",
       "ff8af29b                                            0.0   \n",
       "ff906750                                            0.0   \n",
       "ff97d56f                                            0.0   \n",
       "ff97e281                                            0.0   \n",
       "ff9a58dd                                            0.0   \n",
       "ff9b9954                                            0.0   \n",
       "ff9da79b                                           -0.0   \n",
       "ffa9ac98                                            0.0   \n",
       "ffae1445                                            0.0   \n",
       "ffaf0844                                            0.0   \n",
       "ffb598de                                            0.0   \n",
       "ffc51f07                                            0.0   \n",
       "ffc670b3                                            0.0   \n",
       "ffcaae19                                            0.0   \n",
       "ffcaeaae                                            0.0   \n",
       "ffd9756a                                            0.0   \n",
       "ffde3628                                            0.0   \n",
       "ffe066cc                                            0.0   \n",
       "ffe7e848                                            0.0   \n",
       "ffeb80c5                                            0.0   \n",
       "ffebdbc9                                            0.0   \n",
       "ffecdf29                                            0.0   \n",
       "ffed0342                                            0.0   \n",
       "ffed3d0e                                            0.0   \n",
       "ffee0f18                                            0.0   \n",
       "ffef83e6                                            0.0   \n",
       "fff1659c                                            0.0   \n",
       "fff2bdde                                            0.0   \n",
       "fff78145                                            0.0   \n",
       "\n",
       "variable  label__fft_coefficient__coeff_53__attr_\"imag\"  \\\n",
       "id                                                        \n",
       "0008ed71                                            0.0   \n",
       "000c79fe                                            0.0   \n",
       "001802e4                                            0.0   \n",
       "0019e639                                            0.0   \n",
       "001b0bf9                                            0.0   \n",
       "001ca5ee                                            0.0   \n",
       "001dfc31                                            0.0   \n",
       "001e9aea                                            0.0   \n",
       "0020152e                                            0.0   \n",
       "002b0188                                            0.0   \n",
       "002e74b2                                            0.0   \n",
       "00317e49                                            0.0   \n",
       "0031c75f                                            0.0   \n",
       "003476c0                                            0.0   \n",
       "003847fc                                            0.0   \n",
       "003a7d49                                            0.0   \n",
       "003bdb4d                                            0.0   \n",
       "003d4cac                                            0.0   \n",
       "003dd965                                            0.0   \n",
       "0042421c                                            0.0   \n",
       "004b8d91                                            0.0   \n",
       "004ed8ba                                            0.0   \n",
       "0050d971                                            0.0   \n",
       "00546e55                                            0.0   \n",
       "00665dda                                            0.0   \n",
       "006671fd                                            0.0   \n",
       "00702e02                                            0.0   \n",
       "00736d10                                            0.0   \n",
       "007537e8                                            0.0   \n",
       "007ddac1                                            0.0   \n",
       "...                                                 ...   \n",
       "ff8a9723                                            0.0   \n",
       "ff8af29b                                            0.0   \n",
       "ff906750                                            0.0   \n",
       "ff97d56f                                            0.0   \n",
       "ff97e281                                            0.0   \n",
       "ff9a58dd                                            0.0   \n",
       "ff9b9954                                            0.0   \n",
       "ff9da79b                                           -0.0   \n",
       "ffa9ac98                                            0.0   \n",
       "ffae1445                                            0.0   \n",
       "ffaf0844                                            0.0   \n",
       "ffb598de                                            0.0   \n",
       "ffc51f07                                            0.0   \n",
       "ffc670b3                                            0.0   \n",
       "ffcaae19                                            0.0   \n",
       "ffcaeaae                                            0.0   \n",
       "ffd9756a                                            0.0   \n",
       "ffde3628                                            0.0   \n",
       "ffe066cc                                            0.0   \n",
       "ffe7e848                                            0.0   \n",
       "ffeb80c5                                            0.0   \n",
       "ffebdbc9                                            0.0   \n",
       "ffecdf29                                            0.0   \n",
       "ffed0342                                            0.0   \n",
       "ffed3d0e                                            0.0   \n",
       "ffee0f18                                            0.0   \n",
       "ffef83e6                                            0.0   \n",
       "fff1659c                                            0.0   \n",
       "fff2bdde                                            0.0   \n",
       "fff78145                                            0.0   \n",
       "\n",
       "variable  label__fft_coefficient__coeff_58__attr_\"imag\"  \\\n",
       "id                                                        \n",
       "0008ed71                                            0.0   \n",
       "000c79fe                                            0.0   \n",
       "001802e4                                            0.0   \n",
       "0019e639                                            0.0   \n",
       "001b0bf9                                            0.0   \n",
       "001ca5ee                                            0.0   \n",
       "001dfc31                                            0.0   \n",
       "001e9aea                                            0.0   \n",
       "0020152e                                            0.0   \n",
       "002b0188                                            0.0   \n",
       "002e74b2                                            0.0   \n",
       "00317e49                                            0.0   \n",
       "0031c75f                                            0.0   \n",
       "003476c0                                            0.0   \n",
       "003847fc                                            0.0   \n",
       "003a7d49                                            0.0   \n",
       "003bdb4d                                            0.0   \n",
       "003d4cac                                            0.0   \n",
       "003dd965                                            0.0   \n",
       "0042421c                                            0.0   \n",
       "004b8d91                                            0.0   \n",
       "004ed8ba                                            0.0   \n",
       "0050d971                                            0.0   \n",
       "00546e55                                            0.0   \n",
       "00665dda                                            0.0   \n",
       "006671fd                                            0.0   \n",
       "00702e02                                            0.0   \n",
       "00736d10                                            0.0   \n",
       "007537e8                                            0.0   \n",
       "007ddac1                                            0.0   \n",
       "...                                                 ...   \n",
       "ff8a9723                                            0.0   \n",
       "ff8af29b                                            0.0   \n",
       "ff906750                                            0.0   \n",
       "ff97d56f                                            0.0   \n",
       "ff97e281                                            0.0   \n",
       "ff9a58dd                                            0.0   \n",
       "ff9b9954                                            0.0   \n",
       "ff9da79b                                           -0.0   \n",
       "ffa9ac98                                            0.0   \n",
       "ffae1445                                            0.0   \n",
       "ffaf0844                                            0.0   \n",
       "ffb598de                                            0.0   \n",
       "ffc51f07                                            0.0   \n",
       "ffc670b3                                            0.0   \n",
       "ffcaae19                                            0.0   \n",
       "ffcaeaae                                            0.0   \n",
       "ffd9756a                                            0.0   \n",
       "ffde3628                                            0.0   \n",
       "ffe066cc                                            0.0   \n",
       "ffe7e848                                            0.0   \n",
       "ffeb80c5                                            0.0   \n",
       "ffebdbc9                                            0.0   \n",
       "ffecdf29                                            0.0   \n",
       "ffed0342                                            0.0   \n",
       "ffed3d0e                                            0.0   \n",
       "ffee0f18                                            0.0   \n",
       "ffef83e6                                            0.0   \n",
       "fff1659c                                            0.0   \n",
       "fff2bdde                                            0.0   \n",
       "fff78145                                            0.0   \n",
       "\n",
       "variable  label__fft_coefficient__coeff_89__attr_\"angle\"  \\\n",
       "id                                                         \n",
       "0008ed71                                             0.0   \n",
       "000c79fe                                             0.0   \n",
       "001802e4                                             0.0   \n",
       "0019e639                                            -0.0   \n",
       "001b0bf9                                             0.0   \n",
       "001ca5ee                                             0.0   \n",
       "001dfc31                                             0.0   \n",
       "001e9aea                                             0.0   \n",
       "0020152e                                             0.0   \n",
       "002b0188                                             0.0   \n",
       "002e74b2                                             0.0   \n",
       "00317e49                                             0.0   \n",
       "0031c75f                                             0.0   \n",
       "003476c0                                             0.0   \n",
       "003847fc                                             0.0   \n",
       "003a7d49                                             0.0   \n",
       "003bdb4d                                             0.0   \n",
       "003d4cac                                             0.0   \n",
       "003dd965                                             0.0   \n",
       "0042421c                                             0.0   \n",
       "004b8d91                                             0.0   \n",
       "004ed8ba                                             0.0   \n",
       "0050d971                                             0.0   \n",
       "00546e55                                             0.0   \n",
       "00665dda                                             0.0   \n",
       "006671fd                                             0.0   \n",
       "00702e02                                             0.0   \n",
       "00736d10                                             0.0   \n",
       "007537e8                                             0.0   \n",
       "007ddac1                                             0.0   \n",
       "...                                                  ...   \n",
       "ff8a9723                                             0.0   \n",
       "ff8af29b                                             0.0   \n",
       "ff906750                                             0.0   \n",
       "ff97d56f                                             0.0   \n",
       "ff97e281                                             0.0   \n",
       "ff9a58dd                                             0.0   \n",
       "ff9b9954                                             0.0   \n",
       "ff9da79b                                            -0.0   \n",
       "ffa9ac98                                             0.0   \n",
       "ffae1445                                             0.0   \n",
       "ffaf0844                                             0.0   \n",
       "ffb598de                                             0.0   \n",
       "ffc51f07                                             0.0   \n",
       "ffc670b3                                             0.0   \n",
       "ffcaae19                                             0.0   \n",
       "ffcaeaae                                             0.0   \n",
       "ffd9756a                                             0.0   \n",
       "ffde3628                                             0.0   \n",
       "ffe066cc                                             0.0   \n",
       "ffe7e848                                             0.0   \n",
       "ffeb80c5                                             0.0   \n",
       "ffebdbc9                                             0.0   \n",
       "ffecdf29                                             0.0   \n",
       "ffed0342                                             0.0   \n",
       "ffed3d0e                                             0.0   \n",
       "ffee0f18                                             0.0   \n",
       "ffef83e6                                             0.0   \n",
       "fff1659c                                             0.0   \n",
       "fff2bdde                                             0.0   \n",
       "fff78145                                             0.0   \n",
       "\n",
       "variable  label__fft_coefficient__coeff_69__attr_\"imag\"  \n",
       "id                                                       \n",
       "0008ed71                                            0.0  \n",
       "000c79fe                                            0.0  \n",
       "001802e4                                            0.0  \n",
       "0019e639                                            0.0  \n",
       "001b0bf9                                            0.0  \n",
       "001ca5ee                                            0.0  \n",
       "001dfc31                                            0.0  \n",
       "001e9aea                                            0.0  \n",
       "0020152e                                            0.0  \n",
       "002b0188                                            0.0  \n",
       "002e74b2                                            0.0  \n",
       "00317e49                                            0.0  \n",
       "0031c75f                                            0.0  \n",
       "003476c0                                            0.0  \n",
       "003847fc                                            0.0  \n",
       "003a7d49                                            0.0  \n",
       "003bdb4d                                            0.0  \n",
       "003d4cac                                            0.0  \n",
       "003dd965                                            0.0  \n",
       "0042421c                                            0.0  \n",
       "004b8d91                                            0.0  \n",
       "004ed8ba                                            0.0  \n",
       "0050d971                                            0.0  \n",
       "00546e55                                            0.0  \n",
       "00665dda                                            0.0  \n",
       "006671fd                                            0.0  \n",
       "00702e02                                            0.0  \n",
       "00736d10                                            0.0  \n",
       "007537e8                                            0.0  \n",
       "007ddac1                                            0.0  \n",
       "...                                                 ...  \n",
       "ff8a9723                                            0.0  \n",
       "ff8af29b                                            0.0  \n",
       "ff906750                                            0.0  \n",
       "ff97d56f                                            0.0  \n",
       "ff97e281                                            0.0  \n",
       "ff9a58dd                                            0.0  \n",
       "ff9b9954                                            0.0  \n",
       "ff9da79b                                            0.0  \n",
       "ffa9ac98                                            0.0  \n",
       "ffae1445                                            0.0  \n",
       "ffaf0844                                            0.0  \n",
       "ffb598de                                            0.0  \n",
       "ffc51f07                                            0.0  \n",
       "ffc670b3                                            0.0  \n",
       "ffcaae19                                            0.0  \n",
       "ffcaeaae                                            0.0  \n",
       "ffd9756a                                            0.0  \n",
       "ffde3628                                            0.0  \n",
       "ffe066cc                                            0.0  \n",
       "ffe7e848                                            0.0  \n",
       "ffeb80c5                                            0.0  \n",
       "ffebdbc9                                            0.0  \n",
       "ffecdf29                                            0.0  \n",
       "ffed0342                                            0.0  \n",
       "ffed3d0e                                            0.0  \n",
       "ffee0f18                                            0.0  \n",
       "ffef83e6                                            0.0  \n",
       "fff1659c                                            0.0  \n",
       "fff2bdde                                            0.0  \n",
       "fff78145                                            0.0  \n",
       "\n",
       "[19414 rows x 484 columns]"
      ]
     },
     "execution_count": 522,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You have NaN values in your value column.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-501-47e47307eab9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mdf_para_probar\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"person\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"inner\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"label\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m features_filtered_direct = extract_relevant_features(df_para_probar, labels,\n\u001b[1;32m----> 3\u001b[1;33m                                                      column_id='person', column_sort='timestamp')\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tsfresh\\convenience\\relevant_extraction.py\u001b[0m in \u001b[0;36mextract_relevant_features\u001b[1;34m(timeseries_container, y, X, default_fc_parameters, kind_to_fc_parameters, column_id, column_sort, column_kind, column_value, show_warnings, disable_progressbar, profile, profiling_filename, profiling_sorting, test_for_binary_target_binary_feature, test_for_binary_target_real_feature, test_for_real_target_binary_feature, test_for_real_target_real_feature, fdr_level, hypotheses_independent, n_jobs, chunksize, ml_task)\u001b[0m\n\u001b[0;32m    148\u001b[0m                              \u001b[0mcolumn_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumn_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn_sort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumn_sort\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m                              \u001b[0mcolumn_kind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumn_kind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn_value\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumn_value\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m                              impute_function=impute)\n\u001b[0m\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m     X_sel = select_features(X_ext, y,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tsfresh\\feature_extraction\\extraction.py\u001b[0m in \u001b[0;36mextract_features\u001b[1;34m(timeseries_container, default_fc_parameters, kind_to_fc_parameters, column_id, column_sort, column_kind, column_value, chunksize, n_jobs, show_warnings, disable_progressbar, impute_function, profile, profiling_filename, profiling_sorting, distributor)\u001b[0m\n\u001b[0;32m    135\u001b[0m                                                                         \u001b[0mcolumn_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumn_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn_kind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumn_kind\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m                                                                         \u001b[0mcolumn_sort\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumn_sort\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m                                                                         column_value=column_value)\n\u001b[0m\u001b[0;32m    138\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;31m# Use the standard setting if the user did not supply ones himself.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tsfresh\\utilities\\dataframe_functions.py\u001b[0m in \u001b[0;36m_normalize_input_to_internal_representation\u001b[1;34m(timeseries_container, column_id, column_sort, column_kind, column_value)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtimeseries_container\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcolumn_value\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misnull\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 305\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"You have NaN values in your value column.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    306\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    307\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtimeseries_container\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn_kind\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: You have NaN values in your value column."
     ]
    }
   ],
   "source": [
    "df_para_probar = pd.merge(df, labels, on=\"person\", how=\"inner\").drop(columns=\"label\")\n",
    "features_filtered_direct = extract_relevant_features(df_para_probar, labels,\n",
    "                                                     column_id='person', column_sort='timestamp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cantidad de veces que realiza un evento dado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ad campaign hit</th>\n",
       "      <th>brand listing</th>\n",
       "      <th>checkout</th>\n",
       "      <th>conversion</th>\n",
       "      <th>generic listing</th>\n",
       "      <th>search engine hit</th>\n",
       "      <th>searched products</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ad campaign hit  brand listing  checkout  conversion  generic listing  \\\n",
       "0              0.0            0.0       3.0         0.0              1.0   \n",
       "1              1.0            0.0       1.0         0.0              1.0   \n",
       "2              5.0            0.0       1.0         0.0              4.0   \n",
       "3             29.0          165.0      15.0         2.0             28.0   \n",
       "4              0.0            1.0       2.0         1.0              1.0   \n",
       "\n",
       "   search engine hit  searched products  label  \n",
       "0                0.0                0.0      0  \n",
       "1                1.0                9.0      0  \n",
       "2                0.0                4.0      0  \n",
       "3               13.0               11.0      0  \n",
       "4                0.0                0.0      0  "
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cant_por_evento = pd.concat([pd.get_dummies(df['event']),df[['person']]],axis = 1).groupby('person')\\\n",
    "    .sum().reset_index()\n",
    "\n",
    "df_train = pd.merge(cant_por_evento, labels, on=\"person\", how=\"inner\")\\\n",
    "            .drop(columns = ['person', 'viewed product', 'visited site', 'staticpage', 'lead'])\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#veo cuantos users pierdo\n",
    "cant_por_evento_predecir = pd.merge(cant_por_evento, df_persons, on=\"person\", how=\"inner\")\n",
    "cant_por_evento_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = df_train.iloc[:,:-1],df_train.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, scale_pos_weight = 10, min_child_weight=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=6,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=10, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)\n",
    "proba = xg_reg.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8537763183310798\n",
      "Test acuracy:  0.8503734226113829\n",
      "ROC auc score:  0.8260601668812715\n",
      "Confusion matrix: \n",
      "[[3198  494]\n",
      " [  87  104]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos que onda\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, proba)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cantidad de veces que realiza un evento dado en el mes 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>ad campaign hit mes 5</th>\n",
       "      <th>brand listing mes 5</th>\n",
       "      <th>checkout mes 5</th>\n",
       "      <th>conversion mes 5</th>\n",
       "      <th>generic listing mes 5</th>\n",
       "      <th>lead mes 5</th>\n",
       "      <th>search engine hit mes 5</th>\n",
       "      <th>searched products mes 5</th>\n",
       "      <th>staticpage mes 5</th>\n",
       "      <th>viewed product mes 5</th>\n",
       "      <th>visited site mes 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008ed71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091926</td>\n",
       "      <td>15.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>372.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000ba417</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000c79fe</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000e4d9e</td>\n",
       "      <td>19.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>339.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  ad campaign hit mes 5  brand listing mes 5  checkout mes 5  \\\n",
       "0  0008ed71                    0.0                  0.0             3.0   \n",
       "1  00091926                   15.0                 25.0             2.0   \n",
       "2  000ba417                    1.0                 24.0             6.0   \n",
       "3  000c79fe                    1.0                  0.0             1.0   \n",
       "4  000e4d9e                   19.0                 17.0             1.0   \n",
       "\n",
       "   conversion mes 5  generic listing mes 5  lead mes 5  \\\n",
       "0               0.0                    1.0         0.0   \n",
       "1               0.0                    0.0         0.0   \n",
       "2               1.0                   14.0         0.0   \n",
       "3               0.0                    1.0         0.0   \n",
       "4               0.0                   17.0         0.0   \n",
       "\n",
       "   search engine hit mes 5  searched products mes 5  staticpage mes 5  \\\n",
       "0                      0.0                      0.0               0.0   \n",
       "1                      0.0                      0.0               0.0   \n",
       "2                      1.0                      0.0               0.0   \n",
       "3                      1.0                      9.0               0.0   \n",
       "4                      5.0                      0.0               0.0   \n",
       "\n",
       "   viewed product mes 5  visited site mes 5  \n",
       "0                   0.0                 2.0  \n",
       "1                 372.0                34.0  \n",
       "2                 153.0                 6.0  \n",
       "3                   3.0                 1.0  \n",
       "4                 339.0                13.0  "
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eventos_mes_cinco = df.loc[df[\"month\"] == 5]\n",
    "cant_por_evento_mes_cinco = pd.concat([pd.get_dummies(eventos_mes_cinco['event']),eventos_mes_cinco[['person']]],axis = 1).groupby('person')\\\n",
    "    .sum().reset_index()\n",
    "\n",
    "cant_por_evento_mes_cinco.columns = ['person', 'ad campaign hit mes 5', 'brand listing mes 5', 'checkout mes 5',\\\n",
    "                                     'conversion mes 5', 'generic listing mes 5', 'lead mes 5', 'search engine hit mes 5',\\\n",
    "                                     'searched products mes 5', 'staticpage mes 5', 'viewed product mes 5', 'visited site mes 5' ]\n",
    "\n",
    "cant_por_evento_mes_cinco = pd.merge(cant_por_evento_mes_cinco, todas_las_personas, on=\"person\", how='right')\n",
    "\n",
    "df_train = pd.merge(cant_por_evento_mes_cinco, labels, on=\"person\", how=\"inner\")\\\n",
    "            .drop(columns = ['person', 'viewed product mes 5', 'visited site mes 5', 'staticpage mes 5', 'lead mes 5'])\n",
    "cant_por_evento_mes_cinco.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combino = pd.merge(cant_por_evento_mes_cinco, cant_por_evento, on='person', how='inner')\n",
    "\n",
    "df_train = pd.merge(df_combino, labels, on=\"person\", how=\"inner\")\\\n",
    "            .drop(columns = ['person','viewed product', 'visited site', 'staticpage', 'lead', 'viewed product',\\\n",
    "                             'visited site', 'staticpage mes 5', 'lead mes 5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#veo cuantos users pierdo\n",
    "cant_por_evento_predecir = pd.merge(cant_por_evento_mes_cinco, df_persons, on=\"person\", how=\"inner\")\n",
    "cant_por_evento_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ad campaign hit mes 5</th>\n",
       "      <th>brand listing mes 5</th>\n",
       "      <th>checkout mes 5</th>\n",
       "      <th>conversion mes 5</th>\n",
       "      <th>generic listing mes 5</th>\n",
       "      <th>search engine hit mes 5</th>\n",
       "      <th>searched products mes 5</th>\n",
       "      <th>viewed product mes 5</th>\n",
       "      <th>visited site mes 5</th>\n",
       "      <th>ad campaign hit</th>\n",
       "      <th>brand listing</th>\n",
       "      <th>checkout</th>\n",
       "      <th>conversion</th>\n",
       "      <th>generic listing</th>\n",
       "      <th>search engine hit</th>\n",
       "      <th>searched products</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ad campaign hit mes 5  brand listing mes 5  checkout mes 5  \\\n",
       "0                    0.0                  0.0             3.0   \n",
       "1                    1.0                  0.0             1.0   \n",
       "2                    5.0                  0.0             1.0   \n",
       "3                   16.0                113.0             4.0   \n",
       "4                    0.0                  1.0             2.0   \n",
       "\n",
       "   conversion mes 5  generic listing mes 5  search engine hit mes 5  \\\n",
       "0               0.0                    1.0                      0.0   \n",
       "1               0.0                    1.0                      1.0   \n",
       "2               0.0                    4.0                      0.0   \n",
       "3               1.0                   13.0                      7.0   \n",
       "4               1.0                    1.0                      0.0   \n",
       "\n",
       "   searched products mes 5  viewed product mes 5  visited site mes 5  \\\n",
       "0                      0.0                   0.0                 2.0   \n",
       "1                      9.0                   3.0                 1.0   \n",
       "2                      4.0                   4.0                 1.0   \n",
       "3                      1.0                 123.0                12.0   \n",
       "4                      0.0                   2.0                 0.0   \n",
       "\n",
       "   ad campaign hit  brand listing  checkout  conversion  generic listing  \\\n",
       "0              0.0            0.0       3.0         0.0              1.0   \n",
       "1              1.0            0.0       1.0         0.0              1.0   \n",
       "2              5.0            0.0       1.0         0.0              4.0   \n",
       "3             29.0          165.0      15.0         2.0             28.0   \n",
       "4              0.0            1.0       2.0         1.0              1.0   \n",
       "\n",
       "   search engine hit  searched products  label  \n",
       "0                0.0                0.0      0  \n",
       "1                1.0                9.0      0  \n",
       "2                0.0                4.0      0  \n",
       "3               13.0               11.0      0  \n",
       "4                0.0                0.0      0  "
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = df_train.iloc[:,:-1],df_train.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, scale_pos_weight = 5, min_child_weight=17)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=17, missing=None, n_estimators=6,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=5, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)\n",
    "proba = xg_reg.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.9083124074431782\n",
      "Test acuracy:  0.8956992016482102\n",
      "ROC auc score:  0.8517455322306225\n",
      "Confusion matrix: \n",
      "[[3391  279]\n",
      " [ 126   87]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos que onda\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, proba)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cantidad de eventos en un dia del mes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_day = pd.concat([df['person'],pd.get_dummies(df['day'])],axis = 1).groupby('person').sum().\\\n",
    "    reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas = ['dia_' + str(i) for i in range(1,32)]\n",
    "columnas.insert(0,'person')\n",
    "df_day.columns = columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_con_dias_del_mes = pd.merge(df_combino, df_day, on='person', how='inner')\n",
    "\n",
    "df_train = pd.merge(df_con_dias_del_mes, labels, on=\"person\", how=\"inner\")\\\n",
    "            .drop(columns = ['person','viewed product', 'visited site', 'staticpage', 'lead', 'viewed product',\\\n",
    "                             'visited site', 'staticpage mes 5', 'lead mes 5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = df_train.iloc[:,:-1],df_train.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, scale_pos_weight = 5, min_child_weight=17)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=17, missing=None, n_estimators=6,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=5, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)\n",
    "proba = xg_reg.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.9057369132702338\n",
      "Test acuracy:  0.8969868658253928\n",
      "ROC auc score:  0.8561512581392077\n",
      "Confusion matrix: \n",
      "[[3395  275]\n",
      " [ 125   88]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos que onda\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, proba)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cantidad de eventos en top K semanas del año."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 10\n",
    "df['week_of_year'] = df['timestamp'].dt.weekofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_week_of_year = df[['person','week_of_year']]\n",
    "\n",
    "top_K_week_of_year = df_week_of_year['week_of_year'].value_counts().head(K).index\n",
    "\n",
    "df_week_of_year = pd.concat([df_week_of_year,pd.get_dummies(df_week_of_year['week_of_year'])[top_K_week_of_year]],axis = 1)\n",
    "\n",
    "df_week_of_year.drop(columns = ['week_of_year'],inplace = True)\n",
    "\n",
    "df_week_of_year1 = df_week_of_year.groupby('person').sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_con_top_semanas = pd.merge(df_con_dias_del_mes, df_week_of_year1, on='person', how='inner')\n",
    "\n",
    "df_train = pd.merge(df_con_top_semanas, labels, on=\"person\", how=\"inner\")\\\n",
    "            .drop(columns = ['person','viewed product', 'visited site', 'staticpage', 'lead', 'viewed product',\\\n",
    "                             'visited site', 'staticpage mes 5', 'lead mes 5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ad campaign hit mes 5</th>\n",
       "      <th>brand listing mes 5</th>\n",
       "      <th>checkout mes 5</th>\n",
       "      <th>conversion mes 5</th>\n",
       "      <th>generic listing mes 5</th>\n",
       "      <th>search engine hit mes 5</th>\n",
       "      <th>searched products mes 5</th>\n",
       "      <th>viewed product mes 5</th>\n",
       "      <th>visited site mes 5</th>\n",
       "      <th>ad campaign hit</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>22</th>\n",
       "      <th>19</th>\n",
       "      <th>18</th>\n",
       "      <th>17</th>\n",
       "      <th>16</th>\n",
       "      <th>15</th>\n",
       "      <th>14</th>\n",
       "      <th>13</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ad campaign hit mes 5  brand listing mes 5  checkout mes 5  \\\n",
       "0                    0.0                  0.0             3.0   \n",
       "1                    1.0                  0.0             1.0   \n",
       "2                    5.0                  0.0             1.0   \n",
       "3                   16.0                113.0             4.0   \n",
       "4                    0.0                  1.0             2.0   \n",
       "\n",
       "   conversion mes 5  generic listing mes 5  search engine hit mes 5  \\\n",
       "0               0.0                    1.0                      0.0   \n",
       "1               0.0                    1.0                      1.0   \n",
       "2               0.0                    4.0                      0.0   \n",
       "3               1.0                   13.0                      7.0   \n",
       "4               1.0                    1.0                      0.0   \n",
       "\n",
       "   searched products mes 5  viewed product mes 5  visited site mes 5  \\\n",
       "0                      0.0                   0.0                 2.0   \n",
       "1                      9.0                   3.0                 1.0   \n",
       "2                      4.0                   4.0                 1.0   \n",
       "3                      1.0                 123.0                12.0   \n",
       "4                      0.0                   2.0                 0.0   \n",
       "\n",
       "   ad campaign hit  ...       20    22   19     18   17   16   15   14   13  \\\n",
       "0              0.0  ...      6.0   0.0  0.0    0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1              1.0  ...      0.0  17.0  0.0    0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2              5.0  ...      0.0  19.0  0.0    0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3             29.0  ...    181.0   0.0  0.0  108.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4              0.0  ...      0.0   0.0  0.0    0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = df_train.iloc[:,:-1],df_train.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, scale_pos_weight = 5, min_child_weight=17)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=17, missing=None, n_estimators=6,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=5, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)\n",
    "proba = xg_reg.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.9067671109394115\n",
      "Test acuracy:  0.8954416688127737\n",
      "ROC auc score:  0.8574055596065037\n",
      "Confusion matrix: \n",
      "[[3389  281]\n",
      " [ 125   88]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos que onda\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, proba)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.9067671109394115\n",
      "Test acuracy:  0.8954416688127737\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94      3670\n",
      "           1       0.24      0.41      0.30       213\n",
      "\n",
      "   micro avg       0.90      0.90      0.90      3883\n",
      "   macro avg       0.60      0.67      0.62      3883\n",
      "weighted avg       0.92      0.90      0.91      3883\n",
      "\n",
      "\n",
      "Precision Score:  0.23848238482384823\n",
      "Recall Score:  0.4131455399061033\n",
      "F1 Score:  0.3024054982817869\n",
      "Cohen Kappa Score:  0.25025490889860336\n",
      "ROC auc score:  0.8574055596065037\n",
      "Confusion matrix: \n",
      "[[3389  281]\n",
      " [ 125   88]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\\\n",
    "                            f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "# Pruebo todas las metricas.\n",
    "# accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\n",
    "# f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "\n",
    "trainAccuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "testAccuracy = accuracy_score(y_test, preds)\n",
    "\n",
    "meanSquaredError = mean_squared_error(y_test, preds)\n",
    "classificationReport = classification_report(y_test, preds)\n",
    "precisionScore = precision_score(y_test, preds)\n",
    "recallScore = recall_score(y_test, preds)\n",
    "f1Score = f1_score(y_test, preds)\n",
    "cohenKappaScore = cohen_kappa_score(y_test, preds)\n",
    "areaDebajoDeCurva = roc_auc_score(y_test, proba)\n",
    "matrizDeConfusion = confusion_matrix(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", trainAccuracy)\n",
    "print(\"Test acuracy: \", testAccuracy)\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(classificationReport)\n",
    "print()\n",
    "print(\"Precision Score: \",precisionScore)\n",
    "print(\"Recall Score: \",recallScore)\n",
    "print(\"F1 Score: \",f1Score)\n",
    "print(\"Cohen Kappa Score: \",cohenKappaScore)\n",
    "print(\"ROC auc score: \", areaDebajoDeCurva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matrizDeConfusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usando random oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = df_train.iloc[:,:-1].fillna(0), df_train.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "#data_dmatrix = xgb.DMatrix(data=X,label=y, weight={1: 1, 0: 0.1})\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14764, 767)"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cant_ceros = np.sum(y_train == 0)\n",
    "cant_unos = np.sum(y_train == 1)\n",
    "cant_ceros, cant_unos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.any(np.isnan(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(np.isfinite(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(random_state=2, sampling_strategy = {0: 14764, 1: 1200})\n",
    "X_train_res, y_train_res = ros.fit_sample(X_train, y_train)\n",
    "X_train_res_df = pd.DataFrame(X_train_res)\n",
    "X_train_res_df.columns = X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6,eval_metric = \"auc\", scale_pos_weight=5, min_child_weight=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=1, missing=None,\n",
       "       n_estimators=6, n_jobs=1, nthread=None, objective='binary:logistic',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=5,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train_res_df ,y_train_res.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)\n",
    "proba = xg_reg.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8484715610122776\n",
      "Test acuracy:  0.8411022405356683\n",
      "ROC auc score:  0.8582332322728377\n",
      "Confusion matrix: \n",
      "[[3127  543]\n",
      " [  74  139]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos \n",
    "train_accuracy = accuracy_score(y_train_res, xg_reg.predict(X_train_res_df))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, proba)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8484715610122776\n",
      "Test acuracy:  0.8411022405356683\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.85      0.91      3670\n",
      "           1       0.20      0.65      0.31       213\n",
      "\n",
      "   micro avg       0.84      0.84      0.84      3883\n",
      "   macro avg       0.59      0.75      0.61      3883\n",
      "weighted avg       0.93      0.84      0.88      3883\n",
      "\n",
      "\n",
      "Precision Score:  0.20381231671554254\n",
      "Recall Score:  0.6525821596244131\n",
      "F1 Score:  0.3106145251396648\n",
      "Cohen Kappa Score:  0.24772470580921035\n",
      "ROC auc score:  0.8582332322728377\n",
      "Confusion matrix: \n",
      "[[3127  543]\n",
      " [  74  139]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\\\n",
    "                            f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "# Pruebo todas las metricas.\n",
    "# accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\n",
    "# f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "\n",
    "trainAccuracy = accuracy_score(y_train_res, xg_reg.predict(X_train_res_df))\n",
    "testAccuracy = accuracy_score(y_test, preds)\n",
    "\n",
    "meanSquaredError = mean_squared_error(y_test, preds)\n",
    "classificationReport = classification_report(y_test, preds)\n",
    "precisionScore = precision_score(y_test, preds)\n",
    "recallScore = recall_score(y_test, preds)\n",
    "f1Score = f1_score(y_test, preds)\n",
    "cohenKappaScore = cohen_kappa_score(y_test, preds)\n",
    "areaDebajoDeCurva = roc_auc_score(y_test, proba)\n",
    "matrizDeConfusion = confusion_matrix(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", trainAccuracy)\n",
    "print(\"Test acuracy: \", testAccuracy)\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(classificationReport)\n",
    "print()\n",
    "print(\"Precision Score: \",precisionScore)\n",
    "print(\"Recall Score: \",recallScore)\n",
    "print(\"F1 Score: \",f1Score)\n",
    "print(\"Cohen Kappa Score: \",cohenKappaScore)\n",
    "print(\"ROC auc score: \", areaDebajoDeCurva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matrizDeConfusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entradas en el mes cinco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>cant_mes_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008ed71</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091926</td>\n",
       "      <td>448.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000ba417</td>\n",
       "      <td>206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000c79fe</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000e4d9e</td>\n",
       "      <td>411.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  cant_mes_5\n",
       "0  0008ed71         6.0\n",
       "1  00091926       448.0\n",
       "2  000ba417       206.0\n",
       "3  000c79fe        17.0\n",
       "4  000e4d9e       411.0"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entradas_mes_5 = df.loc[df[\"month\"] == 5]\n",
    "cant_entradas_mes_5 = entradas_mes_5.groupby(\"person\").agg({\"month\": \"count\"}).reset_index()\n",
    "cant_entradas_mes_5.columns = [\"person\", \"cant_mes_5\"]\n",
    "cant_entradas_mes_5 = pd.merge(cant_entradas_mes_5, todas_las_personas, on=\"person\", how=\"right\").fillna(0)\n",
    "cant_entradas_mes_5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge\n",
    "\n",
    "df_con_mes_5 = pd.merge(cant_entradas_mes_5, cant_por_evento, on=\"person\", how=\"inner\")\n",
    "df_train = pd.merge(df_con_mes_5, labels, on=\"person\", how=\"inner\")\\\n",
    "            .drop(columns = ['person', 'viewed product', 'visited site', 'staticpage', 'lead'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veo cuantas personas a predecir pierdo\n",
    "entradas_mes_5_predecir = pd.merge(cant_entradas_mes_5, df_persons, on=\"person\", how=\"inner\")\n",
    "entradas_mes_5_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = df_train.iloc[:,:-1],df_train.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, scale_pos_weight = 10, min_child_weight=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=6,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=10, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)\n",
    "proba = xg_reg.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8771634453498552\n",
      "Test acuracy:  0.8569889577161325\n",
      "ROC auc score:  0.8233341063353461\n",
      "Confusion matrix: \n",
      "[[3084  438]\n",
      " [  93   98]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos que onda\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, proba)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distancia en dias de 1er y ultimo dia de entrada al sitio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>distan_dias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008ed71</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091926</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00091a7a</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000ba417</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000c79fe</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  distan_dias\n",
       "0  0008ed71            0\n",
       "1  00091926           27\n",
       "2  00091a7a            0\n",
       "3  000ba417            9\n",
       "4  000c79fe            0"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamp_df = df[[\"person\", \"timestamp\"]]\n",
    "ultimo_dia = timestamp_df.groupby(\"person\")[\"timestamp\"].max().rename(\"ultimo\").reset_index()\n",
    "primer_dia = timestamp_df.groupby(\"person\")[\"timestamp\"].min().rename(\"primer\").reset_index()\n",
    "distancia_dias = pd.merge(primer_dia, ultimo_dia, on=\"person\", how=\"inner\")\n",
    "distancia_dias[\"distan_dias\"] = (distancia_dias[\"ultimo\"] - distancia_dias[\"primer\"]).dt.days\n",
    "distancia_dias = distancia_dias[[\"person\", \"distan_dias\"]]\n",
    "distancia_dias.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Merge\n",
    "#df_con_mes_5\n",
    "df_con_distancias = pd.merge(distancia_dias, df_con_top_semanas, on=\"person\", how=\"inner\") \n",
    "df_train = pd.merge(df_con_distancias, labels, on=\"person\", how=\"inner\")\\\n",
    "            .drop(columns = ['person','viewed product', 'visited site', 'staticpage', 'lead', 'viewed product',\\\n",
    "                             'visited site', 'staticpage mes 5', 'lead mes 5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 597,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veo cuantas personas a predecir pierdo\n",
    "distancia_dias_predecir = pd.merge(distancia_dias, df_persons, on=\"person\", how=\"inner\")\n",
    "distancia_dias_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = df_train.iloc[:,:-1],df_train.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, scale_pos_weight = 7, min_child_weight=17)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=17, missing=None, n_estimators=6,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=7, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 606,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)\n",
    "proba = xg_reg.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8548065160002576\n",
      "Test acuracy:  0.8532062838011847\n",
      "ROC auc score:  0.8468962182276099\n",
      "Confusion matrix: \n",
      "[[3196  496]\n",
      " [  74  117]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos que onda\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, proba)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cantidad de modelos distintos vistos por cada usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>modelos_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008ed71</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091926</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00091a7a</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000ba417</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000c79fe</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  modelos_dist\n",
       "0  0008ed71             3\n",
       "1  00091926            36\n",
       "2  00091a7a             3\n",
       "3  000ba417            26\n",
       "4  000c79fe             1"
      ]
     },
     "execution_count": 545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelos_df = df[[\"person\", \"model\"]]\n",
    "cant_modelos = modelos_df.groupby(\"person\")[\"model\"].nunique().rename(\"modelos_dist\").reset_index()\n",
    "cant_modelos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge \n",
    "#df_con_distancias\n",
    "df_con_modelos = pd.merge(df_con_top_semanas, cant_modelos, on=\"person\", how=\"inner\") \n",
    "df_train = pd.merge(df_con_modelos, labels, on=\"person\", how=\"inner\")\\\n",
    "            .drop(columns = ['person','viewed product', 'visited site', 'staticpage', 'lead', 'viewed product',\\\n",
    "                             'visited site', 'staticpage mes 5', 'lead mes 5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 610,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veo cuantas personas a predecir pierdo\n",
    "cant_modelos_predecir = pd.merge(cant_modelos, df_persons, on=\"person\", how=\"inner\")\n",
    "cant_modelos_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = df_train.iloc[:,:-1],df_train.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, scale_pos_weight = 7, min_child_weight=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=6,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=7, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 615,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)\n",
    "proba = xg_reg.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.882042366879145\n",
      "Test acuracy:  0.8720061807880505\n",
      "ROC auc score:  0.8561429430351409\n",
      "Confusion matrix: \n",
      "[[3275  395]\n",
      " [ 102  111]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos que onda\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, proba)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cantidad de días distintos de entrada al sitio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seba\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>cant_dias_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008ed71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091926</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00091a7a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000ba417</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000c79fe</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  cant_dias_dist\n",
       "0  0008ed71               1\n",
       "1  00091926              22\n",
       "2  00091a7a               1\n",
       "3  000ba417               3\n",
       "4  000c79fe               1"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dias = df[[\"person\", \"timestamp\"]]\n",
    "df_dias[\"day_of_year\"] = df_dias[\"timestamp\"].dt.dayofyear\n",
    "cant_dias_dist = df_dias.groupby(\"person\")[\"day_of_year\"].nunique().rename(\"cant_dias_dist\").reset_index()\n",
    "cant_dias_dist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([  'ad campaign hit mes 5',     'brand listing mes 5',\n",
       "                'checkout mes 5',        'conversion mes 5',\n",
       "         'generic listing mes 5', 'search engine hit mes 5',\n",
       "       'searched products mes 5',    'viewed product mes 5',\n",
       "            'visited site mes 5',         'ad campaign hit',\n",
       "                 'brand listing',                'checkout',\n",
       "                    'conversion',         'generic listing',\n",
       "             'search engine hit',       'searched products',\n",
       "                         'dia_1',                   'dia_2',\n",
       "                         'dia_3',                   'dia_4',\n",
       "                         'dia_5',                   'dia_6',\n",
       "                         'dia_7',                   'dia_8',\n",
       "                         'dia_9',                  'dia_10',\n",
       "                        'dia_11',                  'dia_12',\n",
       "                        'dia_13',                  'dia_14',\n",
       "                        'dia_15',                  'dia_16',\n",
       "                        'dia_17',                  'dia_18',\n",
       "                        'dia_19',                  'dia_20',\n",
       "                        'dia_21',                  'dia_22',\n",
       "                        'dia_23',                  'dia_24',\n",
       "                        'dia_25',                  'dia_26',\n",
       "                        'dia_27',                  'dia_28',\n",
       "                        'dia_29',                  'dia_30',\n",
       "                        'dia_31',                        21,\n",
       "                              20,                        22,\n",
       "                              19,                        18,\n",
       "                              17,                        16,\n",
       "                              15,                        14,\n",
       "                              13,          'cant_dias_dist',\n",
       "                         'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 637,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge df_con_modelos\n",
    "\n",
    "df_con_dias_dist = pd.merge(df_con_top_semanas, cant_dias_dist, on=\"person\", how=\"inner\") \n",
    "df_train = pd.merge(df_con_dias_dist, labels, on=\"person\", how=\"inner\")\\\n",
    "            .drop(columns = ['person','viewed product', 'visited site', 'staticpage', 'lead', 'viewed product',\\\n",
    "                             'visited site', 'staticpage mes 5', 'lead mes 5'])\n",
    "\n",
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 619,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veo cuantas personas a predecir pierdo\n",
    "cant_dias_dist_predecir = pd.merge(cant_dias_dist, df_persons, on=\"person\", how=\"inner\")\n",
    "cant_dias_dist_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = df_train.iloc[:,:-1],df_train.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 622,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 623,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, scale_pos_weight = 7, min_child_weight=17)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 624,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=17, missing=None, n_estimators=6,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=7, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 624,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 625,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)\n",
    "proba = xg_reg.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8837164380915589\n",
      "Test acuracy:  0.8689157867628122\n",
      "ROC auc score:  0.854903352905809\n",
      "Confusion matrix: \n",
      "[[3266  404]\n",
      " [ 105  108]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos que onda\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, proba)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entro como 'new' en el mes 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>nuevo_mes_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c0f2beb1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9ff9d5d2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ae9e5fa3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bbbe368d</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0b7a3edd</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  nuevo_mes_5\n",
       "0  c0f2beb1          1.0\n",
       "1  9ff9d5d2          1.0\n",
       "2  ae9e5fa3          1.0\n",
       "3  bbbe368d          1.0\n",
       "4  0b7a3edd          1.0"
      ]
     },
     "execution_count": 653,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mes_5 = df[[\"person\", \"month\", \"new_vs_returning\"]].loc[df[\"month\"] == 5]\n",
    "df_mes_5[\"nuevo_mes_5\"] = (df_mes_5[\"new_vs_returning\"] == \"New\") * 1\n",
    "df_mew_5 = df_mes_5[[\"person\", \"nuevo_mes_5\"]]\n",
    "df_mew_5 = df_mew_5.sort_values(\"nuevo_mes_5\", ascending=False)\n",
    "df_mew_5 = df_mew_5.drop_duplicates(subset=['person'], keep='first')\n",
    "df_mew_5 = pd.merge(df_mew_5, todas_las_personas, on=\"person\", how=\"right\").fillna(0)\n",
    "df_mew_5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 654,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veo cuantas personas a predecir pierdo\n",
    "df_mew_5_predecir = pd.merge(df_mew_5, df_persons, on=\"person\", how=\"inner\")\n",
    "df_mew_5_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    14789\n",
       "0.0     4625\n",
       "Name: nuevo_mes_5, dtype: int64"
      ]
     },
     "execution_count": 655,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge\n",
    "\n",
    "df_con_new_mes5 = pd.merge(df_con_top_semanas, df_mew_5, on=\"person\", how=\"inner\") \n",
    "df_train = pd.merge(df_con_new_mes5, labels, on=\"person\", how=\"inner\")\\\n",
    "            .drop(columns = ['person','viewed product', 'visited site', 'staticpage', 'lead', 'viewed product',\\\n",
    "                             'visited site', 'staticpage mes 5', 'lead mes 5'])\n",
    "df_train['nuevo_mes_5'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 656,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = df_train.iloc[:,:-1],df_train.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, scale_pos_weight = 7, min_child_weight=17)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=17, missing=None, n_estimators=6,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=7, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 668,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)\n",
    "proba = xg_reg.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8863563196188269\n",
      "Test acuracy:  0.8714911151171775\n",
      "ROC auc score:  0.8565925982781337\n",
      "Confusion matrix: \n",
      "[[3274  396]\n",
      " [ 103  110]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos que onda\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, proba)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visitas a la pagina segun resolucion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>1024x768</th>\n",
       "      <th>1360x768</th>\n",
       "      <th>1366x768</th>\n",
       "      <th>1440x900</th>\n",
       "      <th>1600x900</th>\n",
       "      <th>1920x1080</th>\n",
       "      <th>320x534</th>\n",
       "      <th>320x568</th>\n",
       "      <th>320x570</th>\n",
       "      <th>360x640</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008ed71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091926</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00091a7a</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000ba417</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000c79fe</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  1024x768  1360x768  1366x768  1440x900  1600x900  1920x1080  \\\n",
       "0  0008ed71       0.0       0.0       0.0       0.0       0.0        2.0   \n",
       "1  00091926      34.0       0.0       0.0       0.0       0.0        0.0   \n",
       "2  00091a7a       0.0       0.0       0.0       0.0       0.0        0.0   \n",
       "3  000ba417       6.0       0.0       0.0       0.0       0.0        0.0   \n",
       "4  000c79fe       0.0       0.0       0.0       0.0       0.0        0.0   \n",
       "\n",
       "   320x534  320x568  320x570  360x640  \n",
       "0      0.0      0.0      0.0      0.0  \n",
       "1      0.0      0.0      0.0      0.0  \n",
       "2      0.0      0.0      0.0      1.0  \n",
       "3      0.0      0.0      0.0      0.0  \n",
       "4      0.0      0.0      0.0      1.0  "
      ]
     },
     "execution_count": 671,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resolucion = df.loc[df['event'] == 'visited site']\n",
    "df_resolucion = df_resolucion[['person','screen_resolution']].dropna()\n",
    "\n",
    "top_5_resoluciones = df_resolucion['screen_resolution'].value_counts().head(10).index\n",
    "df_resolucion = df_resolucion.loc[df_resolucion['screen_resolution'].isin(top_5_resoluciones)]\n",
    "df_resolucion = pd.concat([df_resolucion['person'],\\\n",
    "        pd.get_dummies(df_resolucion['screen_resolution'])],axis = 1).groupby('person').sum().reset_index()\n",
    "\n",
    "df_resolucion = pd.merge(df_resolucion, todas_las_personas, on=\"person\", how=\"right\").fillna(0)\n",
    "\n",
    "df_resolucion.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creo que es mucho 20 resoluciones, probar (quizas empeore).."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 673,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veo cuantas personas a predecir pierdo\n",
    "df_resolucion_predecir = pd.merge(df_resolucion, df_persons, on=\"person\", how=\"inner\")\n",
    "df_resolucion_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge\n",
    "\n",
    "df_con_resoluciones = pd.merge(df_con_top_semanas, df_resolucion, on=\"person\", how=\"inner\") \n",
    "df_train = pd.merge(df_con_resoluciones, labels, on=\"person\", how=\"inner\")\\\n",
    "            .drop(columns = ['person','viewed product', 'visited site', 'staticpage', 'lead', 'viewed product',\\\n",
    "                             'visited site', 'staticpage mes 5', 'lead mes 5'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = df_train.iloc[:,:-1],df_train.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, scale_pos_weight = 5, min_child_weight=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=12, missing=None, n_estimators=6,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=5, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 716,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)\n",
    "proba = xg_reg.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.9311055308737364\n",
      "Test acuracy:  0.9175894926603142\n",
      "ROC auc score:  0.8584545419656907\n",
      "Confusion matrix: \n",
      "[[3500  170]\n",
      " [ 150   63]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos que onda\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, proba)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usando random oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = df_train.iloc[:,:-1].fillna(0), df_train.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "#data_dmatrix = xgb.DMatrix(data=X,label=y, weight={1: 1, 0: 0.1})\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14764, 767)"
      ]
     },
     "execution_count": 720,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cant_ceros = np.sum(y_train == 0)\n",
    "cant_unos = np.sum(y_train == 1)\n",
    "cant_ceros, cant_unos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 721,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.any(np.isnan(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 722,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(np.isfinite(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(random_state=2, sampling_strategy = {0: 14764, 1: 1200})\n",
    "X_train_res, y_train_res = ros.fit_sample(X_train, y_train)\n",
    "X_train_res_df = pd.DataFrame(X_train_res)\n",
    "X_train_res_df.columns = X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6,eval_metric = \"auc\", scale_pos_weight=5, min_child_weight=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=20, missing=None,\n",
       "       n_estimators=6, n_jobs=1, nthread=None, objective='binary:logistic',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=5,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 752,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train_res_df ,y_train_res.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)\n",
    "proba = xg_reg.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8737158606865447\n",
      "Test acuracy:  0.871233582281741\n",
      "ROC auc score:  0.860972739251129\n",
      "Confusion matrix: \n",
      "[[3260  410]\n",
      " [  90  123]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos \n",
    "train_accuracy = accuracy_score(y_train_res, xg_reg.predict(X_train_res_df))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, proba)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8737158606865447\n",
      "Test acuracy:  0.871233582281741\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.89      0.93      3670\n",
      "           1       0.23      0.58      0.33       213\n",
      "\n",
      "   micro avg       0.87      0.87      0.87      3883\n",
      "   macro avg       0.60      0.73      0.63      3883\n",
      "weighted avg       0.93      0.87      0.90      3883\n",
      "\n",
      "\n",
      "Precision Score:  0.23076923076923078\n",
      "Recall Score:  0.5774647887323944\n",
      "F1 Score:  0.3297587131367293\n",
      "Cohen Kappa Score:  0.2727538338215353\n",
      "ROC auc score:  0.860972739251129\n",
      "Confusion matrix: \n",
      "[[3260  410]\n",
      " [  90  123]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\\\n",
    "                            f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "# Pruebo todas las metricas.\n",
    "# accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\n",
    "# f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "\n",
    "trainAccuracy = accuracy_score(y_train_res, xg_reg.predict(X_train_res_df))\n",
    "testAccuracy = accuracy_score(y_test, preds)\n",
    "\n",
    "meanSquaredError = mean_squared_error(y_test, preds)\n",
    "classificationReport = classification_report(y_test, preds)\n",
    "precisionScore = precision_score(y_test, preds)\n",
    "recallScore = recall_score(y_test, preds)\n",
    "f1Score = f1_score(y_test, preds)\n",
    "cohenKappaScore = cohen_kappa_score(y_test, preds)\n",
    "areaDebajoDeCurva = roc_auc_score(y_test, proba)\n",
    "matrizDeConfusion = confusion_matrix(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", trainAccuracy)\n",
    "print(\"Test acuracy: \", testAccuracy)\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(classificationReport)\n",
    "print()\n",
    "print(\"Precision Score: \",precisionScore)\n",
    "print(\"Recall Score: \",recallScore)\n",
    "print(\"F1 Score: \",f1Score)\n",
    "print(\"Cohen Kappa Score: \",cohenKappaScore)\n",
    "print(\"ROC auc score: \", areaDebajoDeCurva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matrizDeConfusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OCHENTA Y SEIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dia, mes con mayor cantidad de visitas de cada persona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>day</th>\n",
       "      <th>cant_dia_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99325</th>\n",
       "      <td>c76b8417</td>\n",
       "      <td>3</td>\n",
       "      <td>652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28266</th>\n",
       "      <td>37eff05b</td>\n",
       "      <td>29</td>\n",
       "      <td>616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112559</th>\n",
       "      <td>e1443dd4</td>\n",
       "      <td>30</td>\n",
       "      <td>572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51164</th>\n",
       "      <td>656c18ef</td>\n",
       "      <td>10</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41082</th>\n",
       "      <td>50e16a8a</td>\n",
       "      <td>19</td>\n",
       "      <td>423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          person  day  cant_dia_freq\n",
       "99325   c76b8417    3            652\n",
       "28266   37eff05b   29            616\n",
       "112559  e1443dd4   30            572\n",
       "51164   656c18ef   10            512\n",
       "41082   50e16a8a   19            423"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dia con mas entradas y su cantidad de entradas\n",
    "\n",
    "entradas_x_dia = df.groupby(\"person\")['day'].value_counts().rename(\"cant_dia_freq\").reset_index()\n",
    "entradas_x_dia.columns = ['person', 'day', 'cant_dia_freq']\n",
    "entradas_x_dia = entradas_x_dia.sort_values('cant_dia_freq',ascending=False)\n",
    "dia_mas_entradas = entradas_x_dia.drop_duplicates(subset=['person'])\n",
    "dia_mas_entradas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>month</th>\n",
       "      <th>cant_mes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38966</th>\n",
       "      <td>c76b8417</td>\n",
       "      <td>5</td>\n",
       "      <td>3028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18217</th>\n",
       "      <td>5c76e694</td>\n",
       "      <td>5</td>\n",
       "      <td>1609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32890</th>\n",
       "      <td>a7ffa917</td>\n",
       "      <td>5</td>\n",
       "      <td>1604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4824</th>\n",
       "      <td>18489dd5</td>\n",
       "      <td>5</td>\n",
       "      <td>1563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9989</th>\n",
       "      <td>33385551</td>\n",
       "      <td>4</td>\n",
       "      <td>1539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         person  month  cant_mes\n",
       "38966  c76b8417      5      3028\n",
       "18217  5c76e694      5      1609\n",
       "32890  a7ffa917      5      1604\n",
       "4824   18489dd5      5      1563\n",
       "9989   33385551      4      1539"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mes con mas entradas y su cantidad de entradas\n",
    "\n",
    "entradas_x_mes = df.groupby(\"person\")['month'].value_counts().rename(\"cant_mes\").reset_index()\n",
    "entradas_x_mes.columns = ['person', 'month', 'cant_mes']\n",
    "entradas_x_mes = entradas_x_mes.sort_values('cant_mes',ascending=False)\n",
    "mes_mas_entradas = entradas_x_mes.drop_duplicates(subset=['person'])\n",
    "mes_mas_entradas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>cant_mes</th>\n",
       "      <th>cant_dia_freq</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5c76e694</td>\n",
       "      <td>1609</td>\n",
       "      <td>191</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18489dd5</td>\n",
       "      <td>1563</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1775ba85</td>\n",
       "      <td>1450</td>\n",
       "      <td>126</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6abd2bf1</td>\n",
       "      <td>1334</td>\n",
       "      <td>300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>97b0c0d1</td>\n",
       "      <td>1328</td>\n",
       "      <td>217</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  cant_mes  cant_dia_freq  label\n",
       "0  5c76e694      1609            191      0\n",
       "1  18489dd5      1563            174      0\n",
       "2  1775ba85      1450            126      0\n",
       "3  6abd2bf1      1334            300      0\n",
       "4  97b0c0d1      1328            217      0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge\n",
    "\n",
    "cant_mes_mas_entradas = mes_mas_entradas[[\"person\", \"cant_mes\"]]\n",
    "cant_dia_mas_entradas = dia_mas_entradas[[\"person\", \"cant_dia_freq\"]]\n",
    "\n",
    "mes_dia_mas_entradas = pd.merge(cant_mes_mas_entradas, cant_dia_mas_entradas, on=\"person\", how=\"inner\")\n",
    "\n",
    "df_con_labels = pd.merge(mes_dia_mas_entradas, labels, on=\"person\", how=\"inner\")\n",
    "df_con_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mes_dia_mas_entradas_predecir = pd.merge(mes_dia_mas_entradas, df_persons, on=\"person\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mes_dia_mas_entradas_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_con_labels_num = df_con_labels[[\"cant_mes\", \"cant_dia_freq\", \"label\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = df_con_labels_num.iloc[:,:-1],df_con_labels_num.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:logistic', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, scale_pos_weight = 7, min_child_weight=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=6,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=7, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.9475886935805807\n",
      "Test acuracy:  0.9443729075457121\n",
      "ROC auc score:  0.6264300612293363\n",
      "Confusion matrix: \n",
      "[[3660   12]\n",
      " [ 204    7]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos que onda\n",
    "\n",
    "#train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "#test_accuracy = accuracy_score(y_test, preds)\n",
    "#matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = df_con_labels_num.iloc[:,:-1],df_con_labels_num.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, y_train)\n",
    "dtest = xgb.DMatrix(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, scale_pos_weight = 7, min_child_weight=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=6,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=7, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "probabilidades = xg_reg.predict_proba(X_test)[:, 1]\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.9475886935805807\n",
      "Test acuracy:  0.9443729075457121\n",
      "ROC auc score:  0.6264300612293363\n",
      "Confusion matrix: \n",
      "[[3660   12]\n",
      " [ 204    7]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos que onda\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, probabilidades)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distancia entre ultima entrada al sitio y el ultimo dia del mes 5 que tenemos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 925,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>dias_hasta_ultimo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008ed71</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091926</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00091a7a</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000ba417</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000c79fe</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  dias_hasta_ultimo\n",
       "0  0008ed71                 14\n",
       "1  00091926                  0\n",
       "2  00091a7a                 66\n",
       "3  000ba417                  5\n",
       "4  000c79fe                  2"
      ]
     },
     "execution_count": 925,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamp_df = df[[\"person\", \"timestamp\"]]\n",
    "ultimo_dia_de_todos = timestamp_df[\"timestamp\"].max()\n",
    "ultima_entrada = timestamp_df.groupby(\"person\")[\"timestamp\"].max().rename(\"ultimo\").reset_index()\n",
    "ultima_entrada[\"dias_hasta_ultimo\"] = (ultimo_dia_de_todos - ultima_entrada[\"ultimo\"]).dt.days\n",
    "ultima_entrada = ultima_entrada[[\"person\", \"dias_hasta_ultimo\"]]\n",
    "ultima_entrada.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 926,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 926,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veo cuantas personas a predecir pierdo\n",
    "df_predecir = pd.merge(ultima_entrada, df_persons, on=\"person\", how=\"inner\")\n",
    "df_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1051,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge\n",
    "# df_con_resoluciones\n",
    "\n",
    "df_con_diatancia_hasta_ultimo = pd.merge(df_con_resoluciones, ultima_entrada, on=\"person\", how=\"inner\") \n",
    "df_train = pd.merge(df_con_diatancia_hasta_ultimo, labels, on=\"person\", how=\"inner\")\\\n",
    "            .drop(columns = ['person','viewed product', 'visited site', 'staticpage', 'lead', 'viewed product',\\\n",
    "                             'visited site', 'staticpage mes 5', 'lead mes 5'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1052,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = df_train.iloc[:,:-1],df_train.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1053,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1054,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1055,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, scale_pos_weight = 5, min_child_weight=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1056,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=12, missing=None, n_estimators=6,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=5, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 1056,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1057,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)\n",
    "proba = xg_reg.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1058,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.9307835941021183\n",
      "Test acuracy:  0.921452485191862\n",
      "ROC auc score:  0.8602141459108877\n",
      "Confusion matrix: \n",
      "[[3508  162]\n",
      " [ 143   70]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos que onda\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, proba)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usando random oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1060,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = df_train.iloc[:,:-1].fillna(0), df_train.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "#data_dmatrix = xgb.DMatrix(data=X,label=y, weight={1: 1, 0: 0.1})\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1061,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14764, 767)"
      ]
     },
     "execution_count": 1061,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cant_ceros = np.sum(y_train == 0)\n",
    "cant_unos = np.sum(y_train == 1)\n",
    "cant_ceros, cant_unos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1062,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(random_state=2, sampling_strategy = {0: 14764, 1: 784})\n",
    "X_train_res, y_train_res = ros.fit_sample(X_train, y_train)\n",
    "X_train_res_df = pd.DataFrame(X_train_res)\n",
    "X_train_res_df.columns = X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1063,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6,eval_metric = \"auc\", scale_pos_weight=5, min_child_weight=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1064,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=10, missing=None,\n",
       "       n_estimators=6, n_jobs=1, nthread=None, objective='binary:logistic',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=5,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 1064,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train_res_df ,y_train_res.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1065,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)\n",
    "proba = xg_reg.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1066,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.928222279392848\n",
      "Test acuracy:  0.9173319598248777\n",
      "ROC auc score:  0.8628461961597013\n",
      "Confusion matrix: \n",
      "[[3492  178]\n",
      " [ 143   70]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos \n",
    "train_accuracy = accuracy_score(y_train_res, xg_reg.predict(X_train_res_df))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, proba)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1067,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.928222279392848\n",
      "Test acuracy:  0.9173319598248777\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96      3670\n",
      "           1       0.28      0.33      0.30       213\n",
      "\n",
      "   micro avg       0.92      0.92      0.92      3883\n",
      "   macro avg       0.62      0.64      0.63      3883\n",
      "weighted avg       0.92      0.92      0.92      3883\n",
      "\n",
      "\n",
      "Precision Score:  0.28225806451612906\n",
      "Recall Score:  0.3286384976525822\n",
      "F1 Score:  0.3036876355748373\n",
      "Cohen Kappa Score:  0.2600143076379633\n",
      "ROC auc score:  0.8628461961597013\n",
      "Confusion matrix: \n",
      "[[3492  178]\n",
      " [ 143   70]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\\\n",
    "                            f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "# Pruebo todas las metricas.\n",
    "# accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\n",
    "# f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "\n",
    "trainAccuracy = accuracy_score(y_train_res, xg_reg.predict(X_train_res_df))\n",
    "testAccuracy = accuracy_score(y_test, preds)\n",
    "\n",
    "meanSquaredError = mean_squared_error(y_test, preds)\n",
    "classificationReport = classification_report(y_test, preds)\n",
    "precisionScore = precision_score(y_test, preds)\n",
    "recallScore = recall_score(y_test, preds)\n",
    "f1Score = f1_score(y_test, preds)\n",
    "cohenKappaScore = cohen_kappa_score(y_test, preds)\n",
    "areaDebajoDeCurva = roc_auc_score(y_test, proba)\n",
    "matrizDeConfusion = confusion_matrix(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", trainAccuracy)\n",
    "print(\"Test acuracy: \", testAccuracy)\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(classificationReport)\n",
    "print()\n",
    "print(\"Precision Score: \",precisionScore)\n",
    "print(\"Recall Score: \",recallScore)\n",
    "print(\"F1 Score: \",f1Score)\n",
    "print(\"Cohen Kappa Score: \",cohenKappaScore)\n",
    "print(\"ROC auc score: \", areaDebajoDeCurva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matrizDeConfusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cantidad de eventos segun quincena"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seba\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\seba\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "df_mes_cinco = df.loc[df[\"month\"] == 5]\n",
    "df_quincenas_mes_cinco = df_mes_cinco[['person','day']]\n",
    "\n",
    "df_quincenas_mes_cinco['primer_quincena'] = ((df_quincenas_mes_cinco['day'] >=1) & (df_quincenas_mes_cinco['day'] < 16)).astype(int)\n",
    "df_quincenas_mes_cinco['segunda_quincena'] = (df_quincenas_mes_cinco['day'] > 16).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>primer_quincena</th>\n",
       "      <th>segunda_quincena</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008ed71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091926</td>\n",
       "      <td>187.0</td>\n",
       "      <td>260.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000ba417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000c79fe</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000e4d9e</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  primer_quincena  segunda_quincena\n",
       "0  0008ed71              0.0               6.0\n",
       "1  00091926            187.0             260.0\n",
       "2  000ba417              0.0             206.0\n",
       "3  000c79fe              0.0              17.0\n",
       "4  000e4d9e              0.0             216.0"
      ]
     },
     "execution_count": 1111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_quincenas_mes_cinco = df_quincenas_mes_cinco.drop(columns = ['day'])\n",
    "\n",
    "df_quincenas_mes_cinco = df_quincenas_mes_cinco.groupby('person').sum().reset_index()\n",
    "\n",
    "# Pongo las personas que no entraron en el mes 5 en 0\n",
    "df_quincenas_mes_cinco = pd.merge(df_quincenas_mes_cinco, todas_las_personas, on='person', how='right').fillna(0)\n",
    "df_quincenas_mes_cinco.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1121,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_con_quincenas = pd.merge(df_con_diatancia_hasta_ultimo, df_quincenas_mes_cinco, on=\"person\", how=\"inner\") \n",
    "df_train = pd.merge(df_con_quincenas, labels, on=\"person\", how=\"inner\")\\\n",
    "            .drop(columns = ['person','viewed product', 'visited site', 'staticpage', 'lead', 'viewed product',\\\n",
    "                             'visited site', 'staticpage mes 5', 'lead mes 5'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = df_train.iloc[:,:-1],df_train.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1124,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, scale_pos_weight = 5, min_child_weight=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=12, missing=None, n_estimators=6,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=5, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 1126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)\n",
    "proba = xg_reg.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.9136565578520378\n",
      "Test acuracy:  0.9026525882049962\n",
      "ROC auc score:  0.8549295774647887\n",
      "Confusion matrix: \n",
      "[[3426  244]\n",
      " [ 134   79]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos que onda\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, proba)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entradas en los ultimos 30 dias (hasta la ultima visita)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method DMatrix.__del__ of <xgboost.core.DMatrix object at 0x00000225C2401C18>>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\seba\\Anaconda3\\lib\\site-packages\\xgboost\\core.py\", line 482, in __del__\n",
      "    if self.handle is not None:\n",
      "AttributeError: 'DMatrix' object has no attribute 'handle'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>last_day</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008ed71</td>\n",
       "      <td>2018-05-17 16:28:37</td>\n",
       "      <td>2018-05-17 12:27:47</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0008ed71</td>\n",
       "      <td>2018-05-17 16:28:37</td>\n",
       "      <td>2018-05-17 13:45:00</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0008ed71</td>\n",
       "      <td>2018-05-17 16:28:37</td>\n",
       "      <td>2018-05-17 16:22:06</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0008ed71</td>\n",
       "      <td>2018-05-17 16:28:37</td>\n",
       "      <td>2018-05-17 13:44:59</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0008ed71</td>\n",
       "      <td>2018-05-17 16:28:37</td>\n",
       "      <td>2018-05-17 16:21:54</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person             last_day            timestamp  month\n",
       "0  0008ed71  2018-05-17 16:28:37  2018-05-17 12:27:47    5.0\n",
       "1  0008ed71  2018-05-17 16:28:37  2018-05-17 13:45:00    5.0\n",
       "2  0008ed71  2018-05-17 16:28:37  2018-05-17 16:22:06    5.0\n",
       "3  0008ed71  2018-05-17 16:28:37  2018-05-17 13:44:59    5.0\n",
       "4  0008ed71  2018-05-17 16:28:37  2018-05-17 16:21:54    5.0"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meses = df[[\"timestamp\", \"person\", \"month\"]]\n",
    "df_ultimo_dia = df_meses.groupby(\"person\")[\"timestamp\"].max().reset_index()\n",
    "df_ultimo_dia.columns = [\"person\", \"last_day\"]\n",
    "df_meses_ultimo_dia = pd.merge(df_ultimo_dia, df_meses, on=\"person\", how=\"inner\")\n",
    "entradas_30_dias = df_meses_ultimo_dia.loc[((df_meses_ultimo_dia[\"last_day\"] - timedelta(days=30)) < \\\n",
    "                                           df_meses_ultimo_dia[\"timestamp\"]) & (df_meses_ultimo_dia[\"timestamp\"]< \\\n",
    "                                           df_meses_ultimo_dia[\"last_day\"])]\n",
    "\n",
    "\n",
    "entradas_30_dias = pd.merge(entradas_30_dias, todas_las_personas, on=\"person\", how=\"right\").fillna(0)\n",
    "entradas_30_dias.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>entradas_30_dias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c76b8417</td>\n",
       "      <td>3027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5c76e694</td>\n",
       "      <td>1608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a7ffa917</td>\n",
       "      <td>1603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18489dd5</td>\n",
       "      <td>1562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>622b4acf</td>\n",
       "      <td>1458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  entradas_30_dias\n",
       "0  c76b8417              3027\n",
       "1  5c76e694              1608\n",
       "2  a7ffa917              1603\n",
       "3  18489dd5              1562\n",
       "4  622b4acf              1458"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entradas_30_dias_df = entradas_30_dias[\"person\"].value_counts().rename(\"entradas_30_dias\").reset_index()\n",
    "entradas_30_dias_df.columns = [\"person\", \"entradas_30_dias\"]\n",
    "entradas_30_dias_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>entradas_30_dias</th>\n",
       "      <th>cant_mes</th>\n",
       "      <th>cant_dia_freq</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5c76e694</td>\n",
       "      <td>1608</td>\n",
       "      <td>1609</td>\n",
       "      <td>191</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18489dd5</td>\n",
       "      <td>1562</td>\n",
       "      <td>1563</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6abd2bf1</td>\n",
       "      <td>1319</td>\n",
       "      <td>1334</td>\n",
       "      <td>300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>97b0c0d1</td>\n",
       "      <td>1306</td>\n",
       "      <td>1328</td>\n",
       "      <td>217</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>595b9b50</td>\n",
       "      <td>1177</td>\n",
       "      <td>1179</td>\n",
       "      <td>377</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  entradas_30_dias  cant_mes  cant_dia_freq  label\n",
       "0  5c76e694              1608      1609            191      0\n",
       "1  18489dd5              1562      1563            174      0\n",
       "2  6abd2bf1              1319      1334            300      0\n",
       "3  97b0c0d1              1306      1328            217      0\n",
       "4  595b9b50              1177      1179            377      0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge\n",
    "\n",
    "df_con_labels2 = pd.merge(entradas_30_dias_df, df_con_labels, on=\"person\", how=\"inner\")\n",
    "df_con_labels2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entradas_30_dias_predecir = pd.merge(entradas_30_dias_df, df_persons, on=\"person\", how=\"inner\")\n",
    "entradas_30_dias_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_con_labels2_num = df_con_labels2[[\"entradas_30_dias\", \"cant_mes\", \"cant_dia_freq\", \"label\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = df_con_labels2_num.iloc[:,:-1], df_con_labels2_num.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, scale_pos_weight = 1, min_child_weight=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=6,\n",
       "       n_jobs=1, nthread=None, objective='binary:hinge', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8924731182795699\n",
      "Test acuracy:  0.8807622971928921\n",
      "ROC auc score:  0.5287829377725018\n",
      "Confusion matrix: \n",
      "[[3393  293]\n",
      " [ 170   27]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos que onda\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entradas en el ultimo mes (mes 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>cant_mes_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008ed71</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091926</td>\n",
       "      <td>448.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000ba417</td>\n",
       "      <td>206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000c79fe</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000e4d9e</td>\n",
       "      <td>411.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  cant_mes_5\n",
       "0  0008ed71         6.0\n",
       "1  00091926       448.0\n",
       "2  000ba417       206.0\n",
       "3  000c79fe        17.0\n",
       "4  000e4d9e       411.0"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entradas_mes_5 = df_meses.loc[df_meses[\"month\"] == 5]\n",
    "cant_entradas_mes_5 = entradas_mes_5.groupby(\"person\").agg({\"month\": \"count\"}).reset_index()\n",
    "cant_entradas_mes_5.columns = [\"person\", \"cant_mes_5\"]\n",
    "cant_entradas_mes_5 = pd.merge(cant_entradas_mes_5, todas_las_personas, on=\"person\", how=\"right\").fillna(0)\n",
    "cant_entradas_mes_5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>cant_mes_5</th>\n",
       "      <th>entradas_30_dias</th>\n",
       "      <th>cant_mes</th>\n",
       "      <th>cant_dia_freq</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008ed71</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000c79fe</td>\n",
       "      <td>17.0</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001802e4</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0019e639</td>\n",
       "      <td>290.0</td>\n",
       "      <td>358</td>\n",
       "      <td>290</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001b0bf9</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  cant_mes_5  entradas_30_dias  cant_mes  cant_dia_freq  label\n",
       "0  0008ed71         6.0                 5         6              6      0\n",
       "1  000c79fe        17.0                16        17             17      0\n",
       "2  001802e4        19.0                18        19             19      0\n",
       "3  0019e639       290.0               358       290             72      0\n",
       "4  001b0bf9         7.0                 6         7              7      0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge\n",
    "\n",
    "df_con_mes_5 = pd.merge(cant_entradas_mes_5, df_con_labels2, on=\"person\", how=\"inner\")\n",
    "df_con_mes_5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veo cuantas personas a predecir pierdo\n",
    "entradas_mes_5_predecir = pd.merge(cant_entradas_mes_5, df_persons, on=\"person\", how=\"inner\")\n",
    "entradas_mes_5_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "df_con_mes_5_num = df_con_mes_5.drop(columns=\"person\")\n",
    "\n",
    "X, y = df_con_mes_5_num.iloc[:,:-1],df_con_mes_5_num.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, scale_pos_weight = 1, min_child_weight=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=6,\n",
       "       n_jobs=1, nthread=None, objective='binary:hinge', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8840383748631768\n",
      "Test acuracy:  0.8787020345094\n",
      "ROC auc score:  0.5930984636246178\n",
      "Confusion matrix: \n",
      "[[3354  316]\n",
      " [ 155   58]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos que onda\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cantidad de entradas totales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>cant_entradas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008ed71</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091926</td>\n",
       "      <td>448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00091a7a</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000ba417</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000c79fe</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  cant_entradas\n",
       "0  0008ed71              6\n",
       "1  00091926            448\n",
       "2  00091a7a             10\n",
       "3  000ba417            206\n",
       "4  000c79fe             17"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entradas_tot = df.groupby(\"person\").agg({\"person\": \"count\"})\n",
    "#cant_entradas_tot = entradas_tot[[\"person\", \"entradas_tot\"]]\n",
    "entradas_tot.columns = [\"cant_entradas\"]\n",
    "entradas_tot.reset_index(inplace=True)\n",
    "entradas_tot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>cant_entradas</th>\n",
       "      <th>cant_mes_5</th>\n",
       "      <th>entradas_30_dias</th>\n",
       "      <th>cant_mes</th>\n",
       "      <th>cant_dia_freq</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008ed71</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000c79fe</td>\n",
       "      <td>17</td>\n",
       "      <td>17.0</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001802e4</td>\n",
       "      <td>19</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0019e639</td>\n",
       "      <td>471</td>\n",
       "      <td>290.0</td>\n",
       "      <td>358</td>\n",
       "      <td>290</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001b0bf9</td>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  cant_entradas  cant_mes_5  entradas_30_dias  cant_mes  \\\n",
       "0  0008ed71              6         6.0                 5         6   \n",
       "1  000c79fe             17        17.0                16        17   \n",
       "2  001802e4             19        19.0                18        19   \n",
       "3  0019e639            471       290.0               358       290   \n",
       "4  001b0bf9              7         7.0                 6         7   \n",
       "\n",
       "   cant_dia_freq  label  \n",
       "0              6      0  \n",
       "1             17      0  \n",
       "2             19      0  \n",
       "3             72      0  \n",
       "4              7      0  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge\n",
    "\n",
    "df_con_entradas = pd.merge(entradas_tot, df_con_mes_5, on=\"person\", how=\"inner\")\n",
    "df_con_entradas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veo cuantas personas a predecir pierdo\n",
    "entradas_tot_predecir = pd.merge(entradas_tot, df_persons, on=\"person\", how=\"inner\")\n",
    "entradas_tot_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "df_con_entradas_num = df_con_entradas.drop(columns=\"person\")\n",
    "\n",
    "X, y = df_con_entradas_num.iloc[:,:-1],df_con_entradas_num.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, scale_pos_weight = 1, min_child_weight=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=6,\n",
       "       n_jobs=1, nthread=None, objective='binary:hinge', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8441182151825382\n",
      "Test acuracy:  0.8485706927633273\n",
      "ROC auc score:  0.6473073236033194\n",
      "Confusion matrix: \n",
      "[[3214  478]\n",
      " [ 110   81]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos que onda\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cantidad de checkouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkouts = df.loc[df[\"event\"] == \"checkout\"]\n",
    "\n",
    "checkouts_tot = checkouts.groupby(\"person\")[\"event\"].value_counts().rename(\"check_tot\").reset_index()\n",
    "cant_checkouts_tot = checkouts_tot[[\"person\", \"check_tot\"]]\n",
    "cant_checkouts_tot = pd.merge(cant_entradas_mes_5, todas_las_personas, on=\"person\", how=\"right\").fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>cant_mes_5_x</th>\n",
       "      <th>cant_entradas</th>\n",
       "      <th>cant_mes_5_y</th>\n",
       "      <th>entradas_30_dias</th>\n",
       "      <th>cant_mes</th>\n",
       "      <th>cant_dia_freq</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008ed71</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000c79fe</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17</td>\n",
       "      <td>17.0</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001802e4</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0019e639</td>\n",
       "      <td>290.0</td>\n",
       "      <td>471</td>\n",
       "      <td>290.0</td>\n",
       "      <td>358</td>\n",
       "      <td>290</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001b0bf9</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  cant_mes_5_x  cant_entradas  cant_mes_5_y  entradas_30_dias  \\\n",
       "0  0008ed71           6.0              6           6.0                 5   \n",
       "1  000c79fe          17.0             17          17.0                16   \n",
       "2  001802e4          19.0             19          19.0                18   \n",
       "3  0019e639         290.0            471         290.0               358   \n",
       "4  001b0bf9           7.0              7           7.0                 6   \n",
       "\n",
       "   cant_mes  cant_dia_freq  label  \n",
       "0         6              6      0  \n",
       "1        17             17      0  \n",
       "2        19             19      0  \n",
       "3       290             72      0  \n",
       "4         7              7      0  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge\n",
    "\n",
    "df_con_check = pd.merge(cant_checkouts_tot, df_con_entradas, on=\"person\", how=\"inner\")\n",
    "df_con_check.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost solo usa valores numericos\n",
    "df_con_check_num = df_con_check.drop(columns=\"person\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veo cuantas personas a predecir pierdo\n",
    "cant_checkouts_tot_predecir = pd.merge(cant_checkouts_tot, df_persons, on=\"person\", how=\"inner\")\n",
    "cant_checkouts_tot_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = df_con_check_num.iloc[:,:-1], df_con_check_num.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, scale_pos_weight = 1, min_child_weight=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=6,\n",
       "       n_jobs=1, nthread=None, objective='binary:hinge', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8885454896658296\n",
      "Test acuracy:  0.879217100180273\n",
      "ROC auc score:  0.5756815187217766\n",
      "Confusion matrix: \n",
      "[[3364  306]\n",
      " [ 163   50]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos que onda\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cantidad de entradas al evento mas visitado por cada persona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>cant_ev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>97161</th>\n",
       "      <td>6abd2bf1</td>\n",
       "      <td>2355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160896</th>\n",
       "      <td>b1f4dbf6</td>\n",
       "      <td>2233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129961</th>\n",
       "      <td>8fb4929e</td>\n",
       "      <td>1912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141831</th>\n",
       "      <td>9ccf882a</td>\n",
       "      <td>1891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6202</th>\n",
       "      <td>06ed04d6</td>\n",
       "      <td>1881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          person  cant_ev\n",
       "97161   6abd2bf1     2355\n",
       "160896  b1f4dbf6     2233\n",
       "129961  8fb4929e     1912\n",
       "141831  9ccf882a     1891\n",
       "6202    06ed04d6     1881"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = df.groupby(\"person\")['event'].value_counts().rename().reset_index()\n",
    "s.columns = ['person', 'event', 'cant_ev']\n",
    "s = s.sort_values('cant_ev',ascending=False)\n",
    "mayor_evento = s.drop_duplicates(subset=['person']).drop(columns=\"event\")\n",
    "mayor_evento.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>cant_mod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b1f4dbf6</td>\n",
       "      <td>836.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>171e75cb</td>\n",
       "      <td>683.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6f19cfd9</td>\n",
       "      <td>624.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6abd2bf1</td>\n",
       "      <td>607.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9bf968c5</td>\n",
       "      <td>568.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  cant_mod\n",
       "0  b1f4dbf6     836.0\n",
       "1  171e75cb     683.0\n",
       "2  6f19cfd9     624.0\n",
       "3  6abd2bf1     607.0\n",
       "4  9bf968c5     568.0"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cantidad de entradas al modelo mas visitado por cada persona\n",
    "\n",
    "mod = df.groupby(\"person\")['model'].value_counts().rename().reset_index()\n",
    "mod.columns = ['person', 'model', 'cant_mod']\n",
    "mod = mod.sort_values('cant_mod',ascending=False)\n",
    "mayor_modelo = mod.drop_duplicates(subset=['person']).drop(columns=\"model\")\n",
    "mayor_modelo = pd.merge(mayor_modelo, todas_las_personas, on=\"person\", how=\"right\").fillna(0)\n",
    "mayor_modelo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>cant_eng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c76b8417</td>\n",
       "      <td>762.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6ca3126e</td>\n",
       "      <td>245.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>622b4acf</td>\n",
       "      <td>206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25b77cf2</td>\n",
       "      <td>161.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5c76e694</td>\n",
       "      <td>136.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  cant_eng\n",
       "0  c76b8417     762.0\n",
       "1  6ca3126e     245.0\n",
       "2  622b4acf     206.0\n",
       "3  25b77cf2     161.0\n",
       "4  5c76e694     136.0"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cantidad de entradas al search engine mas visitado por cada persona\n",
    "\n",
    "eng = df.groupby(\"person\")['search_engine'].value_counts().rename().reset_index()\n",
    "eng.columns = ['person', 'search_engine', 'cant_eng']\n",
    "eng = eng.sort_values('cant_eng',ascending=False)\n",
    "mayor_engine = eng.drop_duplicates(subset=['person']).drop(columns=\"search_engine\")\n",
    "mayor_engine = pd.merge(mayor_engine, todas_las_personas, on=\"person\", how=\"right\").fillna(0)\n",
    "mayor_engine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>cant_src</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02f14240</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c76b8417</td>\n",
       "      <td>374.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6ca3126e</td>\n",
       "      <td>335.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>622b4acf</td>\n",
       "      <td>282.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3b2d17f6</td>\n",
       "      <td>221.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  cant_src\n",
       "0  02f14240     500.0\n",
       "1  c76b8417     374.0\n",
       "2  6ca3126e     335.0\n",
       "3  622b4acf     282.0\n",
       "4  3b2d17f6     221.0"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cantidad de entradas al campaign source mas visitado por cada persona\n",
    "\n",
    "src = df.groupby(\"person\")['campaign_source'].value_counts().rename().reset_index()\n",
    "src.columns = ['person', 'campaign_source', 'cant_src']\n",
    "src = src.sort_values('cant_src',ascending=False)\n",
    "mayor_camp = src.drop_duplicates(subset=['person']).drop(columns=\"campaign_source\")\n",
    "mayor_camp = pd.merge(mayor_camp, todas_las_personas, on=\"person\", how=\"right\").fillna(0)\n",
    "mayor_camp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>cant_city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5059f7fd</td>\n",
       "      <td>268.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7ac0c607</td>\n",
       "      <td>208.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67bdc946</td>\n",
       "      <td>207.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ffee0f18</td>\n",
       "      <td>173.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9b3b43aa</td>\n",
       "      <td>171.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  cant_city\n",
       "0  5059f7fd      268.0\n",
       "1  7ac0c607      208.0\n",
       "2  67bdc946      207.0\n",
       "3  ffee0f18      173.0\n",
       "4  9b3b43aa      171.0"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cantidad de entradas desde la ciudad mas frecuente de cada persona\n",
    "\n",
    "cty = df.groupby(\"person\")['city'].value_counts().rename().reset_index()\n",
    "cty.columns = ['person', 'city', 'cant_city']\n",
    "src = cty.sort_values('cant_city',ascending=False)\n",
    "mayor_ciudad = src.drop_duplicates(subset=['person']).drop(columns=\"city\")\n",
    "mayor_ciudad = pd.merge(mayor_ciudad, todas_las_personas, on=\"person\", how=\"right\").fillna(0)\n",
    "mayor_ciudad.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>cant_city</th>\n",
       "      <th>cant_src</th>\n",
       "      <th>cant_eng</th>\n",
       "      <th>cant_mod</th>\n",
       "      <th>cant_ev</th>\n",
       "      <th>cant_mes_5_x</th>\n",
       "      <th>cant_entradas</th>\n",
       "      <th>cant_mes_5_y</th>\n",
       "      <th>entradas_30_dias</th>\n",
       "      <th>cant_mes</th>\n",
       "      <th>cant_dia_freq</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ffee0f18</td>\n",
       "      <td>173.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1518</td>\n",
       "      <td>218.0</td>\n",
       "      <td>3458</td>\n",
       "      <td>218.0</td>\n",
       "      <td>217</td>\n",
       "      <td>1028</td>\n",
       "      <td>282</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9b3b43aa</td>\n",
       "      <td>171.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>1289</td>\n",
       "      <td>246.0</td>\n",
       "      <td>1663</td>\n",
       "      <td>246.0</td>\n",
       "      <td>234</td>\n",
       "      <td>923</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02f14240</td>\n",
       "      <td>155.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>523</td>\n",
       "      <td>225.0</td>\n",
       "      <td>1798</td>\n",
       "      <td>225.0</td>\n",
       "      <td>282</td>\n",
       "      <td>847</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>345fc18e</td>\n",
       "      <td>153.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>844</td>\n",
       "      <td>367.0</td>\n",
       "      <td>1569</td>\n",
       "      <td>367.0</td>\n",
       "      <td>364</td>\n",
       "      <td>1007</td>\n",
       "      <td>137</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30ec9daf</td>\n",
       "      <td>152.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>423</td>\n",
       "      <td>185.0</td>\n",
       "      <td>803</td>\n",
       "      <td>185.0</td>\n",
       "      <td>184</td>\n",
       "      <td>189</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  cant_city  cant_src  cant_eng  cant_mod  cant_ev  cant_mes_5_x  \\\n",
       "0  ffee0f18      173.0      76.0      65.0      80.0     1518         218.0   \n",
       "1  9b3b43aa      171.0      17.0       4.0     468.0     1289         246.0   \n",
       "2  02f14240      155.0     500.0       6.0     272.0      523         225.0   \n",
       "3  345fc18e      153.0     155.0      10.0     106.0      844         367.0   \n",
       "4  30ec9daf      152.0      30.0      10.0      83.0      423         185.0   \n",
       "\n",
       "   cant_entradas  cant_mes_5_y  entradas_30_dias  cant_mes  cant_dia_freq  \\\n",
       "0           3458         218.0               217      1028            282   \n",
       "1           1663         246.0               234       923            174   \n",
       "2           1798         225.0               282       847            114   \n",
       "3           1569         367.0               364      1007            137   \n",
       "4            803         185.0               184       189             68   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "# merge de todos los dfs\n",
    "\n",
    "dfs = [mayor_ciudad, mayor_camp, mayor_engine, mayor_modelo, mayor_evento]\n",
    "df_final1 = reduce(lambda left,right: pd.merge(left,right,on='person', how='inner'), dfs)\n",
    "df_final = pd.merge(df_final1, df_con_check, on=\"person\", how=\"inner\")\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_num = df_final.drop(columns=\"person\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veo cuantas personas a predecir pierdo\n",
    "df1_predecir = pd.merge(df_final1, df_persons, on=\"person\", how=\"inner\")\n",
    "df1_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = df_final_num.iloc[:,:-1], df_final_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y)\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, scale_pos_weight = 1, min_child_weight=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=6,\n",
       "       n_jobs=1, nthread=None, objective='binary:hinge', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.7690425600412079\n",
      "Test acuracy:  0.7532835436518156\n",
      "ROC auc score:  0.6571651387827858\n",
      "Confusion matrix: \n",
      "[[2822  874]\n",
      " [  84  103]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos que onda\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = df_final_num.iloc[:,:-1],df_final_num.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, y_train)\n",
    "dtest = xgb.DMatrix(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, scale_pos_weight = 10, min_child_weight=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=6,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=10, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.60300773, 0.42328286, 0.3905003 , ..., 0.37030753, 0.27939197,\n",
       "       0.40139404], dtype=float32)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict_proba(X_test)[:, 1]\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8640139076685339\n",
      "Test acuracy:  0.8570692763327324\n",
      "ROC auc score:  0.7274687767669051\n",
      "Confusion matrix: \n",
      "[[3260  436]\n",
      " [ 119   68]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos que onda\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, xg_reg.predict(X_test))\n",
    "matriz_de_confusion = confusion_matrix(y_test, xg_reg.predict(X_test))\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distancia entre primer y ultimo dia de entrada al sitio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>distan_dias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008ed71</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091926</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00091a7a</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000ba417</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000c79fe</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  distan_dias\n",
       "0  0008ed71            0\n",
       "1  00091926           27\n",
       "2  00091a7a            0\n",
       "3  000ba417            9\n",
       "4  000c79fe            0"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamp_df = df[[\"person\", \"timestamp\"]]\n",
    "ultimo_dia = timestamp_df.groupby(\"person\")[\"timestamp\"].max().rename(\"ultimo\").reset_index()\n",
    "primer_dia = timestamp_df.groupby(\"person\")[\"timestamp\"].min().rename(\"primer\").reset_index()\n",
    "distancia_dias = pd.merge(primer_dia, ultimo_dia, on=\"person\", how=\"inner\")\n",
    "distancia_dias[\"distan_dias\"] = (distancia_dias[\"ultimo\"] - distancia_dias[\"primer\"]).dt.days\n",
    "distancia_dias = distancia_dias[[\"person\", \"distan_dias\"]]\n",
    "distancia_dias.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distan_dias</th>\n",
       "      <th>cant_city</th>\n",
       "      <th>cant_src</th>\n",
       "      <th>cant_eng</th>\n",
       "      <th>cant_mod</th>\n",
       "      <th>cant_ev</th>\n",
       "      <th>cant_mes_5_x</th>\n",
       "      <th>cant_entradas</th>\n",
       "      <th>cant_mes_5_y</th>\n",
       "      <th>entradas_30_dias</th>\n",
       "      <th>cant_mes</th>\n",
       "      <th>cant_dia_freq</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17</td>\n",
       "      <td>17.0</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>114</td>\n",
       "      <td>12.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>189</td>\n",
       "      <td>290.0</td>\n",
       "      <td>471</td>\n",
       "      <td>290.0</td>\n",
       "      <td>358</td>\n",
       "      <td>290</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   distan_dias  cant_city  cant_src  cant_eng  cant_mod  cant_ev  \\\n",
       "0            0        2.0       0.0       0.0       1.0        3   \n",
       "1            0        1.0       1.0       1.0       4.0        9   \n",
       "2            0        1.0       5.0       0.0       3.0        5   \n",
       "3          114       12.0      17.0      12.0      63.0      189   \n",
       "4            0        0.0       0.0       0.0       5.0        2   \n",
       "\n",
       "   cant_mes_5_x  cant_entradas  cant_mes_5_y  entradas_30_dias  cant_mes  \\\n",
       "0           6.0              6           6.0                 5         6   \n",
       "1          17.0             17          17.0                16        17   \n",
       "2          19.0             19          19.0                18        19   \n",
       "3         290.0            471         290.0               358       290   \n",
       "4           7.0              7           7.0                 6         7   \n",
       "\n",
       "   cant_dia_freq  label  \n",
       "0              6      0  \n",
       "1             17      0  \n",
       "2             19      0  \n",
       "3             72      0  \n",
       "4              7      0  "
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge\n",
    "\n",
    "df_con_distancias = pd.merge(distancia_dias, df_final, on=\"person\", how=\"inner\") \n",
    "df_con_distancias_num = df_con_distancias.drop(columns=\"person\")\n",
    "df_con_distancias_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veo cuantas personas a predecir pierdo\n",
    "distancia_dias_predecir = pd.merge(distancia_dias, df_persons, on=\"person\", how=\"inner\")\n",
    "distancia_dias_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = df_con_distancias_num.iloc[:,:-1], df_con_distancias_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y)\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, scale_pos_weight = 1, min_child_weight=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=6,\n",
       "       n_jobs=1, nthread=None, objective='binary:hinge', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8446977013714506\n",
      "Test acuracy:  0.8398145763584857\n",
      "ROC auc score:  0.6253261615605838\n",
      "Confusion matrix: \n",
      "[[3187  505]\n",
      " [ 117   74]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos que onda\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cantidad de modelos distintos vistos por cada usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>modelos_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008ed71</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091926</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00091a7a</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000ba417</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000c79fe</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  modelos_dist\n",
       "0  0008ed71             3\n",
       "1  00091926            36\n",
       "2  00091a7a             3\n",
       "3  000ba417            26\n",
       "4  000c79fe             1"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelos_df = df[[\"person\", \"model\"]]\n",
    "cant_modelos = modelos_df.groupby(\"person\")[\"model\"].nunique().rename(\"modelos_dist\").reset_index()\n",
    "cant_modelos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelos_dist</th>\n",
       "      <th>distan_dias</th>\n",
       "      <th>cant_city</th>\n",
       "      <th>cant_src</th>\n",
       "      <th>cant_eng</th>\n",
       "      <th>cant_mod</th>\n",
       "      <th>cant_ev</th>\n",
       "      <th>cant_mes_5_x</th>\n",
       "      <th>cant_entradas</th>\n",
       "      <th>cant_mes_5_y</th>\n",
       "      <th>entradas_30_dias</th>\n",
       "      <th>cant_mes</th>\n",
       "      <th>cant_dia_freq</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17</td>\n",
       "      <td>17.0</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26</td>\n",
       "      <td>114</td>\n",
       "      <td>12.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>189</td>\n",
       "      <td>290.0</td>\n",
       "      <td>471</td>\n",
       "      <td>290.0</td>\n",
       "      <td>358</td>\n",
       "      <td>290</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   modelos_dist  distan_dias  cant_city  cant_src  cant_eng  cant_mod  \\\n",
       "0             3            0        2.0       0.0       0.0       1.0   \n",
       "1             1            0        1.0       1.0       1.0       4.0   \n",
       "2             2            0        1.0       5.0       0.0       3.0   \n",
       "3            26          114       12.0      17.0      12.0      63.0   \n",
       "4             1            0        0.0       0.0       0.0       5.0   \n",
       "\n",
       "   cant_ev  cant_mes_5_x  cant_entradas  cant_mes_5_y  entradas_30_dias  \\\n",
       "0        3           6.0              6           6.0                 5   \n",
       "1        9          17.0             17          17.0                16   \n",
       "2        5          19.0             19          19.0                18   \n",
       "3      189         290.0            471         290.0               358   \n",
       "4        2           7.0              7           7.0                 6   \n",
       "\n",
       "   cant_mes  cant_dia_freq  label  \n",
       "0         6              6      0  \n",
       "1        17             17      0  \n",
       "2        19             19      0  \n",
       "3       290             72      0  \n",
       "4         7              7      0  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge \n",
    "\n",
    "df_con_modelos = pd.merge(cant_modelos, df_con_distancias, on=\"person\", how=\"inner\")\n",
    "df_con_modelos_num = df_con_modelos.drop(columns=\"person\")\n",
    "df_con_modelos_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veo cuantas personas a predecir pierdo\n",
    "cant_modelos_predecir = pd.merge(cant_modelos, df_persons, on=\"person\", how=\"inner\")\n",
    "cant_modelos_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = df_con_modelos_num.iloc[:,:-1], df_con_modelos_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y)\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, scale_pos_weight = 1, min_child_weight=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=6,\n",
       "       n_jobs=1, nthread=None, objective='binary:hinge', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8276350524756938\n",
      "Test acuracy:  0.8323461241308266\n",
      "ROC auc score:  0.6412577357013607\n",
      "Confusion matrix: \n",
      "[[3150  542]\n",
      " [ 109   82]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos que onda\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cantidad de días distintos de entrada al sitio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seba\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>cant_dias_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008ed71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091926</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00091a7a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000ba417</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000c79fe</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  cant_dias_dist\n",
       "0  0008ed71               1\n",
       "1  00091926              22\n",
       "2  00091a7a               1\n",
       "3  000ba417               3\n",
       "4  000c79fe               1"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dias = df[[\"person\", \"timestamp\"]]\n",
    "df_dias[\"day_of_year\"] = df_dias[\"timestamp\"].dt.dayofyear\n",
    "cant_dias_dist = df_dias.groupby(\"person\")[\"day_of_year\"].nunique().rename(\"cant_dias_dist\").reset_index()\n",
    "cant_dias_dist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cant_dias_dist</th>\n",
       "      <th>distan_dias</th>\n",
       "      <th>cant_city</th>\n",
       "      <th>cant_src</th>\n",
       "      <th>cant_eng</th>\n",
       "      <th>cant_mod</th>\n",
       "      <th>cant_ev</th>\n",
       "      <th>cant_mes_5_x</th>\n",
       "      <th>cant_entradas</th>\n",
       "      <th>cant_mes_5_y</th>\n",
       "      <th>entradas_30_dias</th>\n",
       "      <th>cant_mes</th>\n",
       "      <th>cant_dia_freq</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17</td>\n",
       "      <td>17.0</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>114</td>\n",
       "      <td>12.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>189</td>\n",
       "      <td>290.0</td>\n",
       "      <td>471</td>\n",
       "      <td>290.0</td>\n",
       "      <td>358</td>\n",
       "      <td>290</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cant_dias_dist  distan_dias  cant_city  cant_src  cant_eng  cant_mod  \\\n",
       "0               1            0        2.0       0.0       0.0       1.0   \n",
       "1               1            0        1.0       1.0       1.0       4.0   \n",
       "2               1            0        1.0       5.0       0.0       3.0   \n",
       "3              14          114       12.0      17.0      12.0      63.0   \n",
       "4               1            0        0.0       0.0       0.0       5.0   \n",
       "\n",
       "   cant_ev  cant_mes_5_x  cant_entradas  cant_mes_5_y  entradas_30_dias  \\\n",
       "0        3           6.0              6           6.0                 5   \n",
       "1        9          17.0             17          17.0                16   \n",
       "2        5          19.0             19          19.0                18   \n",
       "3      189         290.0            471         290.0               358   \n",
       "4        2           7.0              7           7.0                 6   \n",
       "\n",
       "   cant_mes  cant_dia_freq  label  \n",
       "0         6              6      0  \n",
       "1        17             17      0  \n",
       "2        19             19      0  \n",
       "3       290             72      0  \n",
       "4         7              7      0  "
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge \n",
    "\n",
    "df_con_dias_dist = pd.merge(cant_dias_dist, df_con_modelos, on=\"person\", how=\"inner\")\n",
    "df_con_dias_dist_num = df_con_dias_dist.drop(columns=[\"person\", \"modelos_dist\"])\n",
    "df_con_dias_dist_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veo cuantas personas a predecir pierdo\n",
    "cant_dias_dist_predecir = pd.merge(cant_dias_dist, df_persons, on=\"person\", how=\"inner\")\n",
    "cant_dias_dist_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = df_con_dias_dist_num.iloc[:,:-1], df_con_dias_dist_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y)\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, scale_pos_weight = 1, min_child_weight=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=6,\n",
       "       n_jobs=1, nthread=None, objective='binary:hinge', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8376794797501771\n",
      "Test acuracy:  0.837496780839557\n",
      "ROC auc score:  0.6290720561792017\n",
      "Confusion matrix: \n",
      "[[3176  516]\n",
      " [ 115   76]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos que onda\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = df_con_dias_dist_num.iloc[:,:-1],df_con_dias_dist_num.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, y_train)\n",
    "dtest = xgb.DMatrix(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 4, n_estimators = 6, scale_pos_weight = 11, min_child_weight=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=4, min_child_weight=1, missing=None, n_estimators=6,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=11, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.41958648, 0.63762015, 0.30858842, ..., 0.5040561 , 0.39075756,\n",
       "       0.39075756], dtype=float32)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict_proba(X_test)[:, 1]\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8376794797501771\n",
      "Test acuracy:  0.8403296420293588\n",
      "ROC auc score:  0.7308450987844101\n",
      "Confusion matrix: \n",
      "[[3182  510]\n",
      " [ 110   81]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos que onda\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, xg_reg.predict(X_test))\n",
    "matriz_de_confusion = confusion_matrix(y_test, xg_reg.predict(X_test))\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Promedio de entradas por dia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seba\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>cant_entradas</th>\n",
       "      <th>cant_dias_dist</th>\n",
       "      <th>promedio_por_dia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008ed71</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091926</td>\n",
       "      <td>448</td>\n",
       "      <td>22</td>\n",
       "      <td>0.049107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00091a7a</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000ba417</td>\n",
       "      <td>206</td>\n",
       "      <td>3</td>\n",
       "      <td>0.014563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000c79fe</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0.058824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  cant_entradas  cant_dias_dist  promedio_por_dia\n",
       "0  0008ed71              6               1          0.166667\n",
       "1  00091926            448              22          0.049107\n",
       "2  00091a7a             10               1          0.100000\n",
       "3  000ba417            206               3          0.014563\n",
       "4  000c79fe             17               1          0.058824"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entradas_tot = df.groupby(\"person\").agg({\"person\": \"count\"})\n",
    "#cant_entradas_tot = entradas_tot[[\"person\", \"entradas_tot\"]]\n",
    "entradas_tot.columns = [\"cant_entradas\"]\n",
    "entradas_tot.reset_index(inplace=True)\n",
    "\n",
    "df_dias = df[[\"person\", \"timestamp\"]]\n",
    "df_dias[\"day_of_year\"] = df_dias[\"timestamp\"].dt.dayofyear\n",
    "cant_dias_dist = df_dias.groupby(\"person\")[\"day_of_year\"].nunique().rename(\"cant_dias_dist\").reset_index()\n",
    "\n",
    "entradas_tot_y_dias = pd.merge(entradas_tot, cant_dias_dist, on=\"person\", how=\"inner\")\n",
    "entradas_tot_y_dias[\"promedio_por_dia\"] = (entradas_tot_y_dias[\"cant_dias_dist\"] / entradas_tot_y_dias[\"cant_entradas\"])\n",
    "entradas_tot_y_dias.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "entradas_tot_y_dias = entradas_tot_y_dias[[\"person\", \"promedio_por_dia\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veo cuantas personas a predecir pierdo\n",
    "entradas_tot_y_dias_predecir = pd.merge(entradas_tot_y_dias, df_persons, on=\"person\", how=\"inner\")\n",
    "entradas_tot_y_dias_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Promedio de entradas por mes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>promedio_por_mes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008ed71</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091926</td>\n",
       "      <td>0.002232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00091a7a</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000ba417</td>\n",
       "      <td>0.004854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000c79fe</td>\n",
       "      <td>0.058824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  promedio_por_mes\n",
       "0  0008ed71          0.166667\n",
       "1  00091926          0.002232\n",
       "2  00091a7a          0.100000\n",
       "3  000ba417          0.004854\n",
       "4  000c79fe          0.058824"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mes = df[[\"person\", \"month\"]]\n",
    "cant_meses_dist = df_mes.groupby(\"person\")[\"month\"].nunique().rename(\"cant_meses_dist\").reset_index()\n",
    "\n",
    "entradas_tot_y_meses = pd.merge(entradas_tot, cant_meses_dist, on=\"person\", how=\"inner\")\n",
    "entradas_tot_y_meses[\"promedio_por_mes\"] = (entradas_tot_y_meses[\"cant_meses_dist\"] / entradas_tot_y_meses[\"cant_entradas\"])\n",
    "entradas_tot_y_meses = entradas_tot_y_meses[[\"person\", \"promedio_por_mes\"]]\n",
    "\n",
    "entradas_tot_y_meses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>promedio_por_mes</th>\n",
       "      <th>promedio_por_dia</th>\n",
       "      <th>cant_dias_dist</th>\n",
       "      <th>modelos_dist</th>\n",
       "      <th>distan_dias</th>\n",
       "      <th>cant_city</th>\n",
       "      <th>cant_src</th>\n",
       "      <th>cant_eng</th>\n",
       "      <th>cant_mod</th>\n",
       "      <th>cant_ev</th>\n",
       "      <th>cant_mes_5_x</th>\n",
       "      <th>cant_entradas</th>\n",
       "      <th>cant_mes_5_y</th>\n",
       "      <th>entradas_30_dias</th>\n",
       "      <th>cant_mes</th>\n",
       "      <th>cant_dia_freq</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17</td>\n",
       "      <td>17.0</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.008493</td>\n",
       "      <td>0.029724</td>\n",
       "      <td>14</td>\n",
       "      <td>26</td>\n",
       "      <td>114</td>\n",
       "      <td>12.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>189</td>\n",
       "      <td>290.0</td>\n",
       "      <td>471</td>\n",
       "      <td>290.0</td>\n",
       "      <td>358</td>\n",
       "      <td>290</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   promedio_por_mes  promedio_por_dia  cant_dias_dist  modelos_dist  \\\n",
       "0          0.166667          0.166667               1             3   \n",
       "1          0.058824          0.058824               1             1   \n",
       "2          0.052632          0.052632               1             2   \n",
       "3          0.008493          0.029724              14            26   \n",
       "4          0.142857          0.142857               1             1   \n",
       "\n",
       "   distan_dias  cant_city  cant_src  cant_eng  cant_mod  cant_ev  \\\n",
       "0            0        2.0       0.0       0.0       1.0        3   \n",
       "1            0        1.0       1.0       1.0       4.0        9   \n",
       "2            0        1.0       5.0       0.0       3.0        5   \n",
       "3          114       12.0      17.0      12.0      63.0      189   \n",
       "4            0        0.0       0.0       0.0       5.0        2   \n",
       "\n",
       "   cant_mes_5_x  cant_entradas  cant_mes_5_y  entradas_30_dias  cant_mes  \\\n",
       "0           6.0              6           6.0                 5         6   \n",
       "1          17.0             17          17.0                16        17   \n",
       "2          19.0             19          19.0                18        19   \n",
       "3         290.0            471         290.0               358       290   \n",
       "4           7.0              7           7.0                 6         7   \n",
       "\n",
       "   cant_dia_freq  label  \n",
       "0              6      0  \n",
       "1             17      0  \n",
       "2             19      0  \n",
       "3             72      0  \n",
       "4              7      0  "
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge\n",
    "\n",
    "labels_con_promedios = pd.merge(entradas_tot_y_meses, entradas_tot_y_dias, on=\"person\", how=\"inner\")\n",
    "labels_con_promedios = pd.merge(labels_con_promedios, df_con_dias_dist, on=\"person\", how=\"inner\")\n",
    "labels_con_promedios_num = labels_con_promedios.drop(columns=\"person\")\n",
    "labels_con_promedios_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veo cuantas personas a predecir pierdo\n",
    "entradas_tot_y_meses_predecir = pd.merge(entradas_tot_y_meses, df_persons, on=\"person\", how=\"inner\")\n",
    "entradas_tot_y_meses_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = labels_con_promedios_num.iloc[:,:-1], labels_con_promedios_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y, weight={1: 1, 0: 0.1})\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, eval_metric = \"auc\", min_child_weight=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=5, missing=None,\n",
       "       n_estimators=6, n_jobs=1, nthread=None, objective='binary:hinge',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8460498358122465\n",
      "Test acuracy:  0.8411022405356683\n",
      "ROC auc score:  0.6334504206066037\n",
      "Confusion matrix: \n",
      "[[3189  503]\n",
      " [ 114   77]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos \n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8460498358122465\n",
      "Test acuracy:  0.8411022405356683\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.86      0.91      3692\n",
      "           1       0.13      0.40      0.20       191\n",
      "\n",
      "   micro avg       0.84      0.84      0.84      3883\n",
      "   macro avg       0.55      0.63      0.56      3883\n",
      "weighted avg       0.92      0.84      0.88      3883\n",
      "\n",
      "\n",
      "Precision Score:  0.13275862068965516\n",
      "Recall Score:  0.4031413612565445\n",
      "F1 Score:  0.19974059662775617\n",
      "Cohen Kappa Score:  0.1357829590802795\n",
      "ROC auc score:  0.6334504206066037\n",
      "Confusion matrix: \n",
      "[[3189  503]\n",
      " [ 114   77]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\\\n",
    "                            f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "# Pruebo todas las metricas.\n",
    "# accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\n",
    "# f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "\n",
    "trainAccuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "testAccuracy = accuracy_score(y_test, preds)\n",
    "\n",
    "meanSquaredError = mean_squared_error(y_test, preds)\n",
    "classificationReport = classification_report(y_test, preds)\n",
    "precisionScore = precision_score(y_test, preds)\n",
    "recallScore = recall_score(y_test, preds)\n",
    "f1Score = f1_score(y_test, preds)\n",
    "cohenKappaScore = cohen_kappa_score(y_test, preds)\n",
    "areaDebajoDeCurva = roc_auc_score(y_test, preds)\n",
    "matrizDeConfusion = confusion_matrix(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", trainAccuracy)\n",
    "print(\"Test acuracy: \", testAccuracy)\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(classificationReport)\n",
    "print()\n",
    "print(\"Precision Score: \",precisionScore)\n",
    "print(\"Recall Score: \",recallScore)\n",
    "print(\"F1 Score: \",f1Score)\n",
    "print(\"Cohen Kappa Score: \",cohenKappaScore)\n",
    "print(\"ROC auc score: \", areaDebajoDeCurva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matrizDeConfusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = labels_con_promedios_num.iloc[:,:-1],labels_con_promedios_num.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, y_train)\n",
    "dtest = xgb.DMatrix(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, scale_pos_weight = 6, min_child_weight=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=6,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=6, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.36512432, 0.54599017, 0.28901175, ..., 0.42871228, 0.34284964,\n",
       "       0.34284964], dtype=float32)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict_proba(X_test)[:, 1]\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.9318781791256198\n",
      "Test acuracy:  0.9296935359258306\n",
      "ROC auc score:  0.7383659589433501\n",
      "Confusion matrix: \n",
      "[[3576  116]\n",
      " [ 157   34]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos que onda\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, xg_reg.predict(X_test))\n",
    "matriz_de_confusion = confusion_matrix(y_test, xg_reg.predict(X_test))\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplico los compradores (label = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = labels_con_promedios_num.iloc[:,:-1], labels_con_promedios_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "#data_dmatrix = xgb.DMatrix(data=X,label=y, weight={1: 1, 0: 0.1})\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplico los compradores\n",
    "\n",
    "y_train_df = y_train.to_frame()\n",
    "X_train_df = X_train.reset_index()\n",
    "train = pd.merge(X_train, y_train_df, how=\"inner\", left_index=True, right_index=True)\n",
    "train_compradores = train.loc[train[\"label\"] == 1]\n",
    "train_dup = pd.concat([train, train_compradores], ignore_index=True)\n",
    "X_train, y_train = train_dup.drop(columns=\"label\"), train_dup[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBClassifier(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, eval_metric = \"auc\", min_child_weight=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=1, missing=None,\n",
       "       n_estimators=6, n_jobs=1, nthread=None, objective='binary:hinge',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.6244485294117647\n",
      "Test acuracy:  0.6144733453515323\n",
      "ROC auc score:  0.6805928199077671\n",
      "Confusion matrix: \n",
      "[[2242 1450]\n",
      " [  47  144]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos \n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.6244485294117647\n",
      "Test acuracy:  0.6144733453515323\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.61      0.75      3692\n",
      "           1       0.09      0.75      0.16       191\n",
      "\n",
      "   micro avg       0.61      0.61      0.61      3883\n",
      "   macro avg       0.53      0.68      0.46      3883\n",
      "weighted avg       0.94      0.61      0.72      3883\n",
      "\n",
      "\n",
      "Precision Score:  0.0903387703889586\n",
      "Recall Score:  0.7539267015706806\n",
      "F1 Score:  0.16134453781512606\n",
      "Cohen Kappa Score:  0.08057198651049235\n",
      "ROC auc score:  0.6805928199077671\n",
      "Confusion matrix: \n",
      "[[2242 1450]\n",
      " [  47  144]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\\\n",
    "                            f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "# Pruebo todas las metricas.\n",
    "# accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\n",
    "# f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "\n",
    "trainAccuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "testAccuracy = accuracy_score(y_test, preds)\n",
    "\n",
    "meanSquaredError = mean_squared_error(y_test, preds)\n",
    "classificationReport = classification_report(y_test, preds)\n",
    "precisionScore = precision_score(y_test, preds)\n",
    "recallScore = recall_score(y_test, preds)\n",
    "f1Score = f1_score(y_test, preds)\n",
    "cohenKappaScore = cohen_kappa_score(y_test, preds)\n",
    "areaDebajoDeCurva = roc_auc_score(y_test, preds)\n",
    "matrizDeConfusion = confusion_matrix(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", trainAccuracy)\n",
    "print(\"Test acuracy: \", testAccuracy)\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(classificationReport)\n",
    "print()\n",
    "print(\"Precision Score: \",precisionScore)\n",
    "print(\"Recall Score: \",recallScore)\n",
    "print(\"F1 Score: \",f1Score)\n",
    "print(\"Cohen Kappa Score: \",cohenKappaScore)\n",
    "print(\"ROC auc score: \", areaDebajoDeCurva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matrizDeConfusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = labels_con_promedios_num.iloc[:,:-1], labels_con_promedios_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "#data_dmatrix = xgb.DMatrix(data=X,label=y, weight={1: 1, 0: 0.1})\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18434, 980)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cant_ceros = np.sum(y == 0)\n",
    "cant_unos = np.sum(y == 1)\n",
    "cant_ceros, cant_unos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seba\\Anaconda3\\lib\\site-packages\\imblearn\\utils\\_validation.py:257: UserWarning: After over-sampling, the number of samples (18434) in class 0 will be larger than the number of samples in the majority class (class #0 -> 14742)\n",
      "  n_samples_majority))\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE(k_neighbors=90, sampling_strategy={0: 18434, 1: 2500 })\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train.ravel())\n",
    "X_train_res_df = pd.DataFrame(X_train_res)\n",
    "X_train_res_df.columns = X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBClassifier(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, eval_metric = \"auc\", min_child_weight=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=1, missing=None,\n",
       "       n_estimators=6, n_jobs=1, nthread=None, objective='binary:hinge',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train_res_df ,y_train_res.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.5649183147033534\n",
      "Test acuracy:  0.5570435230491888\n",
      "ROC auc score:  0.6305334017799912\n",
      "Confusion matrix: \n",
      "[[2027 1665]\n",
      " [  55  136]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos \n",
    "train_accuracy = accuracy_score(y_train_res, xg_reg.predict(X_train_res_df))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.5649183147033534\n",
      "Test acuracy:  0.5570435230491888\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.55      0.70      3692\n",
      "           1       0.08      0.71      0.14       191\n",
      "\n",
      "   micro avg       0.56      0.56      0.56      3883\n",
      "   macro avg       0.52      0.63      0.42      3883\n",
      "weighted avg       0.93      0.56      0.67      3883\n",
      "\n",
      "\n",
      "Precision Score:  0.07551360355358135\n",
      "Recall Score:  0.7120418848167539\n",
      "F1 Score:  0.13654618473895583\n",
      "Cohen Kappa Score:  0.052248673682274704\n",
      "ROC auc score:  0.6305334017799912\n",
      "Confusion matrix: \n",
      "[[2027 1665]\n",
      " [  55  136]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\\\n",
    "                            f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "# Pruebo todas las metricas.\n",
    "# accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\n",
    "# f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "\n",
    "trainAccuracy = accuracy_score(y_train_res, xg_reg.predict(X_train_res_df))\n",
    "testAccuracy = accuracy_score(y_test, preds)\n",
    "\n",
    "meanSquaredError = mean_squared_error(y_test, preds)\n",
    "classificationReport = classification_report(y_test, preds)\n",
    "precisionScore = precision_score(y_test, preds)\n",
    "recallScore = recall_score(y_test, preds)\n",
    "f1Score = f1_score(y_test, preds)\n",
    "cohenKappaScore = cohen_kappa_score(y_test, preds)\n",
    "areaDebajoDeCurva = roc_auc_score(y_test, preds)\n",
    "matrizDeConfusion = confusion_matrix(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", trainAccuracy)\n",
    "print(\"Test acuracy: \", testAccuracy)\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(classificationReport)\n",
    "print()\n",
    "print(\"Precision Score: \",precisionScore)\n",
    "print(\"Recall Score: \",recallScore)\n",
    "print(\"F1 Score: \",f1Score)\n",
    "print(\"Cohen Kappa Score: \",cohenKappaScore)\n",
    "print(\"ROC auc score: \", areaDebajoDeCurva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matrizDeConfusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = labels_con_promedios_num.iloc[:,:-1], labels_con_promedios_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "#data_dmatrix = xgb.DMatrix(data=X,label=y, weight={1: 1, 0: 0.1})\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18434, 980)"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cant_ceros = np.sum(y == 0)\n",
    "cant_unos = np.sum(y == 1)\n",
    "cant_ceros, cant_unos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(random_state=2, sampling_strategy = {0: 18434, 1: 1219})\n",
    "X_train_res, y_train_res = ros.fit_sample(X, y)\n",
    "X_train_res_df = pd.DataFrame(X_train_res)\n",
    "X_train_res_df.columns = X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBClassifier(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, eval_metric = \"auc\", min_child_weight=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=1, missing=None,\n",
       "       n_estimators=6, n_jobs=1, nthread=None, objective='binary:hinge',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train_res_df ,y_train_res.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.750826845774182\n",
      "Test acuracy:  0.758434200360546\n",
      "ROC auc score:  0.7116143295536408\n",
      "Confusion matrix: \n",
      "[[2819  873]\n",
      " [  65  126]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos \n",
    "train_accuracy = accuracy_score(y_train_res, xg_reg.predict(X_train_res_df))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.750826845774182\n",
      "Test acuracy:  0.758434200360546\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.76      0.86      3692\n",
      "           1       0.13      0.66      0.21       191\n",
      "\n",
      "   micro avg       0.76      0.76      0.76      3883\n",
      "   macro avg       0.55      0.71      0.53      3883\n",
      "weighted avg       0.94      0.76      0.83      3883\n",
      "\n",
      "\n",
      "Precision Score:  0.12612612612612611\n",
      "Recall Score:  0.6596858638743456\n",
      "F1 Score:  0.21176470588235294\n",
      "Cohen Kappa Score:  0.1408059913869566\n",
      "ROC auc score:  0.7116143295536408\n",
      "Confusion matrix: \n",
      "[[2819  873]\n",
      " [  65  126]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\\\n",
    "                            f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "# Pruebo todas las metricas.\n",
    "# accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\n",
    "# f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "\n",
    "trainAccuracy = accuracy_score(y_train_res, xg_reg.predict(X_train_res_df))\n",
    "testAccuracy = accuracy_score(y_test, preds)\n",
    "\n",
    "meanSquaredError = mean_squared_error(y_test, preds)\n",
    "classificationReport = classification_report(y_test, preds)\n",
    "precisionScore = precision_score(y_test, preds)\n",
    "recallScore = recall_score(y_test, preds)\n",
    "f1Score = f1_score(y_test, preds)\n",
    "cohenKappaScore = cohen_kappa_score(y_test, preds)\n",
    "areaDebajoDeCurva = roc_auc_score(y_test, preds)\n",
    "matrizDeConfusion = confusion_matrix(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", trainAccuracy)\n",
    "print(\"Test acuracy: \", testAccuracy)\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(classificationReport)\n",
    "print()\n",
    "print(\"Precision Score: \",precisionScore)\n",
    "print(\"Recall Score: \",recallScore)\n",
    "print(\"F1 Score: \",f1Score)\n",
    "print(\"Cohen Kappa Score: \",cohenKappaScore)\n",
    "print(\"ROC auc score: \", areaDebajoDeCurva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matrizDeConfusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = labels_con_promedios_num.iloc[:,:-1],labels_con_promedios_num.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, y_train)\n",
    "dtest = xgb.DMatrix(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18434, 980)"
      ]
     },
     "execution_count": 473,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cant_ceros = np.sum(y == 0)\n",
    "cant_unos = np.sum(y == 1)\n",
    "cant_ceros, cant_unos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(random_state=2, sampling_strategy = {0: 18434, 1: 1219})\n",
    "X_train_res, y_train_res = ros.fit_sample(X, y)\n",
    "X_train_res_df = pd.DataFrame(X_train_res)\n",
    "X_train_res_df.columns = X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, scale_pos_weight = 4, min_child_weight=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=6,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=4, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 492,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train_res_df,y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.3594419 , 0.5228824 , 0.2852726 , ..., 0.408071  , 0.3316679 ,\n",
       "       0.31432545], dtype=float32)"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict_proba(X_test)[:, 1]\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.9334452755304533\n",
      "Test acuracy:  0.9464331702292043\n",
      "ROC auc score:  0.7834819022876689\n",
      "Confusion matrix: \n",
      "[[3643   49]\n",
      " [ 159   32]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos que onda\n",
    "\n",
    "train_accuracy = accuracy_score(y_train_res, xg_reg.predict(X_train_res_df))\n",
    "test_accuracy = accuracy_score(y_test, xg_reg.predict(X_test))\n",
    "matriz_de_confusion = confusion_matrix(y_test, xg_reg.predict(X_test))\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = labels_con_promedios_num.iloc[:,:-1], labels_con_promedios_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "#data_dmatrix = xgb.DMatrix(data=X,label=y, weight={1: 1, 0: 0.1})\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18434, 980)"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cant_ceros = np.sum(y == 0)\n",
    "cant_unos = np.sum(y == 1)\n",
    "cant_ceros, cant_unos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "ros = RandomUnderSampler(random_state=2, sampling_strategy ={0: 15434, 1: 980 })\n",
    "X_train_res, y_train_res = ros.fit_sample(X, y)\n",
    "X_train_res_df = pd.DataFrame(X_train_res)\n",
    "X_train_res_df.columns = X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBClassifier(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, eval_metric = \"auc\", min_child_weight=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=1, missing=None,\n",
       "       n_estimators=6, n_jobs=1, nthread=None, objective='binary:hinge',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 448,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train_res_df ,y_train_res.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8069940294870233\n",
      "Test acuracy:  0.8127736286376513\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.83      0.89      3692\n",
      "           1       0.14      0.56      0.23       191\n",
      "\n",
      "   micro avg       0.81      0.81      0.81      3883\n",
      "   macro avg       0.56      0.69      0.56      3883\n",
      "weighted avg       0.93      0.81      0.86      3883\n",
      "\n",
      "\n",
      "Precision Score:  0.14266666666666666\n",
      "Recall Score:  0.5602094240837696\n",
      "F1 Score:  0.22741764080765142\n",
      "Cohen Kappa Score:  0.16168602332420556\n",
      "ROC auc score:  0.6930245386941059\n",
      "Confusion matrix: \n",
      "[[3049  643]\n",
      " [  84  107]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\\\n",
    "                            f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "# Pruebo todas las metricas.\n",
    "# accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\n",
    "# f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "\n",
    "trainAccuracy = accuracy_score(y_train_res, xg_reg.predict(X_train_res_df))\n",
    "testAccuracy = accuracy_score(y_test, preds)\n",
    "\n",
    "meanSquaredError = mean_squared_error(y_test, preds)\n",
    "classificationReport = classification_report(y_test, preds)\n",
    "precisionScore = precision_score(y_test, preds)\n",
    "recallScore = recall_score(y_test, preds)\n",
    "f1Score = f1_score(y_test, preds)\n",
    "cohenKappaScore = cohen_kappa_score(y_test, preds)\n",
    "areaDebajoDeCurva = roc_auc_score(y_test, preds)\n",
    "matrizDeConfusion = confusion_matrix(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", trainAccuracy)\n",
    "print(\"Test acuracy: \", testAccuracy)\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(classificationReport)\n",
    "print()\n",
    "print(\"Precision Score: \",precisionScore)\n",
    "print(\"Recall Score: \",recallScore)\n",
    "print(\"F1 Score: \",f1Score)\n",
    "print(\"Cohen Kappa Score: \",cohenKappaScore)\n",
    "print(\"ROC auc score: \", areaDebajoDeCurva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matrizDeConfusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cantidad de eventos particulares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ad campaign hit</th>\n",
       "      <th>search engine hit</th>\n",
       "      <th>promedio_por_mes</th>\n",
       "      <th>promedio_por_dia</th>\n",
       "      <th>cant_dias_dist</th>\n",
       "      <th>modelos_dist</th>\n",
       "      <th>distan_dias</th>\n",
       "      <th>cant_city</th>\n",
       "      <th>cant_src</th>\n",
       "      <th>cant_eng</th>\n",
       "      <th>cant_mod</th>\n",
       "      <th>cant_ev</th>\n",
       "      <th>cant_mes_5_x</th>\n",
       "      <th>cant_entradas</th>\n",
       "      <th>cant_mes_5_y</th>\n",
       "      <th>entradas_30_dias</th>\n",
       "      <th>cant_mes</th>\n",
       "      <th>cant_dia_freq</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17</td>\n",
       "      <td>17.0</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.008493</td>\n",
       "      <td>0.029724</td>\n",
       "      <td>14</td>\n",
       "      <td>26</td>\n",
       "      <td>114</td>\n",
       "      <td>12.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>189</td>\n",
       "      <td>290.0</td>\n",
       "      <td>471</td>\n",
       "      <td>290.0</td>\n",
       "      <td>358</td>\n",
       "      <td>290</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ad campaign hit  search engine hit  promedio_por_mes  promedio_por_dia  \\\n",
       "0              0.0                0.0          0.166667          0.166667   \n",
       "1              1.0                1.0          0.058824          0.058824   \n",
       "2              5.0                0.0          0.052632          0.052632   \n",
       "3             29.0               13.0          0.008493          0.029724   \n",
       "4              0.0                0.0          0.142857          0.142857   \n",
       "\n",
       "   cant_dias_dist  modelos_dist  distan_dias  cant_city  cant_src  cant_eng  \\\n",
       "0               1             3            0        2.0       0.0       0.0   \n",
       "1               1             1            0        1.0       1.0       1.0   \n",
       "2               1             2            0        1.0       5.0       0.0   \n",
       "3              14            26          114       12.0      17.0      12.0   \n",
       "4               1             1            0        0.0       0.0       0.0   \n",
       "\n",
       "   cant_mod  cant_ev  cant_mes_5_x  cant_entradas  cant_mes_5_y  \\\n",
       "0       1.0        3           6.0              6           6.0   \n",
       "1       4.0        9          17.0             17          17.0   \n",
       "2       3.0        5          19.0             19          19.0   \n",
       "3      63.0      189         290.0            471         290.0   \n",
       "4       5.0        2           7.0              7           7.0   \n",
       "\n",
       "   entradas_30_dias  cant_mes  cant_dia_freq  label  \n",
       "0                 5         6              6      0  \n",
       "1                16        17             17      0  \n",
       "2                18        19             19      0  \n",
       "3               358       290             72      0  \n",
       "4                 6         7              7      0  "
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_events = df[[\"person\", \"event\"]]\n",
    "cant_por_evento = pd.concat([pd.get_dummies(df_events['event']),df_events[['person']]],axis = 1).groupby('person')\\\n",
    "    .sum().reset_index()\n",
    "cant_por_evento_short = cant_por_evento[[\"person\", \"ad campaign hit\", \"search engine hit\"]]\n",
    "\n",
    "# Merge ... \"search engine hit\", \"generic listing\", \"searched products\" \"ad campaign hit\", \"brand listing\"\n",
    "\n",
    "labels_con_eventos = pd.merge(cant_por_evento_short, labels_con_promedios, on=\"person\", how=\"inner\")\n",
    "labels_con_eventos_num = labels_con_eventos.drop(columns=\"person\")\n",
    "labels_con_eventos_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veo cuantas personas a predecir pierdo\n",
    "cant_por_evento_short_predecir = pd.merge(cant_por_evento_short, df_persons, on=\"person\", how=\"inner\")\n",
    "cant_por_evento_short_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = labels_con_eventos_num.iloc[:,:-1], labels_con_eventos_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y, weight={1: 1, 0: 0.1})\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, eval_metric = \"auc\", min_child_weight=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=15, missing=None,\n",
       "       n_estimators=6, n_jobs=1, nthread=None, objective='binary:hinge',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8313695190264632\n",
      "Test acuracy:  0.8328611898016998\n",
      "ROC auc score:  0.6365638454164374\n",
      "Confusion matrix: \n",
      "[[3154  538]\n",
      " [ 111   80]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos \n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = labels_con_eventos_num.iloc[:,:-1],labels_con_eventos_num.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, y_train)\n",
    "dtest = xgb.DMatrix(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, scale_pos_weight = 7, min_child_weight=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=6,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=7, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.39336428, 0.61340684, 0.29059574, ..., 0.44678748, 0.35029072,\n",
       "       0.3423286 ], dtype=float32)"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict_proba(X_test)[:, 1]\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.9086343442147962\n",
      "Test acuracy:  0.9090909090909091\n",
      "ROC auc score:  0.7412716330200292\n",
      "Confusion matrix: \n",
      "[[3483  209]\n",
      " [ 144   47]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos que onda\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, xg_reg.predict(X_test))\n",
    "matriz_de_confusion = confusion_matrix(y_test, xg_reg.predict(X_test))\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visitas a productos segun condicion, color y almacenamiento de producto.¶\n",
    "copiado de santi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events_visitas_prod = df.loc[df['event'] == 'viewed product']\n",
    "df_events_visitas_prod = df_events_visitas_prod[['person','storage','color','condition']]\n",
    "\n",
    "df_events_visitas_prod_condition_storage = pd.concat([df_events_visitas_prod['person'],\\\n",
    "           pd.get_dummies(df_events_visitas_prod['storage']),\\\n",
    "           pd.get_dummies(df_events_visitas_prod['condition'])],axis = 1).groupby('person').sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>128GB</th>\n",
       "      <th>16GB</th>\n",
       "      <th>256GB</th>\n",
       "      <th>32GB</th>\n",
       "      <th>4GB</th>\n",
       "      <th>512MB</th>\n",
       "      <th>64GB</th>\n",
       "      <th>8GB</th>\n",
       "      <th>Bom</th>\n",
       "      <th>...</th>\n",
       "      <th>Azul</th>\n",
       "      <th>Branco</th>\n",
       "      <th>Cinza espacial</th>\n",
       "      <th>Dourado</th>\n",
       "      <th>Ouro Rosa</th>\n",
       "      <th>Prata</th>\n",
       "      <th>Prateado</th>\n",
       "      <th>Preto</th>\n",
       "      <th>Preto Matte</th>\n",
       "      <th>Rosa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00091926</td>\n",
       "      <td>48.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091a7a</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000ba417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000c79fe</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000e4d9e</td>\n",
       "      <td>1.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  128GB   16GB  256GB   32GB  4GB  512MB  64GB   8GB    Bom  ...   \\\n",
       "0  00091926   48.0  104.0   10.0  132.0  0.0    0.0  78.0   0.0  102.0  ...    \n",
       "1  00091a7a    1.0    1.0    0.0    0.0  0.0    0.0   1.0   0.0    1.0  ...    \n",
       "2  000ba417    0.0  108.0    1.0   20.0  1.0    0.0   1.0  22.0  110.0  ...    \n",
       "3  000c79fe    3.0    0.0    0.0    0.0  0.0    0.0   0.0   0.0    3.0  ...    \n",
       "4  000e4d9e    1.0  108.0    1.0  208.0  0.0    0.0  21.0   0.0  124.0  ...    \n",
       "\n",
       "   Azul  Branco  Cinza espacial  Dourado  Ouro Rosa  Prata  Prateado  Preto  \\\n",
       "0   3.0     3.0            65.0    101.0       28.0    1.0      43.0   79.0   \n",
       "1   0.0     0.0             1.0      1.0        1.0    0.0       0.0    0.0   \n",
       "2   4.0    15.0             1.0     14.0        0.0    0.0       0.0   71.0   \n",
       "3   0.0     0.0             0.0      0.0        0.0    0.0       0.0    0.0   \n",
       "4  23.0    85.0            14.0     46.0        2.0    6.0       1.0  149.0   \n",
       "\n",
       "   Preto Matte  Rosa  \n",
       "0         29.0   3.0  \n",
       "1          0.0   0.0  \n",
       "2          0.0   7.0  \n",
       "3          3.0   0.0  \n",
       "4          0.0   9.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10_colores = df_events_visitas_prod['color'].value_counts().head(10).index\n",
    "\n",
    "\n",
    "df_events_visitas_prod_color = df_events_visitas_prod.loc[df_events_visitas_prod['color'].isin(top_10_colores)]\n",
    "df_events_visitas_prod_color = pd.concat([df_events_visitas_prod_color['person'],\\\n",
    "                                          pd.get_dummies(df_events_visitas_prod_color['color'])],axis = 1)\n",
    "\n",
    "df_events_visitas_prod_color = df_events_visitas_prod_color.groupby('person').sum().reset_index()\n",
    "\n",
    "df_events_visitas_prod_color_storage_condition = pd.merge(df_events_visitas_prod_condition_storage,\\\n",
    "                        df_events_visitas_prod_color, on = 'person', how = 'inner')\n",
    "\n",
    "\n",
    "df_events_visitas_prod_color_storage_condition = pd.merge(df_events_visitas_prod_color_storage_condition, todas_las_personas, on=\"person\", how=\"right\").fillna(0)\n",
    "df_events_visitas_prod_color_storage_condition.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veo cuantas personas a predecir pierdo\n",
    "visitas_prod_color_storage_condition_predecir = pd.merge(df_events_visitas_prod_color_storage_condition, df_persons, on=\"person\", how=\"inner\")\n",
    "visitas_prod_color_storage_condition_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>128GB</th>\n",
       "      <th>16GB</th>\n",
       "      <th>256GB</th>\n",
       "      <th>32GB</th>\n",
       "      <th>4GB</th>\n",
       "      <th>512MB</th>\n",
       "      <th>64GB</th>\n",
       "      <th>8GB</th>\n",
       "      <th>Bom</th>\n",
       "      <th>Bom - Sem Touch ID</th>\n",
       "      <th>...</th>\n",
       "      <th>cant_eng</th>\n",
       "      <th>cant_mod</th>\n",
       "      <th>cant_ev</th>\n",
       "      <th>cant_mes_5_x</th>\n",
       "      <th>cant_entradas</th>\n",
       "      <th>cant_mes_5_y</th>\n",
       "      <th>entradas_30_dias</th>\n",
       "      <th>cant_mes</th>\n",
       "      <th>cant_dia_freq</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17</td>\n",
       "      <td>17.0</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>189</td>\n",
       "      <td>290.0</td>\n",
       "      <td>471</td>\n",
       "      <td>290.0</td>\n",
       "      <td>358</td>\n",
       "      <td>290</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>52</td>\n",
       "      <td>54.0</td>\n",
       "      <td>96</td>\n",
       "      <td>54.0</td>\n",
       "      <td>64</td>\n",
       "      <td>54</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   128GB  16GB  256GB  32GB  4GB  512MB  64GB   8GB    Bom  \\\n",
       "0    3.0   0.0    0.0   0.0  0.0    0.0   0.0   0.0    3.0   \n",
       "1    0.0   0.0    2.0   0.0  0.0    0.0   2.0   0.0    2.0   \n",
       "2    0.0  94.0    0.0  14.0  0.0    0.0   0.0  81.0  105.0   \n",
       "3    1.0   0.0    0.0   0.0  0.0    0.0   1.0   0.0    0.0   \n",
       "4    8.0  19.0    4.0  11.0  0.0    0.0  10.0   0.0    9.0   \n",
       "\n",
       "   Bom - Sem Touch ID  ...    cant_eng  cant_mod  cant_ev  cant_mes_5_x  \\\n",
       "0                 0.0  ...         1.0       4.0        9          17.0   \n",
       "1                 0.0  ...         0.0       3.0        5          19.0   \n",
       "2                 0.0  ...        12.0      63.0      189         290.0   \n",
       "3                 0.0  ...         0.0       5.0        2           7.0   \n",
       "4                 0.0  ...         6.0      20.0       52          54.0   \n",
       "\n",
       "   cant_entradas  cant_mes_5_y  entradas_30_dias  cant_mes  cant_dia_freq  \\\n",
       "0             17          17.0                16        17             17   \n",
       "1             19          19.0                18        19             19   \n",
       "2            471         290.0               358       290             72   \n",
       "3              7           7.0                 6         7              7   \n",
       "4             96          54.0                64        54             17   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge\n",
    "\n",
    "labels_con_storage_color = pd.merge(df_events_visitas_prod_color_storage_condition, labels_con_eventos, on=\"person\", how=\"inner\")\n",
    "labels_con_storage_color_num = labels_con_storage_color.drop(columns=\"person\")\n",
    "labels_con_storage_color_num.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = labels_con_storage_color_num.iloc[:,:-1], labels_con_storage_color_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y, weight={1: 1, 0: 0.1})\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, eval_metric = \"auc\", min_child_weight=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=15, missing=None,\n",
       "       n_estimators=6, n_jobs=1, nthread=None, objective='binary:hinge',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8342025626167021\n",
      "Test acuracy:  0.8269379345866598\n",
      "ROC auc score:  0.6305553149094689\n",
      "Confusion matrix: \n",
      "[[3131  558]\n",
      " [ 114   80]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos \n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entro como 'new' en el mes 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>is_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4886f805</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d6288188</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4858040e</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a6538d3e</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b884c881</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  is_new\n",
       "0  4886f805     0.0\n",
       "1  d6288188     0.0\n",
       "2  4858040e     0.0\n",
       "3  a6538d3e     0.0\n",
       "4  b884c881     0.0"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mes_5 = df[[\"person\", \"month\", \"new_vs_returning\"]].loc[df[\"month\"] == 5]\n",
    "df_mes_5[\"is_new\"] = (df_mes_5[\"new_vs_returning\"] == \"New\") * 1\n",
    "df_mew_5 = df_mes_5[[\"person\", \"is_new\"]]\n",
    "df_mew_5 = df_mew_5.sort_values(\"is_new\", ascending=True)\n",
    "df_mew_5 = df_mew_5.drop_duplicates(subset=['person'])\n",
    "df_mew_5 = pd.merge(df_mew_5, todas_las_personas, on=\"person\", how=\"right\").fillna(0)\n",
    "df_mew_5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veo cuantas personas a predecir pierdo\n",
    "df_mew_5_predecir = pd.merge(df_mew_5, df_persons, on=\"person\", how=\"inner\")\n",
    "df_mew_5_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge\n",
    "\n",
    "labels_con_new_mes5 = pd.merge(df_mew_5, labels_con_storage_color, on=\"person\", how=\"inner\")\n",
    "labels_con_new_mes5_num = labels_con_new_mes5.drop(columns=\"person\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = labels_con_new_mes5_num.iloc[:,:-1], labels_con_new_mes5_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y, weight={1: 1, 0: 0.1})\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, eval_metric = \"auc\", min_child_weight=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=4, missing=None,\n",
       "       n_estimators=6, n_jobs=1, nthread=None, objective='binary:hinge',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8540982551026979\n",
      "Test acuracy:  0.8524336852948751\n",
      "ROC auc score:  0.6102463712757831\n",
      "Confusion matrix: \n",
      "[[3246  450]\n",
      " [ 123   64]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos \n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -- Agrego cosas de Santi --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cantidad de visitas a los 15 modelos mas visitados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ad93850f</td>\n",
       "      <td>iPhone 5s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0297fc1e</td>\n",
       "      <td>iPhone 6S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2d681dd8</td>\n",
       "      <td>iPhone 7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1b9f7cf6</td>\n",
       "      <td>iPhone 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>29ebb414</td>\n",
       "      <td>iPhone 6 Plus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person          model\n",
       "1  ad93850f      iPhone 5s\n",
       "2  0297fc1e      iPhone 6S\n",
       "3  2d681dd8       iPhone 7\n",
       "6  1b9f7cf6       iPhone 6\n",
       "7  29ebb414  iPhone 6 Plus"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_visitas_producto = df.loc[df['event'] == 'viewed product']\n",
    "top_15 = df_visitas_producto['model'].value_counts().head(15).index\n",
    "df_15_productos_mas_visitados = df_visitas_producto.loc[df_visitas_producto['model'].isin(top_15)]\n",
    "\n",
    "df_15_productos_mas_visitados = df_15_productos_mas_visitados[['person','model']]\n",
    "df_15_productos_mas_visitados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>Samsung Galaxy J5</th>\n",
       "      <th>Samsung Galaxy S6 Edge</th>\n",
       "      <th>Samsung Galaxy S6 Flat</th>\n",
       "      <th>Samsung Galaxy S7</th>\n",
       "      <th>Samsung Galaxy S7 Edge</th>\n",
       "      <th>Samsung Galaxy S8</th>\n",
       "      <th>iPhone 5c</th>\n",
       "      <th>iPhone 5s</th>\n",
       "      <th>iPhone 6</th>\n",
       "      <th>iPhone 6 Plus</th>\n",
       "      <th>iPhone 6S</th>\n",
       "      <th>iPhone 6S Plus</th>\n",
       "      <th>iPhone 7</th>\n",
       "      <th>iPhone 7 Plus</th>\n",
       "      <th>iPhone SE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00091926</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091a7a</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000ba417</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000c79fe</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000e4d9e</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  Samsung Galaxy J5  Samsung Galaxy S6 Edge  \\\n",
       "0  00091926                1.0                     3.0   \n",
       "1  00091a7a                0.0                     0.0   \n",
       "2  000ba417               11.0                     0.0   \n",
       "3  000c79fe                0.0                     0.0   \n",
       "4  000e4d9e                1.0                     5.0   \n",
       "\n",
       "   Samsung Galaxy S6 Flat  Samsung Galaxy S7  Samsung Galaxy S7 Edge  \\\n",
       "0                    15.0                1.0                     9.0   \n",
       "1                     0.0                0.0                     0.0   \n",
       "2                     1.0                0.0                     0.0   \n",
       "3                     0.0                0.0                     0.0   \n",
       "4                   139.0               22.0                     2.0   \n",
       "\n",
       "   Samsung Galaxy S8  iPhone 5c  iPhone 5s  iPhone 6  iPhone 6 Plus  \\\n",
       "0                5.0        0.0        0.0       5.0           41.0   \n",
       "1                0.0        0.0        0.0       1.0            0.0   \n",
       "2                0.0        6.0        1.0       0.0            0.0   \n",
       "3                0.0        0.0        0.0       0.0            0.0   \n",
       "4                9.0        0.0        7.0       0.0            0.0   \n",
       "\n",
       "   iPhone 6S  iPhone 6S Plus  iPhone 7  iPhone 7 Plus  iPhone SE  \n",
       "0       94.0            51.0      45.0            9.0        3.0  \n",
       "1        1.0             0.0       0.0            0.0        1.0  \n",
       "2        0.0             0.0       1.0            0.0        0.0  \n",
       "3        0.0             0.0       3.0            0.0        0.0  \n",
       "4        1.0             0.0       1.0            0.0       11.0  "
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_15_productos_mas_visitados = pd.concat([df_15_productos_mas_visitados,\\\n",
    "                    pd.get_dummies(df_15_productos_mas_visitados['model'])],axis = 1)\n",
    "\n",
    "df_15_productos_mas_visitados = df_15_productos_mas_visitados.groupby('person').sum().reset_index()\n",
    "df_15_productos_mas_visitados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>vis_Samsung Galaxy J5</th>\n",
       "      <th>vis_Samsung Galaxy S6 Edge</th>\n",
       "      <th>vis_Samsung Galaxy S6 Flat</th>\n",
       "      <th>vis_Samsung Galaxy S7</th>\n",
       "      <th>vis_Samsung Galaxy S7 Edge</th>\n",
       "      <th>vis_Samsung Galaxy S8</th>\n",
       "      <th>vis_iPhone 5c</th>\n",
       "      <th>vis_iPhone 5s</th>\n",
       "      <th>vis_iPhone 6</th>\n",
       "      <th>vis_iPhone 6 Plus</th>\n",
       "      <th>vis_iPhone 6S</th>\n",
       "      <th>vis_iPhone 6S Plus</th>\n",
       "      <th>vis_iPhone 7</th>\n",
       "      <th>vis_iPhone 7 Plus</th>\n",
       "      <th>vis_iPhone SE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00091926</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091a7a</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000ba417</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000c79fe</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000e4d9e</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  vis_Samsung Galaxy J5  vis_Samsung Galaxy S6 Edge  \\\n",
       "0  00091926                    1.0                         3.0   \n",
       "1  00091a7a                    0.0                         0.0   \n",
       "2  000ba417                   11.0                         0.0   \n",
       "3  000c79fe                    0.0                         0.0   \n",
       "4  000e4d9e                    1.0                         5.0   \n",
       "\n",
       "   vis_Samsung Galaxy S6 Flat  vis_Samsung Galaxy S7  \\\n",
       "0                        15.0                    1.0   \n",
       "1                         0.0                    0.0   \n",
       "2                         1.0                    0.0   \n",
       "3                         0.0                    0.0   \n",
       "4                       139.0                   22.0   \n",
       "\n",
       "   vis_Samsung Galaxy S7 Edge  vis_Samsung Galaxy S8  vis_iPhone 5c  \\\n",
       "0                         9.0                    5.0            0.0   \n",
       "1                         0.0                    0.0            0.0   \n",
       "2                         0.0                    0.0            6.0   \n",
       "3                         0.0                    0.0            0.0   \n",
       "4                         2.0                    9.0            0.0   \n",
       "\n",
       "   vis_iPhone 5s  vis_iPhone 6  vis_iPhone 6 Plus  vis_iPhone 6S  \\\n",
       "0            0.0           5.0               41.0           94.0   \n",
       "1            0.0           1.0                0.0            1.0   \n",
       "2            1.0           0.0                0.0            0.0   \n",
       "3            0.0           0.0                0.0            0.0   \n",
       "4            7.0           0.0                0.0            1.0   \n",
       "\n",
       "   vis_iPhone 6S Plus  vis_iPhone 7  vis_iPhone 7 Plus  vis_iPhone SE  \n",
       "0                51.0          45.0                9.0            3.0  \n",
       "1                 0.0           0.0                0.0            1.0  \n",
       "2                 0.0           1.0                0.0            0.0  \n",
       "3                 0.0           3.0                0.0            0.0  \n",
       "4                 0.0           1.0                0.0           11.0  "
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vis = visitas\n",
    "nombres_columnas = ['vis_'+columna for columna in df_15_productos_mas_visitados.columns]\n",
    "nombres_columnas[0] = 'person'\n",
    "df_15_productos_mas_visitados.columns = nombres_columnas\n",
    "\n",
    "df_15_productos_mas_visitados = pd.merge(df_15_productos_mas_visitados, todas_las_personas, on=\"person\", how=\"right\").fillna(0)\n",
    "\n",
    "df_15_productos_mas_visitados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veo cuantas personas a predecir pierdo\n",
    "df_15_productos_mas_visitados_predecir = pd.merge(df_15_productos_mas_visitados, df_persons, on=\"person\", how=\"inner\")\n",
    "df_15_productos_mas_visitados_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 38829 entries, 0 to 38828\n",
      "Data columns (total 27 columns):\n",
      "person                        38829 non-null object\n",
      "vis_Samsung Galaxy J5         38829 non-null float64\n",
      "vis_Samsung Galaxy S6 Edge    38829 non-null float64\n",
      "vis_Samsung Galaxy S6 Flat    38829 non-null float64\n",
      "vis_Samsung Galaxy S7         38829 non-null float64\n",
      "vis_Samsung Galaxy S7 Edge    38829 non-null float64\n",
      "vis_Samsung Galaxy S8         38829 non-null float64\n",
      "vis_iPhone 5c                 38829 non-null float64\n",
      "vis_iPhone 5s                 38829 non-null float64\n",
      "vis_iPhone 6                  38829 non-null float64\n",
      "vis_iPhone 6 Plus             38829 non-null float64\n",
      "vis_iPhone 6S                 38829 non-null float64\n",
      "vis_iPhone 6S Plus            38829 non-null float64\n",
      "vis_iPhone 7                  38829 non-null float64\n",
      "vis_iPhone 7 Plus             38829 non-null float64\n",
      "vis_iPhone SE                 38829 non-null float64\n",
      "ad campaign hit               38829 non-null float64\n",
      "brand listing                 38829 non-null float64\n",
      "checkout                      38829 non-null float64\n",
      "conversion                    38829 non-null float64\n",
      "generic listing               38829 non-null float64\n",
      "lead                          38829 non-null float64\n",
      "search engine hit             38829 non-null float64\n",
      "searched products             38829 non-null float64\n",
      "staticpage                    38829 non-null float64\n",
      "viewed product                38829 non-null float64\n",
      "visited site                  38829 non-null float64\n",
      "dtypes: float64(26), object(1)\n",
      "memory usage: 8.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train_sin_labels = pd.merge(df_15_productos_mas_visitados,cant_por_evento,on = 'person',how = 'outer')\n",
    "\n",
    "df_train_sin_labels.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probar 2 alternativas\n",
    "df_train_sin_labels1 = df_train_sin_labels.dropna()\n",
    "df_train_sin_labels2 = df_train_sin_labels.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge\n",
    "\n",
    "labels_con_15_modelos = pd.merge(df_15_productos_mas_visitados, labels_con_new_mes5, on=\"person\", how=\"inner\")\n",
    "labels_con_15_modelos_num = labels_con_15_modelos.drop(columns=\"person\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = labels_con_15_modelos_num.iloc[:,:-1], labels_con_15_modelos_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y, weight={1: 1, 0: 0.1})\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, eval_metric = \"auc\", min_child_weight=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=10, missing=None,\n",
       "       n_estimators=6, n_jobs=1, nthread=None, objective='binary:hinge',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8465649346468354\n",
      "Test acuracy:  0.8403296420293588\n",
      "ROC auc score:  0.6333179732429994\n",
      "Confusion matrix: \n",
      "[[3184  503]\n",
      " [ 117   79]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos \n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- Aca bajó de 65 a 60!! ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estado(region) del usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sao Paulo',\n",
       " 'Minas Gerais',\n",
       " 'Rio de Janeiro',\n",
       " 'Bahia',\n",
       " 'Pernambuco',\n",
       " 'Ceara',\n",
       " 'Parana',\n",
       " 'Rio Grande do Sul',\n",
       " 'Espirito Santo',\n",
       " 'Federal District',\n",
       " 'Maranhao',\n",
       " 'Goias',\n",
       " 'Santa Catarina',\n",
       " 'Para',\n",
       " 'Rio Grande do Norte',\n",
       " 'Paraíba',\n",
       " 'Piaui',\n",
       " 'Alagoas',\n",
       " 'Sergipe',\n",
       " 'Amazonas']"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_20_estados = list(df['region'].value_counts().head(21).index)\n",
    "del top_20_estados[1]\n",
    "top_20_estados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2151588</th>\n",
       "      <td>0869b313</td>\n",
       "      <td>Pernambuco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150498</th>\n",
       "      <td>78561ee9</td>\n",
       "      <td>Sao Paulo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2294065</th>\n",
       "      <td>540e67b1</td>\n",
       "      <td>Pernambuco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2248029</th>\n",
       "      <td>041627fe</td>\n",
       "      <td>Federal District</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2151706</th>\n",
       "      <td>62acae45</td>\n",
       "      <td>Minas Gerais</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           person            region\n",
       "2151588  0869b313        Pernambuco\n",
       "2150498  78561ee9         Sao Paulo\n",
       "2294065  540e67b1        Pernambuco\n",
       "2248029  041627fe  Federal District\n",
       "2151706  62acae45      Minas Gerais"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_estado = df[['person','region','month']]\n",
    "df_estado = df_estado.sort_values('month',ascending = True).dropna()\n",
    "\n",
    "df_estado = df_estado.loc[df_estado['region'].isin(top_20_estados)]\n",
    "\n",
    "\n",
    "df_estado = df_estado.drop_duplicates(subset = 'person', keep = 'last').drop(columns = ['month'])\n",
    "\n",
    "df_estado.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROBAR 2 OPCIONES (LabelEncoder o con One hot encoding)\n",
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "df_estado1 = df_estado.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0869b313</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>78561ee9</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>540e67b1</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>041627fe</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62acae45</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  region\n",
       "0  0869b313    12.0\n",
       "1  78561ee9    18.0\n",
       "2  540e67b1    12.0\n",
       "3  041627fe     5.0\n",
       "4  62acae45     8.0"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_estado1['region'] = le.fit_transform(df_estado1['region'])\n",
    "df_estado1 = pd.merge(df_estado1, todas_las_personas, on=\"person\", how=\"right\").fillna(0)\n",
    "\n",
    "df_estado1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>Alagoas</th>\n",
       "      <th>Amazonas</th>\n",
       "      <th>Bahia</th>\n",
       "      <th>Ceara</th>\n",
       "      <th>Espirito Santo</th>\n",
       "      <th>Federal District</th>\n",
       "      <th>Goias</th>\n",
       "      <th>Maranhao</th>\n",
       "      <th>Minas Gerais</th>\n",
       "      <th>...</th>\n",
       "      <th>Parana</th>\n",
       "      <th>Paraíba</th>\n",
       "      <th>Pernambuco</th>\n",
       "      <th>Piaui</th>\n",
       "      <th>Rio Grande do Norte</th>\n",
       "      <th>Rio Grande do Sul</th>\n",
       "      <th>Rio de Janeiro</th>\n",
       "      <th>Santa Catarina</th>\n",
       "      <th>Sao Paulo</th>\n",
       "      <th>Sergipe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0869b313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>78561ee9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>540e67b1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>041627fe</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62acae45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  Alagoas  Amazonas  Bahia  Ceara  Espirito Santo  \\\n",
       "0  0869b313      0.0       0.0    0.0    0.0             0.0   \n",
       "1  78561ee9      0.0       0.0    0.0    0.0             0.0   \n",
       "2  540e67b1      0.0       0.0    0.0    0.0             0.0   \n",
       "3  041627fe      0.0       0.0    0.0    0.0             0.0   \n",
       "4  62acae45      0.0       0.0    0.0    0.0             0.0   \n",
       "\n",
       "   Federal District  Goias  Maranhao  Minas Gerais   ...     Parana  Paraíba  \\\n",
       "0               0.0    0.0       0.0           0.0   ...        0.0      0.0   \n",
       "1               0.0    0.0       0.0           0.0   ...        0.0      0.0   \n",
       "2               0.0    0.0       0.0           0.0   ...        0.0      0.0   \n",
       "3               1.0    0.0       0.0           0.0   ...        0.0      0.0   \n",
       "4               0.0    0.0       0.0           1.0   ...        0.0      0.0   \n",
       "\n",
       "   Pernambuco  Piaui  Rio Grande do Norte  Rio Grande do Sul  Rio de Janeiro  \\\n",
       "0         1.0    0.0                  0.0                0.0             0.0   \n",
       "1         0.0    0.0                  0.0                0.0             0.0   \n",
       "2         1.0    0.0                  0.0                0.0             0.0   \n",
       "3         0.0    0.0                  0.0                0.0             0.0   \n",
       "4         0.0    0.0                  0.0                0.0             0.0   \n",
       "\n",
       "   Santa Catarina  Sao Paulo  Sergipe  \n",
       "0             0.0        0.0      0.0  \n",
       "1             0.0        1.0      0.0  \n",
       "2             0.0        0.0      0.0  \n",
       "3             0.0        0.0      0.0  \n",
       "4             0.0        0.0      0.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_estado2 = 0\n",
    "df_estado2 = pd.concat([df_estado['person'],pd.get_dummies(df_estado['region'])],axis=1)\n",
    "df_estado2 = pd.merge(df_estado2, todas_las_personas, on=\"person\", how=\"right\").fillna(0)\n",
    "df_estado2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veo cuantas personas a predecir pierdo\n",
    "df_estado2_predecir = pd.merge(df_estado2, df_persons, on=\"person\", how=\"inner\")\n",
    "df_estado2_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veo cuantas personas a predecir pierdo\n",
    "df_estado1_predecir = pd.merge(df_estado1, df_persons, on=\"person\", how=\"inner\")\n",
    "df_estado1_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge\n",
    "\n",
    "labels_con_regiones = pd.merge(df_estado2, labels_con_15_modelos, on=\"person\", how=\"inner\")\n",
    "labels_con_regiones_num = labels_con_regiones.drop(columns=\"person\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = labels_con_regiones_num.iloc[:,:-1], labels_con_regiones_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y, weight={1: 1, 0: 0.1})\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, eval_metric = \"auc\", min_child_weight=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=1, missing=None,\n",
       "       n_estimators=6, n_jobs=1, nthread=None, objective='binary:hinge',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8478526817333076\n",
      "Test acuracy:  0.8405871748647953\n",
      "ROC auc score:  0.6250383146701501\n",
      "Confusion matrix: \n",
      "[[3191  503]\n",
      " [ 116   73]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos \n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " --- ¿¿¿?? aca se cagó todo, paso a 0.5, wtf. Tanto con LE como con OHE ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cantidad de veces que accede desde cada dispositivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>Computer</th>\n",
       "      <th>Smartphone</th>\n",
       "      <th>Tablet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008ed71</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091926</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00091a7a</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000ba417</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000c79fe</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  Computer  Smartphone  Tablet\n",
       "0  0008ed71       2.0         0.0     0.0\n",
       "1  00091926      34.0         0.0     0.0\n",
       "2  00091a7a       0.0         1.0     0.0\n",
       "3  000ba417       6.0         0.0     0.0\n",
       "4  000c79fe       0.0         1.0     0.0"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_device = df.loc[df['event'] == 'visited site']\n",
    "\n",
    "df_device = df_device[['person','device_type']]\n",
    "\n",
    "df_device = pd.concat([df_device['person'],pd.get_dummies(df_device['device_type'])],axis = 1)\n",
    "\n",
    "df_device.drop(columns = ['Unknown'],inplace = True)\n",
    "\n",
    "df_device = df_device.groupby('person').sum().reset_index()\n",
    "\n",
    "df_device = pd.merge(df_device, todas_las_personas, on=\"person\", how=\"right\").fillna(0)\n",
    "\n",
    "\n",
    "df_device.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo mismo se podria hacer pero considerando las visitas a producto desde cada movil.\n",
    "# Ver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 360,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veo cuantas personas a predecir pierdo\n",
    "df_device_predecir = pd.merge(df_device, df_persons, on=\"person\", how=\"inner\")\n",
    "df_device_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge\n",
    "\n",
    "labels_con_dispositivos = pd.merge(df_device, labels_con_15_modelos, on=\"person\", how=\"inner\")\n",
    "labels_con_dispositivos_num = labels_con_dispositivos.drop(columns=\"person\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = labels_con_dispositivos_num.iloc[:,:-1], labels_con_dispositivos_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y, weight={1: 1, 0: 0.1})\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, eval_metric = \"auc\", min_child_weight=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=20, missing=None,\n",
       "       n_estimators=6, n_jobs=1, nthread=None, objective='binary:hinge',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8575751722361729\n",
      "Test acuracy:  0.8465104300798352\n",
      "ROC auc score:  0.5995195305629726\n",
      "Confusion matrix: \n",
      "[[3221  458]\n",
      " [ 138   66]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos \n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visitas a la pagina segun resolucion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>1024x768</th>\n",
       "      <th>1360x768</th>\n",
       "      <th>1366x768</th>\n",
       "      <th>1440x900</th>\n",
       "      <th>1600x900</th>\n",
       "      <th>1920x1080</th>\n",
       "      <th>320x534</th>\n",
       "      <th>320x568</th>\n",
       "      <th>320x570</th>\n",
       "      <th>360x640</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008ed71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091926</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00091a7a</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000ba417</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000c79fe</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  1024x768  1360x768  1366x768  1440x900  1600x900  1920x1080  \\\n",
       "0  0008ed71       0.0       0.0       0.0       0.0       0.0        2.0   \n",
       "1  00091926      34.0       0.0       0.0       0.0       0.0        0.0   \n",
       "2  00091a7a       0.0       0.0       0.0       0.0       0.0        0.0   \n",
       "3  000ba417       6.0       0.0       0.0       0.0       0.0        0.0   \n",
       "4  000c79fe       0.0       0.0       0.0       0.0       0.0        0.0   \n",
       "\n",
       "   320x534  320x568  320x570  360x640  \n",
       "0      0.0      0.0      0.0      0.0  \n",
       "1      0.0      0.0      0.0      0.0  \n",
       "2      0.0      0.0      0.0      1.0  \n",
       "3      0.0      0.0      0.0      0.0  \n",
       "4      0.0      0.0      0.0      1.0  "
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resolucion = df.loc[df['event'] == 'visited site']\n",
    "df_resolucion = df_resolucion[['person','screen_resolution']].dropna()\n",
    "\n",
    "top_5_resoluciones = df_resolucion['screen_resolution'].value_counts().head(10).index\n",
    "df_resolucion = df_resolucion.loc[df_resolucion['screen_resolution'].isin(top_5_resoluciones)]\n",
    "df_resolucion = pd.concat([df_resolucion['person'],\\\n",
    "        pd.get_dummies(df_resolucion['screen_resolution'])],axis = 1).groupby('person').sum().reset_index()\n",
    "\n",
    "df_resolucion = pd.merge(df_resolucion, todas_las_personas, on=\"person\", how=\"right\").fillna(0)\n",
    "\n",
    "df_resolucion.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1024x768</th>\n",
       "      <th>1360x768</th>\n",
       "      <th>1366x768</th>\n",
       "      <th>1440x900</th>\n",
       "      <th>1600x900</th>\n",
       "      <th>1920x1080</th>\n",
       "      <th>320x534</th>\n",
       "      <th>320x568</th>\n",
       "      <th>320x570</th>\n",
       "      <th>360x640</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>38829.000000</td>\n",
       "      <td>38829.000000</td>\n",
       "      <td>38829.000000</td>\n",
       "      <td>38829.000000</td>\n",
       "      <td>38829.000000</td>\n",
       "      <td>38829.000000</td>\n",
       "      <td>38829.000000</td>\n",
       "      <td>38829.000000</td>\n",
       "      <td>38829.000000</td>\n",
       "      <td>38829.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.154266</td>\n",
       "      <td>0.170285</td>\n",
       "      <td>1.281516</td>\n",
       "      <td>0.142368</td>\n",
       "      <td>0.158129</td>\n",
       "      <td>0.204692</td>\n",
       "      <td>0.196554</td>\n",
       "      <td>0.114116</td>\n",
       "      <td>0.133199</td>\n",
       "      <td>1.886065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.700296</td>\n",
       "      <td>1.907744</td>\n",
       "      <td>5.156652</td>\n",
       "      <td>1.606356</td>\n",
       "      <td>1.929644</td>\n",
       "      <td>2.114615</td>\n",
       "      <td>1.843201</td>\n",
       "      <td>1.318921</td>\n",
       "      <td>1.453222</td>\n",
       "      <td>6.464359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>105.000000</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>246.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>293.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           1024x768      1360x768      1366x768      1440x900      1600x900  \\\n",
       "count  38829.000000  38829.000000  38829.000000  38829.000000  38829.000000   \n",
       "mean       0.154266      0.170285      1.281516      0.142368      0.158129   \n",
       "std        1.700296      1.907744      5.156652      1.606356      1.929644   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max      105.000000    133.000000    246.000000     99.000000    116.000000   \n",
       "\n",
       "          1920x1080       320x534       320x568       320x570       360x640  \n",
       "count  38829.000000  38829.000000  38829.000000  38829.000000  38829.000000  \n",
       "mean       0.204692      0.196554      0.114116      0.133199      1.886065  \n",
       "std        2.114615      1.843201      1.318921      1.453222      6.464359  \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000  \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000  \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000  \n",
       "75%        0.000000      0.000000      0.000000      0.000000      1.000000  \n",
       "max      146.000000    124.000000     78.000000     75.000000    293.000000  "
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resolucion.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creo que es mucho 20 resoluciones, probar (quizas empeore).."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veo cuantas personas a predecir pierdo\n",
    "df_resolucion_predecir = pd.merge(df_resolucion, df_persons, on=\"person\", how=\"inner\")\n",
    "df_resolucion_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge\n",
    "\n",
    "labels_con_resoluciones = pd.merge(df_resolucion, labels_con_dispositivos, on=\"person\", how=\"inner\")\n",
    "labels_con_resoluciones_num = labels_con_resoluciones.drop(columns=\"person\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19414, 72)"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_con_resoluciones.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dfs=0\\ndfs =[mes_dia_mas_entradas, entradas_30_dias_df, df_con_mes_5, entradas_tot,      cant_checkouts_tot, mayor_ciudad, mayor_camp, mayor_engine, mayor_modelo, mayor_evento, df_con_check     , distancia_dias, cant_modelos, cant_dias_dist, entradas_tot_y_dias, entradas_tot_y_meses,      df_events_visitas_prod_color_storage_condition, df_mew_5, df_device, df_resolucion,      df_sistema]\\n\\ndf_mejor = pd.concat(dfs, axis=1).reset_index()'"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Super Merge\n",
    "\"\"\"dfs=0\n",
    "dfs =[mes_dia_mas_entradas, entradas_30_dias_df, df_con_mes_5, entradas_tot,\\\n",
    "      cant_checkouts_tot, mayor_ciudad, mayor_camp, mayor_engine, mayor_modelo, mayor_evento, df_con_check\\\n",
    "     , distancia_dias, cant_modelos, cant_dias_dist, entradas_tot_y_dias, entradas_tot_y_meses,\\\n",
    "      df_events_visitas_prod_color_storage_condition, df_mew_5, df_device, df_resolucion,\\\n",
    "      df_sistema]\n",
    "\n",
    "df_mejor = pd.concat(dfs, axis=1).reset_index()\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = labels_con_resoluciones_num.iloc[:,:-1], labels_con_resoluciones_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y, weight={1: 1, 0: 0.1})\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, eval_metric = \"auc\", min_child_weight=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=16, missing=None,\n",
       "       n_estimators=6, n_jobs=1, nthread=None, objective='binary:hinge',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.850106239134634\n",
      "Test acuracy:  0.84393510172547\n",
      "ROC auc score:  0.6774540894209073\n",
      "Confusion matrix: \n",
      "[[3173  498]\n",
      " [ 108  104]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos \n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = labels_con_resoluciones_num.iloc[:,:-1],labels_con_resoluciones_num.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, y_train)\n",
    "dtest = xgb.DMatrix(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, scale_pos_weight = 7, min_child_weight=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=6,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=7, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.33288836, 0.28972083, 0.4415593 , ..., 0.31668237, 0.4630233 ,\n",
       "       0.3611661 ], dtype=float32)"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict_proba(X_test)[:, 1]\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.9370935548258322\n",
      "Test acuracy:  0.9255730105588462\n",
      "ROC auc score:  0.7726057883564708\n",
      "Confusion matrix: \n",
      "[[3554  117]\n",
      " [ 172   40]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos que onda\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, xg_reg.predict(X_test))\n",
    "matriz_de_confusion = confusion_matrix(y_test, xg_reg.predict(X_test))\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " --- Aumento un toke, bien ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visitas a la pagina segun sistema operativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>Android 6</th>\n",
       "      <th>Android 6.0.1</th>\n",
       "      <th>Android 7</th>\n",
       "      <th>Windows 10</th>\n",
       "      <th>Windows 7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008ed71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091926</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000ba417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000c79fe</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000e4d9e</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  Android 6  Android 6.0.1  Android 7  Windows 10   Windows 7 \n",
       "0  0008ed71        0.0            0.0        0.0          2.0         0.0\n",
       "1  00091926        0.0            0.0        0.0          0.0        34.0\n",
       "2  000ba417        0.0            0.0        0.0          6.0         0.0\n",
       "3  000c79fe        0.0            0.0        1.0          0.0         0.0\n",
       "4  000e4d9e        0.0            0.0        0.0         13.0         0.0"
      ]
     },
     "execution_count": 495,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sistema = df.loc[df['event'] == 'visited site']\n",
    "df_sistema = df_sistema[['person','operating_system_version']].dropna()\n",
    "\n",
    "top_5_sistemas = df_sistema['operating_system_version'].value_counts().head(5).index\n",
    "df_sistema = df_sistema.loc[df_sistema['operating_system_version'].isin(top_5_sistemas)]\n",
    "df_sistema = pd.concat([df_sistema['person'],\\\n",
    "        pd.get_dummies(df_sistema['operating_system_version'])],axis = 1).groupby('person').sum().reset_index()\n",
    "\n",
    "df_sistema = pd.merge(df_sistema, todas_las_personas, on=\"person\", how=\"right\").fillna(0)\n",
    "df_sistema.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veo cuantas personas a predecir pierdo\n",
    "df_sistema_predecir = pd.merge(df_sistema, df_persons, on=\"person\", how=\"inner\")\n",
    "df_sistema_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge\n",
    "\n",
    "labels_con_SO = pd.merge(df_sistema, labels_con_resoluciones, on=\"person\", how=\"inner\")\n",
    "labels_con_SO_num = labels_con_SO.drop(columns=\"person\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19414, 77)"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_con_SO.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = labels_con_SO_num.iloc[:,:-1], labels_con_SO_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "#data_dmatrix = xgb.DMatrix(data=X,label=y, weight={1: 1, 0: 0.1})\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18.937098844672658"
      ]
     },
     "execution_count": 500,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBClassifier(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, eval_metric = \"auc\", min_child_weight=9, scale_pos_weight=ratio)\n",
    "ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=9, missing=None,\n",
       "       n_estimators=6, n_jobs=1, nthread=None, objective='binary:hinge',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=18.937098844672658, seed=None, silent=True,\n",
       "       subsample=1)"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8540338677483742\n",
      "Test acuracy:  0.8465104300798352\n",
      "ROC auc score:  0.6321502211917057\n",
      "Confusion matrix: \n",
      "[[3208  474]\n",
      " [ 122   79]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos \n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba duplicando los compradores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = labels_con_SO_num.iloc[:,:-1], labels_con_SO_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "#data_dmatrix = xgb.DMatrix(data=X,label=y, weight={1: 1, 0: 0.1})\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplico los compradores\n",
    "\n",
    "y_train_df = y_train.to_frame()\n",
    "X_train_df = X_train.reset_index()\n",
    "train = pd.merge(X_train, y_train_df, how=\"inner\", left_index=True, right_index=True)\n",
    "train_compradores = train.loc[train[\"label\"] == 1]\n",
    "train_dup = pd.concat([train, train_compradores], ignore_index=True)\n",
    "X_train, y_train = train_dup.drop(columns=\"label\"), train_dup[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.468549422336329"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBClassifier(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, eval_metric = \"auc\", min_child_weight=10)\n",
    "ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=10, missing=None,\n",
       "       n_estimators=6, n_jobs=1, nthread=None, objective='binary:hinge',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 507,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 508,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.703862660944206\n",
      "Test acuracy:  0.69379345866598\n",
      "ROC auc score:  0.6503975235176642\n",
      "Confusion matrix: \n",
      "[[2573 1109]\n",
      " [  80  121]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos \n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visitas a la pagina segun version del navegador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 510,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>Chrome 65.0</th>\n",
       "      <th>Chrome 66.0</th>\n",
       "      <th>Chrome Mobile 64.0</th>\n",
       "      <th>Chrome Mobile 65.0</th>\n",
       "      <th>Chrome Mobile 66.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008ed71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091926</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000ba417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000c79fe</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000e619d</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  Chrome 65.0  Chrome 66.0  Chrome Mobile 64.0  Chrome Mobile 65.0  \\\n",
       "0  0008ed71          0.0          2.0                 0.0                 0.0   \n",
       "1  00091926          0.0         34.0                 0.0                 0.0   \n",
       "2  000ba417          0.0          6.0                 0.0                 0.0   \n",
       "3  000c79fe          0.0          0.0                 0.0                 0.0   \n",
       "4  000e619d          0.0          5.0                 0.0                 0.0   \n",
       "\n",
       "   Chrome Mobile 66.0  \n",
       "0                 0.0  \n",
       "1                 0.0  \n",
       "2                 0.0  \n",
       "3                 1.0  \n",
       "4                 0.0  "
      ]
     },
     "execution_count": 510,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_navegador = df.loc[df['event'] == 'visited site']\n",
    "df_navegador = df_navegador[['person','browser_version']].dropna()\n",
    "\n",
    "top_5_navegadores = df_navegador['browser_version'].value_counts().head(5).index\n",
    "df_navegador = df_navegador.loc[df_navegador['browser_version'].isin(top_5_navegadores)]\n",
    "df_navegador = pd.concat([df_navegador['person'],\\\n",
    "        pd.get_dummies(df_navegador['browser_version'])],axis = 1).groupby('person').sum().reset_index()\n",
    "\n",
    "df_navegador = pd.merge(df_navegador, todas_las_personas, on=\"person\", how=\"right\").fillna(0)\n",
    "\n",
    "df_navegador.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 511,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 511,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veo cuantas personas a predecir pierdo\n",
    "df_navegador_predecir = pd.merge(df_navegador, df_persons, on=\"person\", how=\"inner\")\n",
    "df_navegador_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 512,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge\n",
    "\n",
    "labels_con_navegador = pd.merge(df_navegador, labels_con_SO, on=\"person\", how=\"inner\")\n",
    "labels_con_navegador_num = labels_con_navegador.drop(columns=\"person\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 513,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = labels_con_navegador_num.iloc[:,:-1], labels_con_navegador_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y, weight={1: 1, 0: 0.1})\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, eval_metric = \"auc\", min_child_weight=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 515,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=1000, missing=None,\n",
       "       n_estimators=6, n_jobs=1, nthread=None, objective='binary:hinge',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 515,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.7969222844633314\n",
      "Test acuracy:  0.8029873808910636\n",
      "ROC auc score:  0.6204591087904234\n",
      "Confusion matrix: \n",
      "[[3035  649]\n",
      " [ 116   83]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos \n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visitas a producto por mes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00091926</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>372.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091a7a</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000ba417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000c79fe</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000e4d9e</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>339.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person    1    2    3    4      5\n",
       "0  00091926  0.0  0.0  0.0  0.0  372.0\n",
       "1  00091a7a  0.0  0.0  3.0  0.0    0.0\n",
       "2  000ba417  0.0  0.0  0.0  0.0  153.0\n",
       "3  000c79fe  0.0  0.0  0.0  0.0    3.0\n",
       "4  000e4d9e  0.0  0.0  0.0  0.0  339.0"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_visitas_producto_por_mes = df.loc[df_events['event'] == 'viewed product']\n",
    "df_visitas_producto_por_mes = df_visitas_producto_por_mes[['person','month']]\n",
    "\n",
    "df_visitas_producto_por_mes = pd.concat([pd.get_dummies(df_visitas_producto_por_mes['month'])\\\n",
    "                                         ,df_visitas_producto_por_mes[['person']]],axis = 1).groupby('person')\\\n",
    "                                        .sum().reset_index()\n",
    "\n",
    "df_visitas_producto_por_mes = pd.merge(df_visitas_producto_por_mes, todas_las_personas, on=\"person\", how=\"right\").fillna(0)\n",
    "\n",
    "df_visitas_producto_por_mes.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_columnas = ['mes_'+str(columna) for columna in df_visitas_producto_por_mes.columns]\n",
    "nombres_columnas[0] = 'person'\n",
    "df_visitas_producto_por_mes.columns = nombres_columnas\n",
    "\n",
    "# Merge \n",
    "labels_con_meses = pd.merge(df_visitas_producto_por_mes, labels_con_SO, on=\"person\", how=\"inner\")\n",
    "labels_con_meses_num = labels_con_meses.drop(columns=\"person\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 520,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veo cuantas personas a predecir pierdo\n",
    "df_visitas_producto_por_mes_predecir = pd.merge(df_visitas_producto_por_mes, df_persons, on=\"person\", how=\"inner\")\n",
    "df_visitas_producto_por_mes_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['person', 'mes_1', 'mes_2', 'mes_3', 'mes_4', 'mes_5', 'Android 6',\n",
       "       'Android 6.0.1', 'Android 7', 'Windows 10 ', 'Windows 7 ', '1024x768',\n",
       "       '1360x768', '1366x768', '1440x900', '1600x900', '1920x1080', '320x534',\n",
       "       '320x568', '320x570', '360x640', 'Computer', 'Smartphone', 'Tablet',\n",
       "       'vis_Samsung Galaxy J5', 'vis_Samsung Galaxy S6 Edge',\n",
       "       'vis_Samsung Galaxy S6 Flat', 'vis_Samsung Galaxy S7',\n",
       "       'vis_Samsung Galaxy S7 Edge', 'vis_Samsung Galaxy S8', 'vis_iPhone 5c',\n",
       "       'vis_iPhone 5s', 'vis_iPhone 6', 'vis_iPhone 6 Plus', 'vis_iPhone 6S',\n",
       "       'vis_iPhone 6S Plus', 'vis_iPhone 7', 'vis_iPhone 7 Plus',\n",
       "       'vis_iPhone SE', 'is_new', '128GB', '16GB', '256GB', '32GB', '4GB',\n",
       "       '512MB', '64GB', '8GB', 'Bom', 'Bom - Sem Touch ID', 'Excelente',\n",
       "       'Muito Bom', 'Novo', 'Azul', 'Branco', 'Cinza espacial', 'Dourado',\n",
       "       'Ouro Rosa', 'Prata', 'Prateado', 'Preto', 'Preto Matte', 'Rosa',\n",
       "       'ad campaign hit', 'search engine hit', 'promedio_por_mes',\n",
       "       'promedio_por_dia', 'cant_dias_dist', 'modelos_dist', 'distan_dias',\n",
       "       'cant_city', 'cant_src', 'cant_eng', 'cant_mod', 'cant_ev',\n",
       "       'cant_mes_5_x', 'cant_entradas', 'cant_mes_5_y', 'entradas_30_dias',\n",
       "       'cant_mes', 'cant_dia_freq', 'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 521,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_con_meses.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 522,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = labels_con_meses_num.iloc[:,:-1], labels_con_meses_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y, weight={1: 1, 0: 0.1})\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 523,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, eval_metric = \"auc\", min_child_weight=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=1000, missing=None,\n",
       "       n_estimators=6, n_jobs=1, nthread=None, objective='binary:hinge',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 524,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8036185693129869\n",
      "Test acuracy:  0.8050476435745557\n",
      "ROC auc score:  0.5891212054880405\n",
      "Confusion matrix: \n",
      "[[3056  626]\n",
      " [ 131   70]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos \n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dia de la semana que accede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008ed71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091926</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00091a7a</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000ba417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000c79fe</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person    0    1    2    3    4    5     6\n",
       "0  0008ed71  0.0  0.0  0.0  2.0  0.0  0.0   0.0\n",
       "1  00091926  2.0  4.0  3.0  6.0  3.0  5.0  11.0\n",
       "2  00091a7a  1.0  0.0  0.0  0.0  0.0  0.0   0.0\n",
       "3  000ba417  0.0  0.0  0.0  4.0  0.0  2.0   0.0\n",
       "4  000c79fe  0.0  1.0  0.0  0.0  0.0  0.0   0.0"
      ]
     },
     "execution_count": 527,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['day_of_week'] = df[\"timestamp\"].dt.dayofweek\n",
    "df_dia_visita = df.loc[df['event'] == 'visited site']\n",
    "df_dia_visita = df_dia_visita[['person','day_of_week']]\n",
    "\n",
    "df_dia_visita = pd.concat([df_dia_visita['person'],\\\n",
    "                                 pd.get_dummies(df_dia_visita['day_of_week'])],axis = 1)\\\n",
    "                                .groupby('person').sum().reset_index()\n",
    "\n",
    "df_dia_visita = pd.merge(df_dia_visita, todas_las_personas, on=\"person\", how=\"right\").fillna(0)\n",
    "\n",
    "\n",
    "df_dia_visita.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 528,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 528,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veo cuantas personas a predecir pierdo\n",
    "df_dia_visita_predecir = pd.merge(df_dia_visita, df_persons, on=\"person\", how=\"inner\")\n",
    "df_dia_visita_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2341681 entries, 0 to 2341680\n",
      "Data columns (total 26 columns):\n",
      "timestamp                   datetime64[ns]\n",
      "event                       object\n",
      "person                      object\n",
      "url                         object\n",
      "sku                         float64\n",
      "model                       object\n",
      "condition                   object\n",
      "storage                     object\n",
      "color                       object\n",
      "skus                        object\n",
      "search_term                 object\n",
      "staticpage                  object\n",
      "campaign_source             object\n",
      "search_engine               object\n",
      "channel                     object\n",
      "new_vs_returning            object\n",
      "city                        object\n",
      "region                      object\n",
      "country                     object\n",
      "device_type                 object\n",
      "screen_resolution           object\n",
      "operating_system_version    object\n",
      "browser_version             object\n",
      "month                       int64\n",
      "day                         int64\n",
      "day_of_week                 int64\n",
      "dtypes: datetime64[ns](1), float64(1), int64(3), object(21)\n",
      "memory usage: 464.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge\n",
    "\n",
    "labels_con_dia_semana = pd.merge(df_dia_visita, labels_con_navegador, on=\"person\", how=\"inner\")\n",
    "labels_con_dia_semana_num = labels_con_dia_semana.drop(columns=\"person\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = labels_con_dia_semana_num.iloc[:,:-1], labels_con_dia_semana_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y, weight={1: 1, 0: 0.1})\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, eval_metric = \"auc\", min_child_weight=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=1000, missing=None,\n",
       "       n_estimators=6, n_jobs=1, nthread=None, objective='binary:hinge',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 533,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.798467580967098\n",
      "Test acuracy:  0.787792943600309\n",
      "ROC auc score:  0.5870534405662237\n",
      "Confusion matrix: \n",
      "[[2985  694]\n",
      " [ 130   74]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos \n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.798467580967098\n",
      "Test acuracy:  0.787792943600309\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.81      0.88      3679\n",
      "           1       0.10      0.36      0.15       204\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      3883\n",
      "   macro avg       0.53      0.59      0.52      3883\n",
      "weighted avg       0.91      0.79      0.84      3883\n",
      "\n",
      "\n",
      "Precision Score:  0.09635416666666667\n",
      "Recall Score:  0.3627450980392157\n",
      "F1 Score:  0.1522633744855967\n",
      "Cohen Kappa Score:  0.07551145182858243\n",
      "ROC auc score:  0.5870534405662237\n",
      "Confusion matrix: \n",
      "[[2985  694]\n",
      " [ 130   74]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\\\n",
    "                            f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "# Pruebo todas las metricas.\n",
    "# accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\n",
    "# f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "\n",
    "trainAccuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "testAccuracy = accuracy_score(y_test, preds)\n",
    "\n",
    "meanSquaredError = mean_squared_error(y_test, preds)\n",
    "classificationReport = classification_report(y_test, preds)\n",
    "precisionScore = precision_score(y_test, preds)\n",
    "recallScore = recall_score(y_test, preds)\n",
    "f1Score = f1_score(y_test, preds)\n",
    "cohenKappaScore = cohen_kappa_score(y_test, preds)\n",
    "areaDebajoDeCurva = roc_auc_score(y_test, preds)\n",
    "matrizDeConfusion = confusion_matrix(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", trainAccuracy)\n",
    "print(\"Test acuracy: \", testAccuracy)\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(classificationReport)\n",
    "print()\n",
    "print(\"Precision Score: \",precisionScore)\n",
    "print(\"Recall Score: \",recallScore)\n",
    "print(\"F1 Score: \",f1Score)\n",
    "print(\"Cohen Kappa Score: \",cohenKappaScore)\n",
    "print(\"ROC auc score: \", areaDebajoDeCurva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matrizDeConfusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba duplicando los compradores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = labels_con_dia_semana_num.iloc[:,:-1], labels_con_dia_semana_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y, weight={1: 1, 0: 0.1})\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplico los compradores\n",
    "y_train_df = pd.DataFrame(y_train)\n",
    "train = pd.merge(X_train, y_train_df, how=\"inner\", left_index=True, right_index=True)\n",
    "train_compradores = train.loc[train[\"label\"] == 1]\n",
    "train_dup = pd.concat([train, train_compradores], ignore_index=True)\n",
    "X_train, y_train = train_dup.drop(columns=\"label\"), train_dup[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, eval_metric = \"auc\", min_child_weight=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=1, missing=None,\n",
       "       n_estimators=6, n_jobs=1, nthread=None, objective='binary:hinge',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.6874961672901208\n",
      "Test acuracy:  0.6901879989698687\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.69      0.81      3679\n",
      "           1       0.10      0.62      0.17       204\n",
      "\n",
      "   micro avg       0.69      0.69      0.69      3883\n",
      "   macro avg       0.54      0.66      0.49      3883\n",
      "weighted avg       0.93      0.69      0.78      3883\n",
      "\n",
      "\n",
      "Precision Score:  0.10135674381484437\n",
      "Recall Score:  0.6225490196078431\n",
      "F1 Score:  0.17433081674673986\n",
      "Cohen Kappa Score:  0.09231046651511454\n",
      "ROC auc score:  0.6582437949357509\n",
      "Confusion matrix: \n",
      "[[2553 1126]\n",
      " [  77  127]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\\\n",
    "                            f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "# Pruebo todas las metricas.\n",
    "# accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\n",
    "# f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "\n",
    "trainAccuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "testAccuracy = accuracy_score(y_test, preds)\n",
    "\n",
    "meanSquaredError = mean_squared_error(y_test, preds)\n",
    "classificationReport = classification_report(y_test, preds)\n",
    "precisionScore = precision_score(y_test, preds)\n",
    "recallScore = recall_score(y_test, preds)\n",
    "f1Score = f1_score(y_test, preds)\n",
    "cohenKappaScore = cohen_kappa_score(y_test, preds)\n",
    "areaDebajoDeCurva = roc_auc_score(y_test, preds)\n",
    "matrizDeConfusion = confusion_matrix(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", trainAccuracy)\n",
    "print(\"Test acuracy: \", testAccuracy)\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(classificationReport)\n",
    "print()\n",
    "print(\"Precision Score: \",precisionScore)\n",
    "print(\"Recall Score: \",recallScore)\n",
    "print(\"F1 Score: \",f1Score)\n",
    "print(\"Cohen Kappa Score: \",cohenKappaScore)\n",
    "print(\"ROC auc score: \", areaDebajoDeCurva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matrizDeConfusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICCIÓN..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs=0\n",
    "df_final=0\n",
    "dfs =[mes_dia_mas_entradas, entradas_30_dias_df, entradas_tot,\\\n",
    "      cant_checkouts_tot, mayor_ciudad, mayor_camp, mayor_engine, mayor_modelo, mayor_evento\\\n",
    "     , distancia_dias, cant_modelos, cant_dias_dist, entradas_tot_y_dias, entradas_tot_y_meses,\\\n",
    "      df_events_visitas_prod_color_storage_condition, df_mew_5, df_device, df_resolucion,\\\n",
    "      df_sistema, df_navegador, df_visitas_producto_por_mes, df_dia_visita]\n",
    "\n",
    "df_final = reduce(lambda left,right: pd.merge(left,right,on='person', how='inner'), dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_prueba =pd.merge(df_final, labels, on=\"person\", how=\"inner\").drop(columns=\"person\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = df_final_prueba.iloc[:,:-1], df_final_prueba.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y, weight={1: 1, 0: 0.1})\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 546,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplico los compradores\n",
    "y_train_df = pd.DataFrame(y_train)\n",
    "train = pd.merge(X_train, y_train_df, how=\"inner\", left_index=True, right_index=True)\n",
    "train_compradores = train.loc[train[\"label\"] == 1]\n",
    "train_dup = pd.concat([train, train_compradores], ignore_index=True)\n",
    "X_train, y_train = train_dup.drop(columns=\"label\"), train_dup[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 547,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, eval_metric = \"auc\", min_child_weight=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=1, missing=None,\n",
       "       n_estimators=6, n_jobs=1, nthread=None, objective='binary:hinge',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 548,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., ..., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 549,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.6257055214723927\n",
      "Test acuracy:  0.6229719289209374\n",
      "ROC auc score:  0.7023794773306901\n",
      "Confusion matrix: \n",
      "[[2252 1420]\n",
      " [  44  167]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos \n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = df_final_prueba.iloc[:,:-1], df_final_prueba.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y, weight={1: 1, 0: 0.1})\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18434, 980)"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cant_ceros = np.sum(y == 0)\n",
    "cant_unos = np.sum(y == 1)\n",
    "cant_ceros, cant_unos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 554,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(random_state=2, sampling_strategy = {0: 18434, 1: 1399})\n",
    "X_train_res, y_train_res = ros.fit_sample(X, y)\n",
    "X_train_res_df = pd.DataFrame(X_train_res)\n",
    "X_train_res_df.columns = X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 555,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, eval_metric = \"auc\", min_child_weight=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 556,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=1, missing=None,\n",
       "       n_estimators=6, n_jobs=1, nthread=None, objective='binary:hinge',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 556,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train_res_df,y_train_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 557,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 557,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 558,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.7901477335753542\n",
      "Test acuracy:  0.7978367241823332\n",
      "ROC auc score:  0.7032622949126991\n",
      "Confusion matrix: \n",
      "[[2972  700]\n",
      " [  85  126]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos \n",
    "train_accuracy = accuracy_score(y_train_res, xg_reg.predict(X_train_res_df))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 559,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fijandose lo de RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 560,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = df_final_prueba.iloc[:,:-1], df_final_prueba.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y, weight={1: 1, 0: 0.1})\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18434, 980)"
      ]
     },
     "execution_count": 561,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cant_ceros = np.sum(y == 0)\n",
    "cant_unos = np.sum(y == 1)\n",
    "cant_ceros, cant_unos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(random_state=2, sampling_strategy = {0: 18434, 1: 1399})\n",
    "X_train_res, y_train_res = ros.fit_sample(X, y)\n",
    "X_train_res_df = pd.DataFrame(X_train_res)\n",
    "X_train_res_df.columns = X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, eval_metric = \"auc\", min_child_weight=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False  True  True  True  True False False False  True  True  True  True\n",
      " False  True False False False False False False False False  True False\n",
      " False False False False False False False False False False False False\n",
      " False False False  True  True False False False False False False False\n",
      " False False False  True  True False False False False False False False\n",
      " False False False  True False False False False False False False False\n",
      " False False]\n",
      "[50  1  1  1  1 16  8  7  1  1  1  1  3  1 18 34 49 59 43 37 31 39  1 21\n",
      " 20 14  6 38 45  4  2 40 46 15 53 55 33 29 56  1  1 44 30 58 42 19  9 25\n",
      " 27 52 17  1  1 35 28 12 32 48 13 23 22 41 36  1 47  5 10 24 11 26 51 54\n",
      " 57 60]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = df_final_prueba.iloc[:,:-1], df_final_prueba.iloc[:,-1]\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "ros = RandomOverSampler(random_state=2, sampling_strategy = {0: 18434, 1: 1399})\n",
    "X_train_res, y_train_res = ros.fit_sample(X, y)\n",
    "X_train_res_df = pd.DataFrame(X_train_res)\n",
    "X_train_res_df.columns = X_test.columns\n",
    "\n",
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, eval_metric = \"auc\", min_child_weight=1)\n",
    "\n",
    "rfe = RFE(xg_reg, 15)\n",
    "rfe = rfe.fit(X_train_res_df,y_train_res)\n",
    "# summarize the selection of the attributes\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 565,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = rfe.predict(X_test)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.7551555488327535\n",
      "Test acuracy:  0.7563739376770539\n",
      "ROC auc score:  0.6880401449679397\n",
      "Confusion matrix: \n",
      "[[2808  864]\n",
      " [  82  129]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos \n",
    "train_accuracy = accuracy_score(y_train_res, rfe.predict(X_train_res_df))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = labels_con_promedios_num.iloc[:,:-1],labels_con_promedios_num.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, y_train)\n",
    "dtest = xgb.DMatrix(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, scale_pos_weight = 6, min_child_weight=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=6,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=6, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.36512432, 0.54599017, 0.28901175, ..., 0.42871228, 0.34284964,\n",
       "       0.34284964], dtype=float32)"
      ]
     },
     "execution_count": 572,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict_proba(X_test)[:, 1]\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.9318781791256198\n",
      "Test acuracy:  0.9296935359258306\n",
      "ROC auc score:  0.7383659589433501\n",
      "Confusion matrix: \n",
      "[[3576  116]\n",
      " [ 157   34]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos que onda\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, xg_reg.predict(X_test))\n",
    "matriz_de_confusion = confusion_matrix(y_test, xg_reg.predict(X_test))\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8779859635567574\n",
      "Test acuracy:  0.8720061807880505\n",
      "ROC auc score:  0.6218688370556227\n",
      "Confusion matrix: \n",
      "[[3314  358]\n",
      " [ 139   72]]\n"
     ]
    }
   ],
   "source": [
    "# sin duplicar\n",
    "\n",
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = df_final_prueba.iloc[:,:-1], df_final_prueba.iloc[:,-1]\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, eval_metric = \"auc\", min_child_weight=1)\n",
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)\n",
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)\n",
    "\n",
    "# Vemos \n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4886f805</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0297fc1e</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2d681dd8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cccea85e</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4c8a8b93</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  label\n",
       "0  4886f805      0\n",
       "1  0297fc1e      0\n",
       "2  2d681dd8      0\n",
       "3  cccea85e      0\n",
       "4  4c8a8b93      0"
      ]
     },
     "execution_count": 575,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ejemplo = pd.read_csv(\"trocafone_kaggle_submit_sample_all_0.csv\")\n",
    "df_ejemplo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4886f805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0297fc1e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2d681dd8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cccea85e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4c8a8b93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person\n",
       "0  4886f805\n",
       "1  0297fc1e\n",
       "2  2d681dd8\n",
       "3  cccea85e\n",
       "4  4c8a8b93"
      ]
     },
     "execution_count": 576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_persons.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_predecir = pd.merge(df_final, df_persons, on=\"person\", how=\"inner\")\n",
    "a_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_predecir_num = a_predecir.drop(columns=\"person\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19415, 2)"
      ]
     },
     "execution_count": 579,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predecimos\n",
    "\n",
    "labels_predicciones = xg_reg.predict(a_predecir_num)\n",
    "\n",
    "personas_a_predecir = df_persons[[\"person\"]]\n",
    "personas_a_predecir[\"label\"] = pd.Series(labels_predicciones, dtype=int)\n",
    "personas_a_predecir.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [],
   "source": [
    "personas_a_predecir.to_csv(\"predicciones.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False False  True False  True False  True False  True False  True False\n",
      " False False False False False False False False False False  True False\n",
      " False False False  True False  True False False False  True False False\n",
      " False False False  True  True False False False False False False False\n",
      " False False False False False  True False False False False False False\n",
      " False False False False False  True False False False False  True False\n",
      " False False]\n",
      "[ 2  3  1 15  1 14  1 16  1  4  1  6  9  8 32 61  7 37 24 20 18 48  1 49\n",
      " 56 44 25  1 12  1 46 22 26  1 54 57 59 60 58  1  1 39 43 41 21 36 17 29\n",
      " 19 52  5 11 35  1 30 42 38 23 50 47 45 51 27 31 13  1 10 33 28 34  1 40\n",
      " 53 55]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = df_final_prueba.iloc[:,:-1], df_final_prueba.iloc[:,-1]\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, eval_metric = \"auc\", min_child_weight=1)\n",
    "\n",
    "rfe = RFE(xg_reg, 14)\n",
    "rfe = rfe.fit(X_train,y_train)\n",
    "# summarize the selection of the attributes\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8710321292898074\n",
      "Test acuracy:  0.8622199330414628\n",
      "ROC auc score:  0.6300955611312455\n",
      "Confusion matrix: \n",
      "[[3270  402]\n",
      " [ 133   78]]\n"
     ]
    }
   ],
   "source": [
    "preds = rfe.predict(X_test)\n",
    "\n",
    "# Vemos \n",
    "train_accuracy = accuracy_score(y_train, rfe.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = df_final_prueba.iloc[:,:-1],df_final_prueba.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, y_train)\n",
    "dtest = xgb.DMatrix(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, scale_pos_weight = 6, min_child_weight=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=6,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=6, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.36007977, 0.313215  , 0.38032264, ..., 0.31013724, 0.32352626,\n",
       "       0.32553867], dtype=float32)"
      ]
     },
     "execution_count": 594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = rfe.predict_proba(X_test)[:, 1]\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 598,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True False  True  True  True  True  True  True\n",
      " False False  True  True  True False False False False False  True False\n",
      " False  True False False False  True False  True False  True False  True\n",
      " False False False  True  True False False False False False False False\n",
      " False False  True False False False False False False False False False\n",
      " False False False False False False  True False  True False False False\n",
      " False False]\n",
      "[ 1  1  1  1  1 11  1  1  1  1  1  1 22  2  1  1  1 30  8 12 43 36  1 13\n",
      " 25  1 32 26 33  1  5  1 40  1 46  1 50 49 35  1  1 44 28 38 23 42 27  4\n",
      " 37 39  1 17 31 34  3 20 19 14  7 15  9 10 18 29 21  6  1 24  1 41 16 45\n",
      " 47 48]\n"
     ]
    }
   ],
   "source": [
    "rfe = RFE(xg_reg, 25)\n",
    "rfe = rfe.fit(X_train,y_train)\n",
    "# summarize the selection of the attributes\n",
    "print(rfe.support_)\n",
    "print(rfe.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.9330371515034447\n",
      "Test acuracy:  0.9242853463816637\n",
      "ROC auc score:  0.7678602773389502\n",
      "Confusion matrix: \n",
      "[[3553  119]\n",
      " [ 175   36]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos que onda\n",
    "preds = rfe.predict_proba(X_test)[:, 1]\n",
    "preds\n",
    "train_accuracy = accuracy_score(y_train, rfe.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, rfe.predict(X_test))\n",
    "matriz_de_confusion = confusion_matrix(y_test, rfe.predict(X_test))\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time features de Santi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cantidad de eventos por hora. (Todas las horas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"day\"] = df[\"timestamp\"].dt.day\n",
    "df[\"day_of_week\"] = df['timestamp'].dt.weekday_name\n",
    "df['day_of_year'] = df['timestamp'].dt.dayofyear\n",
    "df['hour'] = df['timestamp'].dt.hour\n",
    "df['minute'] = df['timestamp'].dt.minute\n",
    "#df_events['second'] = df_events['timestamp'].dt.second\n",
    "df['week_of_year'] = df['timestamp'].dt.weekofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hour = df[['person','hour']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008ed71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091926</td>\n",
       "      <td>117.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00091a7a</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000ba417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000c79fe</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     person      0      1     2     3     4    5    6    7    8  ...     14  \\\n",
       "0  0008ed71    0.0    0.0   0.0   0.0   0.0  0.0  0.0  0.0  0.0  ...    0.0   \n",
       "1  00091926  117.0  122.0  33.0  15.0  26.0  0.0  0.0  0.0  0.0  ...    0.0   \n",
       "2  00091a7a    0.0    0.0   0.0   0.0   0.0  0.0  0.0  0.0  0.0  ...   10.0   \n",
       "3  000ba417    0.0    0.0   0.0   0.0   0.0  0.0  0.0  0.0  0.0  ...    0.0   \n",
       "4  000c79fe   17.0    0.0   0.0   0.0   0.0  0.0  0.0  0.0  0.0  ...    0.0   \n",
       "\n",
       "    15    16    17    18    19   20   21   22    23  \n",
       "0  0.0   3.0   0.0   0.0   0.0  0.0  0.0  0.0   0.0  \n",
       "1  0.0   0.0   0.0  50.0  10.0  0.0  3.0  7.0  65.0  \n",
       "2  0.0   0.0   0.0   0.0   0.0  0.0  0.0  0.0   0.0  \n",
       "3  0.0  59.0  22.0   0.0   0.0  0.0  0.0  0.0   0.0  \n",
       "4  0.0   0.0   0.0   0.0   0.0  0.0  0.0  0.0   0.0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hour1 = pd.concat([df_hour['person'],pd.get_dummies(df_hour['hour'])],axis = 1).groupby('person').sum()\\\n",
    "            .reset_index()\n",
    "df_hour1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge\n",
    "\n",
    "labels_con_horas = pd.merge(df_hour1, labels_con_dia_semana, on=\"person\", how=\"inner\")\n",
    "labels_con_horas_num = labels_con_horas.drop(columns=\"person\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = labels_con_horas_num.iloc[:,:-1], labels_con_horas_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y, weight={1: 1, 0: 0.1})\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, eval_metric = \"auc\", min_child_weight=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=1, missing=None,\n",
       "       n_estimators=6, n_jobs=1, nthread=None, objective='binary:hinge',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 349,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.888640546936629\n",
      "Test acuracy:  0.8779910596897187\n",
      "ROC auc score:  0.6152107564848149\n",
      "Confusion matrix: \n",
      "[[3277  334]\n",
      " [ 130   62]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos \n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.888640546936629\n",
      "Test acuracy:  0.8779910596897187\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.91      0.93      3611\n",
      "           1       0.16      0.32      0.21       192\n",
      "\n",
      "   micro avg       0.88      0.88      0.88      3803\n",
      "   macro avg       0.56      0.62      0.57      3803\n",
      "weighted avg       0.92      0.88      0.90      3803\n",
      "\n",
      "\n",
      "Precision Score:  0.15656565656565657\n",
      "Recall Score:  0.3229166666666667\n",
      "F1 Score:  0.2108843537414966\n",
      "Cohen Kappa Score:  0.1533074228683845\n",
      "ROC auc score:  0.6152107564848149\n",
      "Confusion matrix: \n",
      "[[3277  334]\n",
      " [ 130   62]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\\\n",
    "                            f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "# Pruebo todas las metricas.\n",
    "# accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\n",
    "# f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "\n",
    "trainAccuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "testAccuracy = accuracy_score(y_test, preds)\n",
    "\n",
    "meanSquaredError = mean_squared_error(y_test, preds)\n",
    "classificationReport = classification_report(y_test, preds)\n",
    "precisionScore = precision_score(y_test, preds)\n",
    "recallScore = recall_score(y_test, preds)\n",
    "f1Score = f1_score(y_test, preds)\n",
    "cohenKappaScore = cohen_kappa_score(y_test, preds)\n",
    "areaDebajoDeCurva = roc_auc_score(y_test, preds)\n",
    "matrizDeConfusion = confusion_matrix(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", trainAccuracy)\n",
    "print(\"Test acuracy: \", testAccuracy)\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(classificationReport)\n",
    "print()\n",
    "print(\"Precision Score: \",precisionScore)\n",
    "print(\"Recall Score: \",recallScore)\n",
    "print(\"F1 Score: \",f1Score)\n",
    "print(\"Cohen Kappa Score: \",cohenKappaScore)\n",
    "print(\"ROC auc score: \", areaDebajoDeCurva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matrizDeConfusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba duplicando los compradores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = labels_con_horas_num.iloc[:,:-1], labels_con_horas_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y, weight={1: 1, 0: 0.1})\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplico los compradores\n",
    "y_train_df = pd.DataFrame(y_train)\n",
    "y_train_df.columns = [\"label\"]\n",
    "train = pd.merge(X_train, y_train_df, how=\"inner\", left_index=True, right_index=True)\n",
    "train_compradores = train.loc[train[\"label\"] == 1]\n",
    "train_dup = pd.concat([train, train_compradores], ignore_index=True)\n",
    "X_train, y_train = train_dup.drop(columns=\"label\"), train_dup[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, eval_metric = \"auc\", min_child_weight=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=1, missing=None,\n",
       "       n_estimators=6, n_jobs=1, nthread=None, objective='binary:hinge',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.7140353073744835\n",
      "Test acuracy:  0.7125953194846174\n",
      "ROC auc score:  0.6735921201421582\n",
      "Confusion matrix: \n",
      "[[2589 1022]\n",
      " [  71  121]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos \n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.6731563791160636\n",
      "Test acuracy:  0.6655272153562977\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.67      0.79      3611\n",
      "           1       0.09      0.66      0.17       192\n",
      "\n",
      "   micro avg       0.67      0.67      0.67      3803\n",
      "   macro avg       0.53      0.66      0.48      3803\n",
      "weighted avg       0.93      0.67      0.76      3803\n",
      "\n",
      "\n",
      "Precision Score:  0.0945945945945946\n",
      "Recall Score:  0.65625\n",
      "F1 Score:  0.16535433070866143\n",
      "Cohen Kappa Score:  0.08456547755571042\n",
      "ROC auc score:  0.6611352464691221\n",
      "Confusion matrix: \n",
      "[[2405 1206]\n",
      " [  66  126]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\\\n",
    "                            f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "# Pruebo todas las metricas.\n",
    "# accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\n",
    "# f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "\n",
    "trainAccuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "testAccuracy = accuracy_score(y_test, preds)\n",
    "\n",
    "meanSquaredError = mean_squared_error(y_test, preds)\n",
    "classificationReport = classification_report(y_test, preds)\n",
    "precisionScore = precision_score(y_test, preds)\n",
    "recallScore = recall_score(y_test, preds)\n",
    "f1Score = f1_score(y_test, preds)\n",
    "cohenKappaScore = cohen_kappa_score(y_test, preds)\n",
    "areaDebajoDeCurva = roc_auc_score(y_test, preds)\n",
    "matrizDeConfusion = confusion_matrix(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", trainAccuracy)\n",
    "print(\"Test acuracy: \", testAccuracy)\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(classificationReport)\n",
    "print()\n",
    "print(\"Precision Score: \",precisionScore)\n",
    "print(\"Recall Score: \",recallScore)\n",
    "print(\"F1 Score: \",f1Score)\n",
    "print(\"Cohen Kappa Score: \",cohenKappaScore)\n",
    "print(\"ROC auc score: \", areaDebajoDeCurva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matrizDeConfusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREDICCIÓN..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4886f805</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0297fc1e</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2d681dd8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cccea85e</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4c8a8b93</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  label\n",
       "0  4886f805      0\n",
       "1  0297fc1e      0\n",
       "2  2d681dd8      0\n",
       "3  cccea85e      0\n",
       "4  4c8a8b93      0"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ejemplo = pd.read_csv(\"trocafone_kaggle_submit_sample_all_0.csv\")\n",
    "df_ejemplo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4886f805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0297fc1e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2d681dd8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cccea85e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4c8a8b93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person\n",
       "0  4886f805\n",
       "1  0297fc1e\n",
       "2  2d681dd8\n",
       "3  cccea85e\n",
       "4  4c8a8b93"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_persons.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0_x</th>\n",
       "      <th>1_x</th>\n",
       "      <th>2_x</th>\n",
       "      <th>3_x</th>\n",
       "      <th>4_x</th>\n",
       "      <th>5_x</th>\n",
       "      <th>6_x</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>cant_mod</th>\n",
       "      <th>cant_ev</th>\n",
       "      <th>cant_mes_5_x</th>\n",
       "      <th>cant_entradas</th>\n",
       "      <th>cant_mes_5_y</th>\n",
       "      <th>entradas_30_dias</th>\n",
       "      <th>cant_mes</th>\n",
       "      <th>cant_dia_freq</th>\n",
       "      <th>label</th>\n",
       "      <th>person</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 113 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [0_x, 1_x, 2_x, 3_x, 4_x, 5_x, 6_x, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 0_y, 1_y, 2_y, 3_y, 4_y, 5_y, 6_y, Chrome 65.0, Chrome 66.0, Chrome Mobile 64.0, Chrome Mobile 65.0, Chrome Mobile 66.0, Android 6, Android 6.0.1, Android 7, Windows 10 , Windows 7 , 1024x768, 1360x768, 1366x768, 1440x900, 1600x900, 1920x1080, 320x534, 320x568, 320x570, 360x640, Computer, Smartphone, Tablet, vis_Samsung Galaxy J5, vis_Samsung Galaxy S6 Edge, vis_Samsung Galaxy S6 Flat, vis_Samsung Galaxy S7, vis_Samsung Galaxy S7 Edge, vis_Samsung Galaxy S8, vis_iPhone 5c, vis_iPhone 5s, vis_iPhone 6, vis_iPhone 6 Plus, vis_iPhone 6S, vis_iPhone 6S Plus, vis_iPhone 7, vis_iPhone 7 Plus, vis_iPhone SE, is_new, 128GB, 16GB, 256GB, 32GB, 4GB, 512MB, 64GB, 8GB, Bom, Bom - Sem Touch ID, Excelente, Muito Bom, Novo, Azul, Branco, Cinza espacial, Dourado, Ouro Rosa, Prata, Prateado, Preto, Preto Matte, Rosa, ad campaign hit, search engine hit, promedio_por_mes, promedio_por_dia, cant_dias_dist, modelos_dist, distan_dias, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 113 columns]"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_con_horas = pd.merge(labels_con_horas, df_persons, on=\"person\", how=\"inner\")\n",
    "labels_con_horas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "Predicciones = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cantidad de eventos en fin de semana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_day_of_week3 = df[['person','day_of_week']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seba\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_day_of_week3['fin_de_semana'] = df_day_of_week3['day_of_week'].isin(['Saturday','Sunday'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_day_of_week3 = df_day_of_week3.groupby('person').sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge\n",
    "\n",
    "labels_con_findes = pd.merge(df_day_of_week3, labels_con_horas, on=\"person\", how=\"inner\")\n",
    "labels_con_findes_num = labels_con_findes.drop(columns=\"person\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = labels_con_findes_num.iloc[:,:-1], labels_con_findes_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y, weight={1: 1, 0: 0.1})\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, eval_metric = \"auc\", min_child_weight=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=1000, missing=None,\n",
       "       n_estimators=6, n_jobs=1, nthread=None, objective='binary:hinge',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8519589797528268\n",
      "Test acuracy:  0.8543255324743624\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.88      0.92      3611\n",
      "           1       0.13      0.34      0.19       192\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      3803\n",
      "   macro avg       0.55      0.61      0.56      3803\n",
      "weighted avg       0.92      0.85      0.88      3803\n",
      "\n",
      "\n",
      "Precision Score:  0.13360323886639677\n",
      "Recall Score:  0.34375\n",
      "F1 Score:  0.1924198250728863\n",
      "Cohen Kappa Score:  0.12909428967551584\n",
      "ROC auc score:  0.6126116380504015\n",
      "Confusion matrix: \n",
      "[[3183  428]\n",
      " [ 126   66]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\\\n",
    "                            f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "# Pruebo todas las metricas.\n",
    "# accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\n",
    "# f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "\n",
    "trainAccuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "testAccuracy = accuracy_score(y_test, preds)\n",
    "\n",
    "meanSquaredError = mean_squared_error(y_test, preds)\n",
    "classificationReport = classification_report(y_test, preds)\n",
    "precisionScore = precision_score(y_test, preds)\n",
    "recallScore = recall_score(y_test, preds)\n",
    "f1Score = f1_score(y_test, preds)\n",
    "cohenKappaScore = cohen_kappa_score(y_test, preds)\n",
    "areaDebajoDeCurva = roc_auc_score(y_test, preds)\n",
    "matrizDeConfusion = confusion_matrix(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", trainAccuracy)\n",
    "print(\"Test acuracy: \", testAccuracy)\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(classificationReport)\n",
    "print()\n",
    "print(\"Precision Score: \",precisionScore)\n",
    "print(\"Recall Score: \",recallScore)\n",
    "print(\"F1 Score: \",f1Score)\n",
    "print(\"Cohen Kappa Score: \",cohenKappaScore)\n",
    "print(\"ROC auc score: \", areaDebajoDeCurva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matrizDeConfusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba duplicando los compradores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = labels_con_findes_num.iloc[:,:-1], labels_con_findes_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y, weight={1: 1, 0: 0.1})\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplico los compradores\n",
    "y_train_df = pd.DataFrame(y_train)\n",
    "y_train_df.columns = [\"label\"]\n",
    "train = pd.merge(X_train, y_train_df, how=\"inner\", left_index=True, right_index=True)\n",
    "train_compradores = train.loc[train[\"label\"] == 1]\n",
    "train_dup = pd.concat([train, train_compradores], ignore_index=True)\n",
    "X_train, y_train = train_dup.drop(columns=\"label\"), train_dup[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, eval_metric = \"auc\", min_child_weight=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=1, missing=None,\n",
       "       n_estimators=6, n_jobs=1, nthread=None, objective='binary:hinge',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.6854263177663703\n",
      "Test acuracy:  0.6831448856166185\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.68      0.80      3611\n",
      "           1       0.10      0.65      0.17       192\n",
      "\n",
      "   micro avg       0.68      0.68      0.68      3803\n",
      "   macro avg       0.54      0.67      0.49      3803\n",
      "weighted avg       0.93      0.68      0.77      3803\n",
      "\n",
      "\n",
      "Precision Score:  0.09897070467141726\n",
      "Recall Score:  0.6510416666666666\n",
      "F1 Score:  0.17182130584192443\n",
      "Cohen Kappa Score:  0.09225903078080788\n",
      "ROC auc score:  0.6679467541308963\n",
      "Confusion matrix: \n",
      "[[2473 1138]\n",
      " [  67  125]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\\\n",
    "                            f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "# Pruebo todas las metricas.\n",
    "# accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\n",
    "# f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "\n",
    "trainAccuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "testAccuracy = accuracy_score(y_test, preds)\n",
    "\n",
    "meanSquaredError = mean_squared_error(y_test, preds)\n",
    "classificationReport = classification_report(y_test, preds)\n",
    "precisionScore = precision_score(y_test, preds)\n",
    "recallScore = recall_score(y_test, preds)\n",
    "f1Score = f1_score(y_test, preds)\n",
    "cohenKappaScore = cohen_kappa_score(y_test, preds)\n",
    "areaDebajoDeCurva = roc_auc_score(y_test, preds)\n",
    "matrizDeConfusion = confusion_matrix(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", trainAccuracy)\n",
    "print(\"Test acuracy: \", testAccuracy)\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(classificationReport)\n",
    "print()\n",
    "print(\"Precision Score: \",precisionScore)\n",
    "print(\"Recall Score: \",recallScore)\n",
    "print(\"F1 Score: \",f1Score)\n",
    "print(\"Cohen Kappa Score: \",cohenKappaScore)\n",
    "print(\"ROC auc score: \", areaDebajoDeCurva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matrizDeConfusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_con_findes_predecir[\"person\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-19415"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_con_findes_predecir = pd.merge(labels_con_findes, df_persons, on=\"person\", how=\"inner\")\n",
    "labels_con_findes_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cantidad de eventos en rango de horas (Morning , Afternoon, Evening y Night) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Morning     5 a 12  \n",
    "\n",
    "Afternoon     12 a 17\n",
    "\n",
    "Evening     17 a 21\n",
    "\n",
    "Night         21 a 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hour_rango2 = df_hour.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hour_rango2['Morning'] = (df_hour_rango2['hour'].isin(list(range(5,13)))).astype(int)\n",
    "df_hour_rango2['Afternoon'] = (df_hour_rango2['hour'].isin(list(range(13,18)))).astype(int)\n",
    "df_hour_rango2['Evening'] = (df_hour_rango2['hour'].isin(list(range(18,21)))).astype(int)\n",
    "df_hour_rango2['Night'] = (df_hour_rango2['hour'].isin([22,23,0,1,2,3,4])).astype(int)\n",
    "df_hour_rango2.drop(columns = ['hour'],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hour_rango2a = df_hour_rango2.groupby('person').sum().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visita la pagina en rango de horas (Morning , Afternoon, Evening y Night) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hour_rango2b = df_hour_rango2.drop_duplicates().groupby('person').sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge\n",
    "\n",
    "labels_con_rango_horario = pd.merge(df_hour_rango2b, labels_con_findes, on=\"person\", how=\"inner\")\n",
    "labels_con_rango_horario_num = labels_con_rango_horario.drop(columns=\"person\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = labels_con_rango_horario_num.iloc[:,:-1], labels_con_rango_horario_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y, weight={1: 1, 0: 0.1})\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, eval_metric = \"auc\", min_child_weight=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=1000, missing=None,\n",
       "       n_estimators=6, n_jobs=1, nthread=None, objective='binary:hinge',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.850512753089666\n",
      "Test acuracy:  0.8535366815671838\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.88      0.92      3611\n",
      "           1       0.13      0.34      0.19       192\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      3803\n",
      "   macro avg       0.55      0.61      0.56      3803\n",
      "weighted avg       0.92      0.85      0.88      3803\n",
      "\n",
      "\n",
      "Precision Score:  0.13279678068410464\n",
      "Recall Score:  0.34375\n",
      "F1 Score:  0.19158200290275762\n",
      "Cohen Kappa Score:  0.1280750665076711\n",
      "ROC auc score:  0.6121962406535586\n",
      "Confusion matrix: \n",
      "[[3180  431]\n",
      " [ 126   66]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\\\n",
    "                            f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "# Pruebo todas las metricas.\n",
    "# accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\n",
    "# f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "\n",
    "trainAccuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "testAccuracy = accuracy_score(y_test, preds)\n",
    "\n",
    "meanSquaredError = mean_squared_error(y_test, preds)\n",
    "classificationReport = classification_report(y_test, preds)\n",
    "precisionScore = precision_score(y_test, preds)\n",
    "recallScore = recall_score(y_test, preds)\n",
    "f1Score = f1_score(y_test, preds)\n",
    "cohenKappaScore = cohen_kappa_score(y_test, preds)\n",
    "areaDebajoDeCurva = roc_auc_score(y_test, preds)\n",
    "matrizDeConfusion = confusion_matrix(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", trainAccuracy)\n",
    "print(\"Test acuracy: \", testAccuracy)\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(classificationReport)\n",
    "print()\n",
    "print(\"Precision Score: \",precisionScore)\n",
    "print(\"Recall Score: \",recallScore)\n",
    "print(\"F1 Score: \",f1Score)\n",
    "print(\"Cohen Kappa Score: \",cohenKappaScore)\n",
    "print(\"ROC auc score: \", areaDebajoDeCurva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matrizDeConfusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba duplicando los compradores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = labels_con_rango_horario_num.iloc[:,:-1], labels_con_rango_horario_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y, weight={1: 1, 0: 0.1})\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplico los compradores\n",
    "y_train_df = pd.DataFrame(y_train)\n",
    "y_train_df.columns = [\"label\"]\n",
    "train = pd.merge(X_train, y_train_df, how=\"inner\", left_index=True, right_index=True)\n",
    "train_compradores = train.loc[train[\"label\"] == 1]\n",
    "train_dup = pd.concat([train, train_compradores], ignore_index=True)\n",
    "X_train, y_train = train_dup.drop(columns=\"label\"), train_dup[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, eval_metric = \"auc\", min_child_weight=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=1, missing=None,\n",
       "       n_estimators=6, n_jobs=1, nthread=None, objective='binary:hinge',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.6285839489169901\n",
      "Test acuracy:  0.6108335524585853\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.60      0.75      3611\n",
      "           1       0.09      0.72      0.16       192\n",
      "\n",
      "   micro avg       0.61      0.61      0.61      3803\n",
      "   macro avg       0.53      0.66      0.45      3803\n",
      "weighted avg       0.93      0.61      0.72      3803\n",
      "\n",
      "\n",
      "Precision Score:  0.08876117496807152\n",
      "Recall Score:  0.7239583333333334\n",
      "F1 Score:  0.15813424345847552\n",
      "Cohen Kappa Score:  0.07492854595329301\n",
      "ROC auc score:  0.664388471568356\n",
      "Confusion matrix: \n",
      "[[2184 1427]\n",
      " [  53  139]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\\\n",
    "                            f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "# Pruebo todas las metricas.\n",
    "# accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\n",
    "# f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "\n",
    "trainAccuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "testAccuracy = accuracy_score(y_test, preds)\n",
    "\n",
    "meanSquaredError = mean_squared_error(y_test, preds)\n",
    "classificationReport = classification_report(y_test, preds)\n",
    "precisionScore = precision_score(y_test, preds)\n",
    "recallScore = recall_score(y_test, preds)\n",
    "f1Score = f1_score(y_test, preds)\n",
    "cohenKappaScore = cohen_kappa_score(y_test, preds)\n",
    "areaDebajoDeCurva = roc_auc_score(y_test, preds)\n",
    "matrizDeConfusion = confusion_matrix(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", trainAccuracy)\n",
    "print(\"Test acuracy: \", testAccuracy)\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(classificationReport)\n",
    "print()\n",
    "print(\"Precision Score: \",precisionScore)\n",
    "print(\"Recall Score: \",recallScore)\n",
    "print(\"F1 Score: \",f1Score)\n",
    "print(\"Cohen Kappa Score: \",cohenKappaScore)\n",
    "print(\"ROC auc score: \", areaDebajoDeCurva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matrizDeConfusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Con los datos transformados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = labels_con_rango_horario.loc[:,labels_con_rango_horario.columns != 'person']\n",
    "maxAbsScaler = preprocessing.MaxAbsScaler()\n",
    "x_scaled = maxAbsScaler.fit_transform(x)\n",
    "labels_con_rango_horario = pd.concat([labels_con_rango_horario['person'],pd.DataFrame(x_scaled)],axis = 1)\n",
    "labels_con_rango_horario_num = labels_con_rango_horario.drop(columns=\"person\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = labels_con_rango_horario_num.iloc[:,:-1], labels_con_rango_horario_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y, weight={1: 1, 0: 0.1})\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, eval_metric = \"auc\", min_child_weight=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=1000, missing=None,\n",
       "       n_estimators=6, n_jobs=1, nthread=None, objective='binary:hinge',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.850512753089666\n",
      "Test acuracy:  0.8535366815671838\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.88      0.92      3611\n",
      "         1.0       0.13      0.34      0.19       192\n",
      "\n",
      "   micro avg       0.85      0.85      0.85      3803\n",
      "   macro avg       0.55      0.61      0.56      3803\n",
      "weighted avg       0.92      0.85      0.88      3803\n",
      "\n",
      "\n",
      "Precision Score:  0.13279678068410464\n",
      "Recall Score:  0.34375\n",
      "F1 Score:  0.19158200290275762\n",
      "Cohen Kappa Score:  0.1280750665076711\n",
      "ROC auc score:  0.6121962406535586\n",
      "Confusion matrix: \n",
      "[[3180  431]\n",
      " [ 126   66]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\\\n",
    "                            f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "# Pruebo todas las metricas.\n",
    "# accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\n",
    "# f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "\n",
    "trainAccuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "testAccuracy = accuracy_score(y_test, preds)\n",
    "\n",
    "meanSquaredError = mean_squared_error(y_test, preds)\n",
    "classificationReport = classification_report(y_test, preds)\n",
    "precisionScore = precision_score(y_test, preds)\n",
    "recallScore = recall_score(y_test, preds)\n",
    "f1Score = f1_score(y_test, preds)\n",
    "cohenKappaScore = cohen_kappa_score(y_test, preds)\n",
    "areaDebajoDeCurva = roc_auc_score(y_test, preds)\n",
    "matrizDeConfusion = confusion_matrix(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", trainAccuracy)\n",
    "print(\"Test acuracy: \", testAccuracy)\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(classificationReport)\n",
    "print()\n",
    "print(\"Precision Score: \",precisionScore)\n",
    "print(\"Recall Score: \",recallScore)\n",
    "print(\"F1 Score: \",f1Score)\n",
    "print(\"Cohen Kappa Score: \",cohenKappaScore)\n",
    "print(\"ROC auc score: \", areaDebajoDeCurva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matrizDeConfusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba duplicando los compradores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = labels_con_rango_horario_num.iloc[:,:-1], labels_con_rango_horario_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y, weight={1: 1, 0: 0.1})\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplico los compradores\n",
    "y_train_df = pd.DataFrame(y_train)\n",
    "y_train_df.columns = [\"label\"]\n",
    "train = pd.merge(X_train, y_train_df, how=\"inner\", left_index=True, right_index=True)\n",
    "train_compradores = train.loc[train[\"label\"] == 1]\n",
    "train_dup = pd.concat([train, train_compradores], ignore_index=True)\n",
    "X_train, y_train = train_dup.drop(columns=\"label\"), train_dup[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, eval_metric = \"auc\", min_child_weight=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=1, missing=None,\n",
       "       n_estimators=6, n_jobs=1, nthread=None, objective='binary:hinge',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.6285839489169901\n",
      "Test acuracy:  0.6108335524585853\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.60      0.75      3611\n",
      "         1.0       0.09      0.72      0.16       192\n",
      "\n",
      "   micro avg       0.61      0.61      0.61      3803\n",
      "   macro avg       0.53      0.66      0.45      3803\n",
      "weighted avg       0.93      0.61      0.72      3803\n",
      "\n",
      "\n",
      "Precision Score:  0.08876117496807152\n",
      "Recall Score:  0.7239583333333334\n",
      "F1 Score:  0.15813424345847552\n",
      "Cohen Kappa Score:  0.07492854595329301\n",
      "ROC auc score:  0.664388471568356\n",
      "Confusion matrix: \n",
      "[[2184 1427]\n",
      " [  53  139]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\\\n",
    "                            f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "# Pruebo todas las metricas.\n",
    "# accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\n",
    "# f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "\n",
    "trainAccuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "testAccuracy = accuracy_score(y_test, preds)\n",
    "\n",
    "meanSquaredError = mean_squared_error(y_test, preds)\n",
    "classificationReport = classification_report(y_test, preds)\n",
    "precisionScore = precision_score(y_test, preds)\n",
    "recallScore = recall_score(y_test, preds)\n",
    "f1Score = f1_score(y_test, preds)\n",
    "cohenKappaScore = cohen_kappa_score(y_test, preds)\n",
    "areaDebajoDeCurva = roc_auc_score(y_test, preds)\n",
    "matrizDeConfusion = confusion_matrix(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", trainAccuracy)\n",
    "print(\"Test acuracy: \", testAccuracy)\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(classificationReport)\n",
    "print()\n",
    "print(\"Precision Score: \",precisionScore)\n",
    "print(\"Recall Score: \",recallScore)\n",
    "print(\"F1 Score: \",f1Score)\n",
    "print(\"Cohen Kappa Score: \",cohenKappaScore)\n",
    "print(\"ROC auc score: \", areaDebajoDeCurva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matrizDeConfusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------- Borrador -----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_importance(xg_reg)\n",
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "plt.show()\n",
    "\n",
    "objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, eval_metric = \"auc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"objective\":\"binary:hinge\",'colsample_bytree': 0.8,\n",
    "          'learning_rate': 0.1, 'max_depth': 5, \"n_estimators\" : 6}\n",
    "\n",
    "cv_results = xgb.cv(dtrain=data_dmatrix, params=params, nfold=10,\n",
    "                    num_boost_round=10,\n",
    "                    metrics=\"auc\", as_pandas=True, seed=123);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv_results.sort_values(\"train-auc-mean\", ascending=False)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_test = pd.read_csv(\"trocafone_kaggle_test.csv\")\n",
    "tf_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cantidad de entradas desde campañas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>criteo</th>\n",
       "      <th>emblue</th>\n",
       "      <th>google</th>\n",
       "      <th>rtbhouse</th>\n",
       "      <th>zanox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00091926</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091a7a</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000ba417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000c79fe</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000e4d9e</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  criteo  emblue  google  rtbhouse  zanox\n",
       "0  00091926     1.0     0.0    13.0       1.0    0.0\n",
       "1  00091a7a     0.0     0.0     1.0       0.0    0.0\n",
       "2  000ba417     0.0     0.0     1.0       0.0    0.0\n",
       "3  000c79fe     0.0     0.0     1.0       0.0    0.0\n",
       "4  000e4d9e     0.0     0.0     4.0       0.0    9.0"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_events_campaign = df[['person','campaign_source']].dropna()\n",
    "\n",
    "\n",
    "top_5_campanias = df_events_campaign['campaign_source'].value_counts().head(5).index\n",
    "df_events_campaign = df_events_campaign.loc[df_events_campaign['campaign_source'].isin(top_5_campanias)]\n",
    "df_events_campaign = pd.concat([df_events_campaign['person'],\\\n",
    "        pd.get_dummies(df_events_campaign['campaign_source'])],axis = 1).groupby('person').sum().reset_index()\n",
    "\n",
    "df_events_campaign = pd.merge(df_events_campaign, todas_las_personas, on=\"person\", how=\"right\").fillna(0)\n",
    "\n",
    "\n",
    "df_events_campaign.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veo cuantas personas a predecir pierdo\n",
    "df_events_campaign_predecir = pd.merge(df_events_campaign, df_persons, on=\"person\", how=\"inner\")\n",
    "df_events_campaign_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criteo</th>\n",
       "      <th>emblue</th>\n",
       "      <th>google</th>\n",
       "      <th>rtbhouse</th>\n",
       "      <th>zanox</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>...</th>\n",
       "      <th>cant_eng</th>\n",
       "      <th>cant_mod</th>\n",
       "      <th>cant_ev</th>\n",
       "      <th>check_tot</th>\n",
       "      <th>cant_entradas</th>\n",
       "      <th>cant_mes_5</th>\n",
       "      <th>entradas_30_dias</th>\n",
       "      <th>cant_mes</th>\n",
       "      <th>cant_dia_freq</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>63</td>\n",
       "      <td>189</td>\n",
       "      <td>15</td>\n",
       "      <td>471</td>\n",
       "      <td>290</td>\n",
       "      <td>358</td>\n",
       "      <td>290</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>54</td>\n",
       "      <td>64</td>\n",
       "      <td>54</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>54</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>46</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>26</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   criteo  emblue  google  rtbhouse  zanox    0    1    2    3    4  ...    \\\n",
       "0     0.0     0.0     1.0       0.0    0.0  0.0  1.0  0.0  0.0  0.0  ...     \n",
       "1     5.0     0.0    17.0       7.0    0.0  3.0  6.0  2.0  2.0  3.0  ...     \n",
       "2     3.0     0.0     4.0       0.0    0.0  0.0  3.0  6.0  3.0  0.0  ...     \n",
       "3     2.0     0.0    10.0       0.0    0.0  0.0  1.0  0.0  2.0  0.0  ...     \n",
       "4     0.0     0.0     2.0       0.0    0.0  0.0  0.0  0.0  1.0  1.0  ...     \n",
       "\n",
       "   cant_eng  cant_mod  cant_ev  check_tot  cant_entradas  cant_mes_5  \\\n",
       "0         1         4        9          1             17          17   \n",
       "1        12        63      189         15            471         290   \n",
       "2         6        20       52          1             96          54   \n",
       "3        10         8       17          3             54           5   \n",
       "4         1         3       17          1             38          26   \n",
       "\n",
       "   entradas_30_dias  cant_mes  cant_dia_freq  label  \n",
       "0                16        17             17      0  \n",
       "1               358       290             72      0  \n",
       "2                64        54             17      0  \n",
       "3                26        46             22      0  \n",
       "4                25        26             26      0  \n",
       "\n",
       "[5 rows x 93 columns]"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge\n",
    "labels_con_camps = pd.merge(df_events_campaign, labels_con_dia_semana, on=\"person\", how=\"inner\")\n",
    "labels_con_camps_num = labels_con_camps.drop(columns=\"person\")\n",
    "labels_con_camps_num.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = labels_con_camps_num.iloc[:,:-1], labels_con_camps_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y, weight={1: 1, 0: 0.1})\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, eval_metric = \"auc\", min_child_weight=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=1000, missing=None,\n",
       "       n_estimators=6, n_jobs=1, nthread=None, objective='binary:hinge',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8869953904176561\n",
      "Test acuracy:  0.8748603351955307\n",
      "ROC auc score:  0.5785714285714286\n",
      "Confusion matrix: \n",
      "[[1548  172]\n",
      " [  52   18]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos \n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cantidad de visitas a productos Apple y Samsung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>vistas_samsung</th>\n",
       "      <th>vistas_apple</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6abd2bf1</td>\n",
       "      <td>2051.0</td>\n",
       "      <td>2051.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b1f4dbf6</td>\n",
       "      <td>1866.0</td>\n",
       "      <td>1866.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9bf968c5</td>\n",
       "      <td>1557.0</td>\n",
       "      <td>1557.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bfb74b38</td>\n",
       "      <td>1526.0</td>\n",
       "      <td>1526.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6f19cfd9</td>\n",
       "      <td>1442.0</td>\n",
       "      <td>1442.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  vistas_samsung  vistas_apple\n",
       "0  6abd2bf1          2051.0        2051.0\n",
       "1  b1f4dbf6          1866.0        1866.0\n",
       "2  9bf968c5          1557.0        1557.0\n",
       "3  bfb74b38          1526.0        1526.0\n",
       "4  6f19cfd9          1442.0        1442.0"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_productos = df[[\"person\", \"event\", \"model\"]]\n",
    "df_productos = df_productos.loc[df_productos[\"event\"] == \"viewed product\"]\n",
    "df_productos = df_productos.loc[(df_productos[\"model\"].str.contains(\"iPhone\") )|( df_productos[\"model\"].str.contains(\"Samsung\") )]\n",
    "df_productos.head()\n",
    "\n",
    "df_apple = df_productos.loc[df_productos[\"model\"].str.contains(\"iPhone\")]\n",
    "df_samsung = df_productos.loc[df_productos[\"model\"].str.contains(\"Samsung\")]                           \n",
    "\n",
    "vistas_apple = df_apple[\"person\"].value_counts().reset_index()\n",
    "vistas_apple.columns = [\"person\", \"vistas_apple\"]\n",
    "\n",
    "vistas_samsung = df_apple[\"person\"].value_counts().reset_index()\n",
    "vistas_samsung.columns = [\"person\", \"vistas_samsung\"]\n",
    "\n",
    "vistas_prods = pd.merge(vistas_samsung, vistas_apple, on=\"person\", how=\"inner\")\n",
    "\n",
    "vistas_prods = pd.merge(vistas_prods, todas_las_personas, on=\"person\", how=\"right\").fillna(0)\n",
    "\n",
    "vistas_prods.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veo cuantas personas a predecir pierdo\n",
    "vistas_prods_predecir = pd.merge(vistas_prods, df_persons, on=\"person\", how=\"inner\")\n",
    "vistas_prods_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge\n",
    "\n",
    "df_con_vistas_prods = pd.merge(vistas_prods,labels_con_dia_semana, on=\"person\", how=\"inner\")\n",
    "\n",
    "df_con_vistas_prods_num = df_con_vistas_prods.drop(columns=\"person\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = df_con_vistas_prods_num.iloc[:,:-1], df_con_vistas_prods_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y)\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=6,\n",
       "       n_jobs=1, nthread=None, objective='binary:hinge', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.9113004609582344\n",
      "Test acuracy:  0.9016759776536313\n",
      "ROC auc score:  0.582583419606594\n",
      "Confusion matrix: \n",
      "[[1600  132]\n",
      " [  44   14]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos \n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cantidad de busquedas en 'searched products' y 'search engine hit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_search = df.loc[(df[\"event\"] == \"searched products\" )| (df[\"event\"] == \"search engine hit\" )]\n",
    "\n",
    "searched_products = df_search.loc[df_search[\"event\"] == \"searched products\"]\n",
    "cant_searched_products = searched_products[\"person\"].value_counts().reset_index()\n",
    "cant_searched_products.columns = [\"person\", \"cant_search_prod\"]\n",
    "\n",
    "engine_hit = df_search.loc[df_search[\"event\"] == \"search engine hit\"]\n",
    "cant_engine_hit = engine_hit[\"person\"].value_counts().reset_index()\n",
    "cant_engine_hit.columns = [\"person\", \"cant_engine_hit\"]\n",
    "\n",
    "cant_busquedas = pd.merge(cant_engine_hit, cant_searched_products, on=\"person\", how=\"inner\")\n",
    "\n",
    "cant_busquedas = pd.merge(cant_busquedas, todas_las_personas, on=\"person\", how=\"right\").fillna(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veo cuantas personas a predecir pierdo\n",
    "cant_busquedas_predecir = pd.merge(cant_busquedas, df_persons, on=\"person\", how=\"inner\")\n",
    "cant_busquedas_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cant_engine_hit</th>\n",
       "      <th>cant_search_prod</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>Chrome 65.0</th>\n",
       "      <th>...</th>\n",
       "      <th>cant_eng</th>\n",
       "      <th>cant_mod</th>\n",
       "      <th>cant_ev</th>\n",
       "      <th>check_tot</th>\n",
       "      <th>cant_entradas</th>\n",
       "      <th>cant_mes_5</th>\n",
       "      <th>entradas_30_dias</th>\n",
       "      <th>cant_mes</th>\n",
       "      <th>cant_dia_freq</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>245.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>245</td>\n",
       "      <td>170</td>\n",
       "      <td>744</td>\n",
       "      <td>47</td>\n",
       "      <td>2006</td>\n",
       "      <td>388</td>\n",
       "      <td>378</td>\n",
       "      <td>861</td>\n",
       "      <td>198</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>136.0</td>\n",
       "      <td>739.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>136</td>\n",
       "      <td>61</td>\n",
       "      <td>739</td>\n",
       "      <td>10</td>\n",
       "      <td>1609</td>\n",
       "      <td>1609</td>\n",
       "      <td>1608</td>\n",
       "      <td>1609</td>\n",
       "      <td>191</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>130.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>87</td>\n",
       "      <td>214</td>\n",
       "      <td>4</td>\n",
       "      <td>855</td>\n",
       "      <td>760</td>\n",
       "      <td>759</td>\n",
       "      <td>760</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>102.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>102</td>\n",
       "      <td>130</td>\n",
       "      <td>450</td>\n",
       "      <td>2</td>\n",
       "      <td>1025</td>\n",
       "      <td>103</td>\n",
       "      <td>105</td>\n",
       "      <td>585</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>...</td>\n",
       "      <td>93</td>\n",
       "      <td>416</td>\n",
       "      <td>692</td>\n",
       "      <td>17</td>\n",
       "      <td>1593</td>\n",
       "      <td>412</td>\n",
       "      <td>420</td>\n",
       "      <td>956</td>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cant_engine_hit  cant_search_prod     0     1     2     3     4     5  \\\n",
       "0            245.0               3.0  22.0  15.0  22.0  16.0  28.0  19.0   \n",
       "1            136.0             739.0   9.0   8.0  14.0  13.0   6.0  10.0   \n",
       "2            130.0             214.0  18.0  14.0  12.0  14.0   7.0   9.0   \n",
       "3            102.0               2.0  17.0  21.0  24.0  24.0  21.0  14.0   \n",
       "4             93.0             121.0  26.0  23.0  33.0  20.0  33.0  23.0   \n",
       "\n",
       "      6  Chrome 65.0  ...    cant_eng  cant_mod  cant_ev  check_tot  \\\n",
       "0  19.0          4.0  ...         245       170      744         47   \n",
       "1   6.0          0.0  ...         136        61      739         10   \n",
       "2  12.0          0.0  ...         130        87      214          4   \n",
       "3  14.0         29.0  ...         102       130      450          2   \n",
       "4   7.0         56.0  ...          93       416      692         17   \n",
       "\n",
       "   cant_entradas  cant_mes_5  entradas_30_dias  cant_mes  cant_dia_freq  label  \n",
       "0           2006         388               378       861            198      0  \n",
       "1           1609        1609              1608      1609            191      0  \n",
       "2            855         760               759       760            138      0  \n",
       "3           1025         103               105       585            102      0  \n",
       "4           1593         412               420       956            216      0  \n",
       "\n",
       "[5 rows x 90 columns]"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge\n",
    "\n",
    "labels_con_busq = pd.merge(cant_busquedas, labels_con_dia_semana, on=\"person\", how=\"inner\")\n",
    "labels_con_busq_num = labels_con_busq.drop(columns=\"person\")\n",
    "labels_con_busq_num.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = labels_con_busq_num.iloc[:,:-1], labels_con_busq_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y)\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, scale_pos_weight = 100, min_child_weight=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1000, missing=None, n_estimators=6,\n",
       "       n_jobs=1, nthread=None, objective='binary:hinge', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=100, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8112864925268892\n",
      "Test acuracy:  0.8011173184357542\n",
      "ROC auc score:  0.6384819951317123\n",
      "Confusion matrix: \n",
      "[[1403  320]\n",
      " [  36   31]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos \n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### duplico compradores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1022,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = labels_con_busq_num.iloc[:,:-1], labels_con_busq_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y, weight={1: 1, 0: 0.1})\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1023,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplico los compradores\n",
    "\n",
    "y_train_df = y_train.to_frame()\n",
    "X_train_df = X_train.reset_index()\n",
    "train = pd.merge(X_train, y_train_df, how=\"inner\", left_index=True, right_index=True)\n",
    "train_compradores = train.loc[train[\"label\"] == 1]\n",
    "train_dup = pd.concat([train, train_compradores], ignore_index=True)\n",
    "X_train, y_train = train_dup.drop(columns=\"label\"), train_dup[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1024,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, eval_metric = \"auc\", min_child_weight=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1025,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=1, missing=None,\n",
       "       n_estimators=6, n_jobs=1, nthread=None, objective='binary:hinge',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 1025,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1026,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1027,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.7886639676113361\n",
      "Test acuracy:  0.764804469273743\n",
      "ROC auc score:  0.6339645359967429\n",
      "Confusion matrix: \n",
      "[[1336  387]\n",
      " [  34   33]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos \n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1028,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.7886639676113361\n",
      "Test acuracy:  0.764804469273743\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.78      0.86      1723\n",
      "           1       0.08      0.49      0.14        67\n",
      "\n",
      "   micro avg       0.76      0.76      0.76      1790\n",
      "   macro avg       0.53      0.63      0.50      1790\n",
      "weighted avg       0.94      0.76      0.84      1790\n",
      "\n",
      "\n",
      "Precision Score:  0.07857142857142857\n",
      "Recall Score:  0.4925373134328358\n",
      "F1 Score:  0.135523613963039\n",
      "Cohen Kappa Score:  0.07585995462628004\n",
      "ROC auc score:  0.6339645359967429\n",
      "Confusion matrix: \n",
      "[[1336  387]\n",
      " [  34   33]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\\\n",
    "                            f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "# Pruebo todas las metricas.\n",
    "# accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\n",
    "# f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "\n",
    "trainAccuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "testAccuracy = accuracy_score(y_test, preds)\n",
    "\n",
    "meanSquaredError = mean_squared_error(y_test, preds)\n",
    "classificationReport = classification_report(y_test, preds)\n",
    "precisionScore = precision_score(y_test, preds)\n",
    "recallScore = recall_score(y_test, preds)\n",
    "f1Score = f1_score(y_test, preds)\n",
    "cohenKappaScore = cohen_kappa_score(y_test, preds)\n",
    "areaDebajoDeCurva = roc_auc_score(y_test, preds)\n",
    "matrizDeConfusion = confusion_matrix(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", trainAccuracy)\n",
    "print(\"Test acuracy: \", testAccuracy)\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(classificationReport)\n",
    "print()\n",
    "print(\"Precision Score: \",precisionScore)\n",
    "print(\"Recall Score: \",recallScore)\n",
    "print(\"F1 Score: \",f1Score)\n",
    "print(\"Cohen Kappa Score: \",cohenKappaScore)\n",
    "print(\"ROC auc score: \", areaDebajoDeCurva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matrizDeConfusion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
