{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 832,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt \n",
    "from datetime import timedelta\n",
    "%matplotlib inline\n",
    "\n",
    "#from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seba\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3020: DtypeWarning: Columns (3,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "labels = pd.read_csv(\"fiuba-trocafone-tp2-final-set/labels_training_set.csv\")\n",
    "df = pd.read_csv(\"fiuba-trocafone-tp2-final-set/events_up_to_01062018.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_persons = pd.read_csv(\"tp2-github/data/trocafone_kaggle_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
    "df[\"month\"] = df[\"timestamp\"].dt.month\n",
    "df[\"day\"] = df[\"timestamp\"].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['timestamp', 'event', 'person', 'url', 'sku', 'model', 'condition',\n",
       "       'storage', 'color', 'skus', 'search_term', 'staticpage',\n",
       "       'campaign_source', 'search_engine', 'channel', 'new_vs_returning',\n",
       "       'city', 'region', 'country', 'device_type', 'screen_resolution',\n",
       "       'operating_system_version', 'browser_version', 'month', 'day'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "viewed product       1248124\n",
       "brand listing         216312\n",
       "visited site          204069\n",
       "ad campaign hit       191388\n",
       "generic listing       160176\n",
       "searched products     130616\n",
       "search engine hit     106406\n",
       "checkout               65315\n",
       "staticpage             11201\n",
       "conversion              7091\n",
       "lead                     983\n",
       "Name: event, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"event\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dia, mes con mayor cantidad de visitas de cada persona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>day</th>\n",
       "      <th>cant_dia_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99325</th>\n",
       "      <td>c76b8417</td>\n",
       "      <td>3</td>\n",
       "      <td>652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28266</th>\n",
       "      <td>37eff05b</td>\n",
       "      <td>29</td>\n",
       "      <td>616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112559</th>\n",
       "      <td>e1443dd4</td>\n",
       "      <td>30</td>\n",
       "      <td>572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51164</th>\n",
       "      <td>656c18ef</td>\n",
       "      <td>10</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41082</th>\n",
       "      <td>50e16a8a</td>\n",
       "      <td>19</td>\n",
       "      <td>423</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          person  day  cant_dia_freq\n",
       "99325   c76b8417    3            652\n",
       "28266   37eff05b   29            616\n",
       "112559  e1443dd4   30            572\n",
       "51164   656c18ef   10            512\n",
       "41082   50e16a8a   19            423"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dia con mas entradas y su cantidad de entradas\n",
    "\n",
    "entradas_x_dia = df.groupby(\"person\")['day'].value_counts().rename(\"cant_dia_freq\").reset_index()\n",
    "entradas_x_dia.columns = ['person', 'day', 'cant_dia_freq']\n",
    "entradas_x_dia = entradas_x_dia.sort_values('cant_dia_freq',ascending=False)\n",
    "dia_mas_entradas = entradas_x_dia.drop_duplicates(subset=['person'])\n",
    "dia_mas_entradas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>month</th>\n",
       "      <th>cant_mes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>38966</th>\n",
       "      <td>c76b8417</td>\n",
       "      <td>5</td>\n",
       "      <td>3028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18217</th>\n",
       "      <td>5c76e694</td>\n",
       "      <td>5</td>\n",
       "      <td>1609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32890</th>\n",
       "      <td>a7ffa917</td>\n",
       "      <td>5</td>\n",
       "      <td>1604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4824</th>\n",
       "      <td>18489dd5</td>\n",
       "      <td>5</td>\n",
       "      <td>1563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9989</th>\n",
       "      <td>33385551</td>\n",
       "      <td>4</td>\n",
       "      <td>1539</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         person  month  cant_mes\n",
       "38966  c76b8417      5      3028\n",
       "18217  5c76e694      5      1609\n",
       "32890  a7ffa917      5      1604\n",
       "4824   18489dd5      5      1563\n",
       "9989   33385551      4      1539"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mes con mas entradas y su cantidad de entradas\n",
    "\n",
    "entradas_x_mes = df.groupby(\"person\")['month'].value_counts().rename(\"cant_mes\").reset_index()\n",
    "entradas_x_mes.columns = ['person', 'month', 'cant_mes']\n",
    "entradas_x_mes = entradas_x_mes.sort_values('cant_mes',ascending=False)\n",
    "mes_mas_entradas = entradas_x_mes.drop_duplicates(subset=['person'])\n",
    "mes_mas_entradas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>cant_mes</th>\n",
       "      <th>cant_dia_freq</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5c76e694</td>\n",
       "      <td>1609</td>\n",
       "      <td>191</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18489dd5</td>\n",
       "      <td>1563</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1775ba85</td>\n",
       "      <td>1450</td>\n",
       "      <td>126</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6abd2bf1</td>\n",
       "      <td>1334</td>\n",
       "      <td>300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>97b0c0d1</td>\n",
       "      <td>1328</td>\n",
       "      <td>217</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  cant_mes  cant_dia_freq  label\n",
       "0  5c76e694      1609            191      0\n",
       "1  18489dd5      1563            174      0\n",
       "2  1775ba85      1450            126      0\n",
       "3  6abd2bf1      1334            300      0\n",
       "4  97b0c0d1      1328            217      0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge\n",
    "\n",
    "cant_mes_mas_entradas = mes_mas_entradas[[\"person\", \"cant_mes\"]]\n",
    "cant_dia_mas_entradas = dia_mas_entradas[[\"person\", \"cant_dia_freq\"]]\n",
    "\n",
    "mes_dia_mas_entradas = pd.merge(cant_mes_mas_entradas, cant_dia_mas_entradas, on=\"person\", how=\"inner\")\n",
    "\n",
    "df_con_labels = pd.merge(mes_dia_mas_entradas, labels, on=\"person\", how=\"inner\")\n",
    "df_con_labels.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "mes_dia_mas_entradas_predecir = pd.merge(mes_dia_mas_entradas, df_persons, on=\"person\", how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mes_dia_mas_entradas_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_con_labels_num = df_con_labels[[\"cant_mes\", \"cant_dia_freq\", \"label\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = df_con_labels_num.iloc[:,:-1],df_con_labels_num.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, scale_pos_weight = 1, min_child_weight=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=6,\n",
       "       n_jobs=1, nthread=None, objective='binary:hinge', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.9303328826218531\n",
      "Test acuracy:  0.927890806077775\n",
      "ROC auc score:  0.5285741205381574\n",
      "Confusion matrix: \n",
      "[[3586   86]\n",
      " [ 194   17]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos que onda\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entradas en los ultimos 30 dias (hasta la ultima visita)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>last_day</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0008ed71</td>\n",
       "      <td>2018-05-17 16:28:37</td>\n",
       "      <td>2018-05-17 12:27:47</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0008ed71</td>\n",
       "      <td>2018-05-17 16:28:37</td>\n",
       "      <td>2018-05-17 13:45:00</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0008ed71</td>\n",
       "      <td>2018-05-17 16:28:37</td>\n",
       "      <td>2018-05-17 16:22:06</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0008ed71</td>\n",
       "      <td>2018-05-17 16:28:37</td>\n",
       "      <td>2018-05-17 13:44:59</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0008ed71</td>\n",
       "      <td>2018-05-17 16:28:37</td>\n",
       "      <td>2018-05-17 16:21:54</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person            last_day           timestamp  month\n",
       "1  0008ed71 2018-05-17 16:28:37 2018-05-17 12:27:47      5\n",
       "2  0008ed71 2018-05-17 16:28:37 2018-05-17 13:45:00      5\n",
       "3  0008ed71 2018-05-17 16:28:37 2018-05-17 16:22:06      5\n",
       "4  0008ed71 2018-05-17 16:28:37 2018-05-17 13:44:59      5\n",
       "5  0008ed71 2018-05-17 16:28:37 2018-05-17 16:21:54      5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meses = df[[\"timestamp\", \"person\", \"month\"]]\n",
    "df_ultimo_dia = df_meses.groupby(\"person\")[\"timestamp\"].max().reset_index()\n",
    "df_ultimo_dia.columns = [\"person\", \"last_day\"]\n",
    "df_meses_ultimo_dia = pd.merge(df_ultimo_dia, df_meses, on=\"person\", how=\"inner\")\n",
    "entradas_30_dias = df_meses_ultimo_dia.loc[((df_meses_ultimo_dia[\"last_day\"] - timedelta(days=30)) < \\\n",
    "                                           df_meses_ultimo_dia[\"timestamp\"]) & (df_meses_ultimo_dia[\"timestamp\"]< \\\n",
    "                                           df_meses_ultimo_dia[\"last_day\"])]\n",
    "entradas_30_dias.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>entradas_30_dias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c76b8417</td>\n",
       "      <td>3027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5c76e694</td>\n",
       "      <td>1608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a7ffa917</td>\n",
       "      <td>1603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18489dd5</td>\n",
       "      <td>1562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>622b4acf</td>\n",
       "      <td>1458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  entradas_30_dias\n",
       "0  c76b8417              3027\n",
       "1  5c76e694              1608\n",
       "2  a7ffa917              1603\n",
       "3  18489dd5              1562\n",
       "4  622b4acf              1458"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entradas_30_dias_df = entradas_30_dias[\"person\"].value_counts().rename(\"entradas_30_dias\").reset_index()\n",
    "entradas_30_dias_df.columns = [\"person\", \"entradas_30_dias\"]\n",
    "entradas_30_dias_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>entradas_30_dias</th>\n",
       "      <th>cant_mes</th>\n",
       "      <th>cant_dia_freq</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5c76e694</td>\n",
       "      <td>1608</td>\n",
       "      <td>1609</td>\n",
       "      <td>191</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18489dd5</td>\n",
       "      <td>1562</td>\n",
       "      <td>1563</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6abd2bf1</td>\n",
       "      <td>1319</td>\n",
       "      <td>1334</td>\n",
       "      <td>300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>97b0c0d1</td>\n",
       "      <td>1306</td>\n",
       "      <td>1328</td>\n",
       "      <td>217</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>595b9b50</td>\n",
       "      <td>1177</td>\n",
       "      <td>1179</td>\n",
       "      <td>377</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  entradas_30_dias  cant_mes  cant_dia_freq  label\n",
       "0  5c76e694              1608      1609            191      0\n",
       "1  18489dd5              1562      1563            174      0\n",
       "2  6abd2bf1              1319      1334            300      0\n",
       "3  97b0c0d1              1306      1328            217      0\n",
       "4  595b9b50              1177      1179            377      0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge\n",
    "\n",
    "df_con_labels2 = pd.merge(entradas_30_dias_df, df_con_labels, on=\"person\", how=\"inner\")\n",
    "df_con_labels2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-442"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entradas_30_dias_predecir = pd.merge(entradas_30_dias_df, df_persons, on=\"person\", how=\"inner\")\n",
    "entradas_30_dias_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_con_labels2_num = df_con_labels2[[\"entradas_30_dias\", \"cant_mes\", \"cant_dia_freq\", \"label\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = df_con_labels2_num.iloc[:,:-1], df_con_labels2_num.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, scale_pos_weight = 1, min_child_weight=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=6,\n",
       "       n_jobs=1, nthread=None, objective='binary:hinge', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.9202603207993689\n",
      "Test acuracy:  0.9103339468840389\n",
      "ROC auc score:  0.521793575484172\n",
      "Confusion matrix: \n",
      "[[3444  144]\n",
      " [ 197   18]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos que onda\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entradas en el ultimo mes (mes 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>cant_mes_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008ed71</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091926</td>\n",
       "      <td>448.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000ba417</td>\n",
       "      <td>206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000c79fe</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000e4d9e</td>\n",
       "      <td>411.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  cant_mes_5\n",
       "0  0008ed71         6.0\n",
       "1  00091926       448.0\n",
       "2  000ba417       206.0\n",
       "3  000c79fe        17.0\n",
       "4  000e4d9e       411.0"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "todas_las_personas = df_meses[[\"person\"]].drop_duplicates(subset=\"person\")\n",
    "entradas_mes_5 = df_meses.loc[df_meses[\"month\"] == 5]\n",
    "cant_entradas_mes_5 = entradas_mes_5.groupby(\"person\").agg({\"month\": \"count\"}).reset_index()\n",
    "cant_entradas_mes_5.columns = [\"person\", \"cant_mes_5\"]\n",
    "cant_entradas_mes_5 = pd.merge(cant_entradas_mes_5, todas_las_personas, on=\"person\", how=\"right\").fillna(0)\n",
    "cant_entradas_mes_5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>cant_mes_5</th>\n",
       "      <th>entradas_30_dias</th>\n",
       "      <th>cant_mes</th>\n",
       "      <th>cant_dia_freq</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008ed71</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000c79fe</td>\n",
       "      <td>17.0</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001802e4</td>\n",
       "      <td>19.0</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0019e639</td>\n",
       "      <td>290.0</td>\n",
       "      <td>358</td>\n",
       "      <td>290</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001b0bf9</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  cant_mes_5  entradas_30_dias  cant_mes  cant_dia_freq  label\n",
       "0  0008ed71         6.0                 5         6              6      0\n",
       "1  000c79fe        17.0                16        17             17      0\n",
       "2  001802e4        19.0                18        19             19      0\n",
       "3  0019e639       290.0               358       290             72      0\n",
       "4  001b0bf9         7.0                 6         7              7      0"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge\n",
    "\n",
    "df_con_mes_5 = pd.merge(cant_entradas_mes_5, df_con_labels2, on=\"person\", how=\"inner\")\n",
    "df_con_mes_5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veo cuantas personas a predecir pierdo\n",
    "entradas_mes_5_predecir = pd.merge(cant_entradas_mes_5, df_persons, on=\"person\", how=\"inner\")\n",
    "entradas_mes_5_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 915,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "df_con_mes_5_num = df_con_mes_5.drop(columns=\"person\")\n",
    "\n",
    "X, y = df_con_mes_5_num.iloc[:,:-1],df_con_mes_5_num.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 916,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 917,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 918,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, scale_pos_weight = 1, min_child_weight=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 919,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=6,\n",
       "       n_jobs=1, nthread=None, objective='binary:hinge', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 919,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 920,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 921,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8679332106231922\n",
      "Test acuracy:  0.8645805942676834\n",
      "ROC auc score:  0.5890356751491538\n",
      "Confusion matrix: \n",
      "[[3234  378]\n",
      " [ 137   54]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos que onda\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cantidad de entradas totales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>cant_entradas</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008ed71</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091926</td>\n",
       "      <td>448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00091a7a</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000ba417</td>\n",
       "      <td>206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000c79fe</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  cant_entradas\n",
       "0  0008ed71              6\n",
       "1  00091926            448\n",
       "2  00091a7a             10\n",
       "3  000ba417            206\n",
       "4  000c79fe             17"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entradas_tot = df.groupby(\"person\").agg({\"person\": \"count\"})\n",
    "#cant_entradas_tot = entradas_tot[[\"person\", \"entradas_tot\"]]\n",
    "entradas_tot.columns = [\"cant_entradas\"]\n",
    "entradas_tot.reset_index(inplace=True)\n",
    "entradas_tot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>cant_entradas</th>\n",
       "      <th>cant_mes_5</th>\n",
       "      <th>entradas_30_dias</th>\n",
       "      <th>cant_mes</th>\n",
       "      <th>cant_dia_freq</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008ed71</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000c79fe</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001802e4</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0019e639</td>\n",
       "      <td>471</td>\n",
       "      <td>290</td>\n",
       "      <td>358</td>\n",
       "      <td>290</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001b0bf9</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  cant_entradas  cant_mes_5  entradas_30_dias  cant_mes  \\\n",
       "0  0008ed71              6           6                 5         6   \n",
       "1  000c79fe             17          17                16        17   \n",
       "2  001802e4             19          19                18        19   \n",
       "3  0019e639            471         290               358       290   \n",
       "4  001b0bf9              7           7                 6         7   \n",
       "\n",
       "   cant_dia_freq  label  \n",
       "0              6      0  \n",
       "1             17      0  \n",
       "2             19      0  \n",
       "3             72      0  \n",
       "4              7      0  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge\n",
    "\n",
    "df_con_entradas = pd.merge(entradas_tot, df_con_mes_5, on=\"person\", how=\"inner\")\n",
    "df_con_entradas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veo cuantas personas a predecir pierdo\n",
    "entradas_tot_predecir = pd.merge(entradas_tot, df_persons, on=\"person\", how=\"inner\")\n",
    "entradas_tot_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 922,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "df_con_entradas_num = df_con_entradas.drop(columns=\"person\")\n",
    "\n",
    "X, y = df_con_entradas_num.iloc[:,:-1],df_con_entradas_num.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 923,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 924,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 925,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, scale_pos_weight = 1, min_child_weight=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 926,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=6,\n",
       "       n_jobs=1, nthread=None, objective='binary:hinge', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 926,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 927,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 928,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.9041838134430727\n",
      "Test acuracy:  0.8973936899862826\n",
      "ROC auc score:  0.5427985467769387\n",
      "Confusion matrix: \n",
      "[[3246  236]\n",
      " [ 138   25]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos que onda\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cantidad de checkouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkouts = df.loc[df[\"event\"] == \"checkout\"]\n",
    "\n",
    "checkouts_tot = checkouts.groupby(\"person\")[\"event\"].value_counts().rename(\"check_tot\").reset_index()\n",
    "cant_checkouts_tot = checkouts_tot[[\"person\", \"check_tot\"]]\n",
    "cant_checkouts_tot = pd.merge(cant_entradas_mes_5, todas_las_personas, on=\"person\", how=\"right\").fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>cant_mes_5_x</th>\n",
       "      <th>cant_entradas</th>\n",
       "      <th>cant_mes_5_y</th>\n",
       "      <th>entradas_30_dias</th>\n",
       "      <th>cant_mes</th>\n",
       "      <th>cant_dia_freq</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008ed71</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000c79fe</td>\n",
       "      <td>17.0</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>001802e4</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0019e639</td>\n",
       "      <td>290.0</td>\n",
       "      <td>471</td>\n",
       "      <td>290</td>\n",
       "      <td>358</td>\n",
       "      <td>290</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>001b0bf9</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  cant_mes_5_x  cant_entradas  cant_mes_5_y  entradas_30_dias  \\\n",
       "0  0008ed71           6.0              6             6                 5   \n",
       "1  000c79fe          17.0             17            17                16   \n",
       "2  001802e4          19.0             19            19                18   \n",
       "3  0019e639         290.0            471           290               358   \n",
       "4  001b0bf9           7.0              7             7                 6   \n",
       "\n",
       "   cant_mes  cant_dia_freq  label  \n",
       "0         6              6      0  \n",
       "1        17             17      0  \n",
       "2        19             19      0  \n",
       "3       290             72      0  \n",
       "4         7              7      0  "
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge\n",
    "\n",
    "df_con_check = pd.merge(cant_checkouts_tot, df_con_entradas, on=\"person\", how=\"inner\")\n",
    "df_con_check.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost solo usa valores numericos\n",
    "df_con_check_num = df_con_check.drop(columns=\"person\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veo cuantas personas a predecir pierdo\n",
    "cant_checkouts_tot_predecir = pd.merge(cant_checkouts_tot, df_persons, on=\"person\", how=\"inner\")\n",
    "cant_checkouts_tot_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = df_con_check_num.iloc[:,:-1], df_con_check_num.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, scale_pos_weight = 1, min_child_weight=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=6,\n",
       "       n_jobs=1, nthread=None, objective='binary:hinge', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.9448868071818891\n",
      "Test acuracy:  0.9375585388698096\n",
      "ROC auc score:  0.5753296607423287\n",
      "Confusion matrix: \n",
      "[[2988  138]\n",
      " [  62   15]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos que onda\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cantidad de entradas al evento mas visitado por cada persona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>cant_ev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>97161</th>\n",
       "      <td>6abd2bf1</td>\n",
       "      <td>2355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160896</th>\n",
       "      <td>b1f4dbf6</td>\n",
       "      <td>2233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129961</th>\n",
       "      <td>8fb4929e</td>\n",
       "      <td>1912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141831</th>\n",
       "      <td>9ccf882a</td>\n",
       "      <td>1891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6202</th>\n",
       "      <td>06ed04d6</td>\n",
       "      <td>1881</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          person  cant_ev\n",
       "97161   6abd2bf1     2355\n",
       "160896  b1f4dbf6     2233\n",
       "129961  8fb4929e     1912\n",
       "141831  9ccf882a     1891\n",
       "6202    06ed04d6     1881"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = df.groupby(\"person\")['event'].value_counts().rename().reset_index()\n",
    "s.columns = ['person', 'event', 'cant_ev']\n",
    "s = s.sort_values('cant_ev',ascending=False)\n",
    "mayor_evento = s.drop_duplicates(subset=['person']).drop(columns=\"event\")\n",
    "mayor_evento.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>cant_mod</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b1f4dbf6</td>\n",
       "      <td>836.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>171e75cb</td>\n",
       "      <td>683.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6f19cfd9</td>\n",
       "      <td>624.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6abd2bf1</td>\n",
       "      <td>607.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9bf968c5</td>\n",
       "      <td>568.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  cant_mod\n",
       "0  b1f4dbf6     836.0\n",
       "1  171e75cb     683.0\n",
       "2  6f19cfd9     624.0\n",
       "3  6abd2bf1     607.0\n",
       "4  9bf968c5     568.0"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cantidad de entradas al modelo mas visitado por cada persona\n",
    "\n",
    "mod = df.groupby(\"person\")['model'].value_counts().rename().reset_index()\n",
    "mod.columns = ['person', 'model', 'cant_mod']\n",
    "mod = mod.sort_values('cant_mod',ascending=False)\n",
    "mayor_modelo = mod.drop_duplicates(subset=['person']).drop(columns=\"model\")\n",
    "mayor_modelo = pd.merge(mayor_modelo, todas_las_personas, on=\"person\", how=\"right\").fillna(0)\n",
    "mayor_modelo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>cant_eng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c76b8417</td>\n",
       "      <td>762.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6ca3126e</td>\n",
       "      <td>245.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>622b4acf</td>\n",
       "      <td>206.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25b77cf2</td>\n",
       "      <td>161.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5c76e694</td>\n",
       "      <td>136.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  cant_eng\n",
       "0  c76b8417     762.0\n",
       "1  6ca3126e     245.0\n",
       "2  622b4acf     206.0\n",
       "3  25b77cf2     161.0\n",
       "4  5c76e694     136.0"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cantidad de entradas al search engine mas visitado por cada persona\n",
    "\n",
    "eng = df.groupby(\"person\")['search_engine'].value_counts().rename().reset_index()\n",
    "eng.columns = ['person', 'search_engine', 'cant_eng']\n",
    "eng = eng.sort_values('cant_eng',ascending=False)\n",
    "mayor_engine = eng.drop_duplicates(subset=['person']).drop(columns=\"search_engine\")\n",
    "mayor_engine = pd.merge(mayor_engine, todas_las_personas, on=\"person\", how=\"right\").fillna(0)\n",
    "mayor_engine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>cant_src</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02f14240</td>\n",
       "      <td>500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c76b8417</td>\n",
       "      <td>374.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6ca3126e</td>\n",
       "      <td>335.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>622b4acf</td>\n",
       "      <td>282.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3b2d17f6</td>\n",
       "      <td>221.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  cant_src\n",
       "0  02f14240     500.0\n",
       "1  c76b8417     374.0\n",
       "2  6ca3126e     335.0\n",
       "3  622b4acf     282.0\n",
       "4  3b2d17f6     221.0"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cantidad de entradas al campaign source mas visitado por cada persona\n",
    "\n",
    "src = df.groupby(\"person\")['campaign_source'].value_counts().rename().reset_index()\n",
    "src.columns = ['person', 'campaign_source', 'cant_src']\n",
    "src = src.sort_values('cant_src',ascending=False)\n",
    "mayor_camp = src.drop_duplicates(subset=['person']).drop(columns=\"campaign_source\")\n",
    "mayor_camp = pd.merge(mayor_camp, todas_las_personas, on=\"person\", how=\"right\").fillna(0)\n",
    "mayor_camp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>cant_city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5059f7fd</td>\n",
       "      <td>268.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7ac0c607</td>\n",
       "      <td>208.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67bdc946</td>\n",
       "      <td>207.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ffee0f18</td>\n",
       "      <td>173.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9b3b43aa</td>\n",
       "      <td>171.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  cant_city\n",
       "0  5059f7fd      268.0\n",
       "1  7ac0c607      208.0\n",
       "2  67bdc946      207.0\n",
       "3  ffee0f18      173.0\n",
       "4  9b3b43aa      171.0"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cantidad de entradas desde la ciudad mas frecuente de cada persona\n",
    "\n",
    "cty = df.groupby(\"person\")['city'].value_counts().rename().reset_index()\n",
    "cty.columns = ['person', 'city', 'cant_city']\n",
    "src = cty.sort_values('cant_city',ascending=False)\n",
    "mayor_ciudad = src.drop_duplicates(subset=['person']).drop(columns=\"city\")\n",
    "mayor_ciudad = pd.merge(mayor_ciudad, todas_las_personas, on=\"person\", how=\"right\").fillna(0)\n",
    "mayor_ciudad.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>cant_city</th>\n",
       "      <th>cant_src</th>\n",
       "      <th>cant_eng</th>\n",
       "      <th>cant_mod</th>\n",
       "      <th>cant_ev</th>\n",
       "      <th>cant_mes_5_x</th>\n",
       "      <th>cant_entradas</th>\n",
       "      <th>cant_mes_5_y</th>\n",
       "      <th>entradas_30_dias</th>\n",
       "      <th>cant_mes</th>\n",
       "      <th>cant_dia_freq</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ffee0f18</td>\n",
       "      <td>173.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1518</td>\n",
       "      <td>218.0</td>\n",
       "      <td>3458</td>\n",
       "      <td>218</td>\n",
       "      <td>217</td>\n",
       "      <td>1028</td>\n",
       "      <td>282</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9b3b43aa</td>\n",
       "      <td>171.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>468.0</td>\n",
       "      <td>1289</td>\n",
       "      <td>246.0</td>\n",
       "      <td>1663</td>\n",
       "      <td>246</td>\n",
       "      <td>234</td>\n",
       "      <td>923</td>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>02f14240</td>\n",
       "      <td>155.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>272.0</td>\n",
       "      <td>523</td>\n",
       "      <td>225.0</td>\n",
       "      <td>1798</td>\n",
       "      <td>225</td>\n",
       "      <td>282</td>\n",
       "      <td>847</td>\n",
       "      <td>114</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>345fc18e</td>\n",
       "      <td>153.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>844</td>\n",
       "      <td>367.0</td>\n",
       "      <td>1569</td>\n",
       "      <td>367</td>\n",
       "      <td>364</td>\n",
       "      <td>1007</td>\n",
       "      <td>137</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30ec9daf</td>\n",
       "      <td>152.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>423</td>\n",
       "      <td>185.0</td>\n",
       "      <td>803</td>\n",
       "      <td>185</td>\n",
       "      <td>184</td>\n",
       "      <td>189</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  cant_city  cant_src  cant_eng  cant_mod  cant_ev  cant_mes_5_x  \\\n",
       "0  ffee0f18      173.0      76.0      65.0      80.0     1518         218.0   \n",
       "1  9b3b43aa      171.0      17.0       4.0     468.0     1289         246.0   \n",
       "2  02f14240      155.0     500.0       6.0     272.0      523         225.0   \n",
       "3  345fc18e      153.0     155.0      10.0     106.0      844         367.0   \n",
       "4  30ec9daf      152.0      30.0      10.0      83.0      423         185.0   \n",
       "\n",
       "   cant_entradas  cant_mes_5_y  entradas_30_dias  cant_mes  cant_dia_freq  \\\n",
       "0           3458           218               217      1028            282   \n",
       "1           1663           246               234       923            174   \n",
       "2           1798           225               282       847            114   \n",
       "3           1569           367               364      1007            137   \n",
       "4            803           185               184       189             68   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge\n",
    "\n",
    "from functools import reduce\n",
    "\n",
    "# merge de todos los dfs\n",
    "\n",
    "dfs = [mayor_ciudad, mayor_camp, mayor_engine, mayor_modelo, mayor_evento]\n",
    "df_final1 = reduce(lambda left,right: pd.merge(left,right,on='person', how='inner'), dfs)\n",
    "df_final = pd.merge(df_final1, df_con_check, on=\"person\", how=\"inner\")\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_num = df_final.drop(columns=\"person\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veo cuantas personas a predecir pierdo\n",
    "df1_predecir = pd.merge(df_final1, df_persons, on=\"person\", how=\"inner\")\n",
    "df1_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = df_final_num.iloc[:,:-1], df_final_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y)\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, scale_pos_weight = 1, min_child_weight=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=6,\n",
       "       n_jobs=1, nthread=None, objective='binary:hinge', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8734567901234568\n",
      "Test acuracy:  0.8716049382716049\n",
      "ROC auc score:  0.596550004757156\n",
      "Confusion matrix: \n",
      "[[3129  353]\n",
      " [ 115   48]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos que onda\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distancia entre primer y ultimo dia de entrada al sitio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>distan_dias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008ed71</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091926</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00091a7a</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000ba417</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000c79fe</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  distan_dias\n",
       "0  0008ed71            0\n",
       "1  00091926           27\n",
       "2  00091a7a            0\n",
       "3  000ba417            9\n",
       "4  000c79fe            0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamp_df = df[[\"person\", \"timestamp\"]]\n",
    "ultimo_dia = timestamp_df.groupby(\"person\")[\"timestamp\"].max().rename(\"ultimo\").reset_index()\n",
    "primer_dia = timestamp_df.groupby(\"person\")[\"timestamp\"].min().rename(\"primer\").reset_index()\n",
    "distancia_dias = pd.merge(primer_dia, ultimo_dia, on=\"person\", how=\"inner\")\n",
    "distancia_dias[\"distan_dias\"] = (distancia_dias[\"ultimo\"] - distancia_dias[\"primer\"]).dt.days\n",
    "distancia_dias = distancia_dias[[\"person\", \"distan_dias\"]]\n",
    "distancia_dias.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>distan_dias</th>\n",
       "      <th>cant_city</th>\n",
       "      <th>cant_src</th>\n",
       "      <th>cant_eng</th>\n",
       "      <th>cant_mod</th>\n",
       "      <th>cant_ev</th>\n",
       "      <th>check_tot</th>\n",
       "      <th>cant_entradas</th>\n",
       "      <th>cant_mes_5</th>\n",
       "      <th>entradas_30_dias</th>\n",
       "      <th>cant_mes</th>\n",
       "      <th>cant_dia_freq</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>114</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>63</td>\n",
       "      <td>189</td>\n",
       "      <td>15</td>\n",
       "      <td>471</td>\n",
       "      <td>290</td>\n",
       "      <td>358</td>\n",
       "      <td>290</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>54</td>\n",
       "      <td>64</td>\n",
       "      <td>54</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>54</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>46</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>26</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   distan_dias  cant_city  cant_src  cant_eng  cant_mod  cant_ev  check_tot  \\\n",
       "0            0          1         1         1         4        9          1   \n",
       "1          114         12        17        12        63      189         15   \n",
       "2           79          8         4         6        20       52          1   \n",
       "3           67          5        10        10         8       17          3   \n",
       "4           62          2         2         1         3       17          1   \n",
       "\n",
       "   cant_entradas  cant_mes_5  entradas_30_dias  cant_mes  cant_dia_freq  label  \n",
       "0             17          17                16        17             17      0  \n",
       "1            471         290               358       290             72      0  \n",
       "2             96          54                64        54             17      0  \n",
       "3             54           5                26        46             22      0  \n",
       "4             38          26                25        26             26      0  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge\n",
    "\n",
    "df_con_distancias = pd.merge(distancia_dias, df_final, on=\"person\", how=\"inner\") \n",
    "df_con_distancias_num = df_con_distancias.drop(columns=\"person\")\n",
    "df_con_distancias_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veo cuantas personas a predecir pierdo\n",
    "distancia_dias_predecir = pd.merge(distancia_dias, df_persons, on=\"person\", how=\"inner\")\n",
    "distancia_dias_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = df_con_distancias_num.iloc[:,:-1], df_con_distancias_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y)\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, scale_pos_weight = 1, min_child_weight=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=6,\n",
       "       n_jobs=1, nthread=None, objective='binary:hinge', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.9115798295851376\n",
      "Test acuracy:  0.9067039106145252\n",
      "ROC auc score:  0.59551431955538\n",
      "Confusion matrix: \n",
      "[[1608  125]\n",
      " [  42   15]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos que onda\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cantidad de modelos distintos vistos por cada usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>modelos_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008ed71</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091926</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00091a7a</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000ba417</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000c79fe</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  modelos_dist\n",
       "0  0008ed71             3\n",
       "1  00091926            36\n",
       "2  00091a7a             3\n",
       "3  000ba417            26\n",
       "4  000c79fe             1"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelos_df = df[[\"person\", \"model\"]]\n",
    "cant_modelos = modelos_df.groupby(\"person\")[\"model\"].nunique().rename(\"modelos_dist\").reset_index()\n",
    "cant_modelos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelos_dist</th>\n",
       "      <th>distan_dias</th>\n",
       "      <th>cant_city</th>\n",
       "      <th>cant_src</th>\n",
       "      <th>cant_eng</th>\n",
       "      <th>cant_mod</th>\n",
       "      <th>cant_ev</th>\n",
       "      <th>check_tot</th>\n",
       "      <th>cant_entradas</th>\n",
       "      <th>cant_mes_5</th>\n",
       "      <th>entradas_30_dias</th>\n",
       "      <th>cant_mes</th>\n",
       "      <th>cant_dia_freq</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26</td>\n",
       "      <td>114</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>63</td>\n",
       "      <td>189</td>\n",
       "      <td>15</td>\n",
       "      <td>471</td>\n",
       "      <td>290</td>\n",
       "      <td>358</td>\n",
       "      <td>290</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6</td>\n",
       "      <td>79</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>54</td>\n",
       "      <td>64</td>\n",
       "      <td>54</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>67</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>54</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>46</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>62</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>26</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   modelos_dist  distan_dias  cant_city  cant_src  cant_eng  cant_mod  \\\n",
       "0             1            0          1         1         1         4   \n",
       "1            26          114         12        17        12        63   \n",
       "2             6           79          8         4         6        20   \n",
       "3             6           67          5        10        10         8   \n",
       "4             9           62          2         2         1         3   \n",
       "\n",
       "   cant_ev  check_tot  cant_entradas  cant_mes_5  entradas_30_dias  cant_mes  \\\n",
       "0        9          1             17          17                16        17   \n",
       "1      189         15            471         290               358       290   \n",
       "2       52          1             96          54                64        54   \n",
       "3       17          3             54           5                26        46   \n",
       "4       17          1             38          26                25        26   \n",
       "\n",
       "   cant_dia_freq  label  \n",
       "0             17      0  \n",
       "1             72      0  \n",
       "2             17      0  \n",
       "3             22      0  \n",
       "4             26      0  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge \n",
    "\n",
    "df_con_modelos = pd.merge(cant_modelos, df_con_distancias, on=\"person\", how=\"inner\")\n",
    "df_con_modelos_num = df_con_modelos.drop(columns=\"person\")\n",
    "df_con_modelos_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veo cuantas personas a predecir pierdo\n",
    "cant_modelos_predecir = pd.merge(cant_modelos, df_persons, on=\"person\", how=\"inner\")\n",
    "cant_modelos_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = df_con_modelos_num.iloc[:,:-1], df_con_modelos_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y)\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, scale_pos_weight = 1, min_child_weight=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=6,\n",
       "       n_jobs=1, nthread=None, objective='binary:hinge', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8923033943288169\n",
      "Test acuracy:  0.8759776536312849\n",
      "ROC auc score:  0.5881292961196991\n",
      "Confusion matrix: \n",
      "[[1552  181]\n",
      " [  41   16]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos que onda\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cantidad de das distintos de entrada al sitio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seba\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>cant_dias_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008ed71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091926</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00091a7a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000ba417</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000c79fe</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  cant_dias_dist\n",
       "0  0008ed71               1\n",
       "1  00091926              22\n",
       "2  00091a7a               1\n",
       "3  000ba417               3\n",
       "4  000c79fe               1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dias = df[[\"person\", \"timestamp\"]]\n",
    "df_dias[\"day_of_year\"] = df_dias[\"timestamp\"].dt.dayofyear\n",
    "cant_dias_dist = df_dias.groupby(\"person\")[\"day_of_year\"].nunique().rename(\"cant_dias_dist\").reset_index()\n",
    "cant_dias_dist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cant_dias_dist</th>\n",
       "      <th>distan_dias</th>\n",
       "      <th>cant_city</th>\n",
       "      <th>cant_src</th>\n",
       "      <th>cant_eng</th>\n",
       "      <th>cant_mod</th>\n",
       "      <th>cant_ev</th>\n",
       "      <th>check_tot</th>\n",
       "      <th>cant_entradas</th>\n",
       "      <th>cant_mes_5</th>\n",
       "      <th>entradas_30_dias</th>\n",
       "      <th>cant_mes</th>\n",
       "      <th>cant_dia_freq</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>114</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>63</td>\n",
       "      <td>189</td>\n",
       "      <td>15</td>\n",
       "      <td>471</td>\n",
       "      <td>290</td>\n",
       "      <td>358</td>\n",
       "      <td>290</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>79</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>54</td>\n",
       "      <td>64</td>\n",
       "      <td>54</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>67</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>54</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>46</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>62</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>26</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   cant_dias_dist  distan_dias  cant_city  cant_src  cant_eng  cant_mod  \\\n",
       "0               1            0          1         1         1         4   \n",
       "1              14          114         12        17        12        63   \n",
       "2              11           79          8         4         6        20   \n",
       "3               6           67          5        10        10         8   \n",
       "4               2           62          2         2         1         3   \n",
       "\n",
       "   cant_ev  check_tot  cant_entradas  cant_mes_5  entradas_30_dias  cant_mes  \\\n",
       "0        9          1             17          17                16        17   \n",
       "1      189         15            471         290               358       290   \n",
       "2       52          1             96          54                64        54   \n",
       "3       17          3             54           5                26        46   \n",
       "4       17          1             38          26                25        26   \n",
       "\n",
       "   cant_dia_freq  label  \n",
       "0             17      0  \n",
       "1             72      0  \n",
       "2             17      0  \n",
       "3             22      0  \n",
       "4             26      0  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge \n",
    "\n",
    "df_con_dias_dist = pd.merge(cant_dias_dist, df_con_modelos, on=\"person\", how=\"inner\")\n",
    "df_con_dias_dist_num = df_con_dias_dist.drop(columns=[\"person\", \"modelos_dist\"])\n",
    "df_con_dias_dist_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veo cuantas personas a predecir pierdo\n",
    "cant_dias_dist_predecir = pd.merge(cant_dias_dist, df_persons, on=\"person\", how=\"inner\")\n",
    "cant_dias_dist_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = df_con_dias_dist_num.iloc[:,:-1], df_con_dias_dist_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y)\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, scale_pos_weight = 1, min_child_weight=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=6,\n",
       "       n_jobs=1, nthread=None, objective='binary:hinge', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8868557061042045\n",
      "Test acuracy:  0.8698324022346369\n",
      "ROC auc score:  0.6104058472783227\n",
      "Confusion matrix: \n",
      "[[1538  195]\n",
      " [  38   19]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos que onda\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Promedio de entradas por dia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seba\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>cant_entradas</th>\n",
       "      <th>cant_dias_dist</th>\n",
       "      <th>promedio_por_dia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008ed71</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091926</td>\n",
       "      <td>448</td>\n",
       "      <td>22</td>\n",
       "      <td>0.049107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00091a7a</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000ba417</td>\n",
       "      <td>206</td>\n",
       "      <td>3</td>\n",
       "      <td>0.014563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000c79fe</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0.058824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  cant_entradas  cant_dias_dist  promedio_por_dia\n",
       "0  0008ed71              6               1          0.166667\n",
       "1  00091926            448              22          0.049107\n",
       "2  00091a7a             10               1          0.100000\n",
       "3  000ba417            206               3          0.014563\n",
       "4  000c79fe             17               1          0.058824"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entradas_tot = df.groupby(\"person\").agg({\"person\": \"count\"})\n",
    "#cant_entradas_tot = entradas_tot[[\"person\", \"entradas_tot\"]]\n",
    "entradas_tot.columns = [\"cant_entradas\"]\n",
    "entradas_tot.reset_index(inplace=True)\n",
    "\n",
    "df_dias = df[[\"person\", \"timestamp\"]]\n",
    "df_dias[\"day_of_year\"] = df_dias[\"timestamp\"].dt.dayofyear\n",
    "cant_dias_dist = df_dias.groupby(\"person\")[\"day_of_year\"].nunique().rename(\"cant_dias_dist\").reset_index()\n",
    "\n",
    "entradas_tot_y_dias = pd.merge(entradas_tot, cant_dias_dist, on=\"person\", how=\"inner\")\n",
    "entradas_tot_y_dias[\"promedio_por_dia\"] = (entradas_tot_y_dias[\"cant_dias_dist\"] / entradas_tot_y_dias[\"cant_entradas\"])\n",
    "entradas_tot_y_dias.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "entradas_tot_y_dias = entradas_tot_y_dias[[\"person\", \"promedio_por_dia\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veo cuantas personas a predecir pierdo\n",
    "entradas_tot_y_dias_predecir = pd.merge(entradas_tot_y_dias, df_persons, on=\"person\", how=\"inner\")\n",
    "entradas_tot_y_dias_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Promedio de entradas por mes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 952,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>promedio_por_mes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008ed71</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091926</td>\n",
       "      <td>0.002232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00091a7a</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000ba417</td>\n",
       "      <td>0.004854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000c79fe</td>\n",
       "      <td>0.058824</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  promedio_por_mes\n",
       "0  0008ed71          0.166667\n",
       "1  00091926          0.002232\n",
       "2  00091a7a          0.100000\n",
       "3  000ba417          0.004854\n",
       "4  000c79fe          0.058824"
      ]
     },
     "execution_count": 952,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mes = df[[\"person\", \"month\"]]\n",
    "cant_meses_dist = df_mes.groupby(\"person\")[\"month\"].nunique().rename(\"cant_meses_dist\").reset_index()\n",
    "\n",
    "entradas_tot_y_meses = pd.merge(entradas_tot, cant_meses_dist, on=\"person\", how=\"inner\")\n",
    "entradas_tot_y_meses[\"promedio_por_mes\"] = (entradas_tot_y_meses[\"cant_meses_dist\"] / entradas_tot_y_meses[\"cant_entradas\"])\n",
    "entradas_tot_y_meses = entradas_tot_y_meses[[\"person\", \"promedio_por_mes\"]]\n",
    "\n",
    "entradas_tot_y_meses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 953,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>promedio_por_mes</th>\n",
       "      <th>promedio_por_dia</th>\n",
       "      <th>cant_dias_dist</th>\n",
       "      <th>modelos_dist</th>\n",
       "      <th>distan_dias</th>\n",
       "      <th>cant_city</th>\n",
       "      <th>cant_src</th>\n",
       "      <th>cant_eng</th>\n",
       "      <th>cant_mod</th>\n",
       "      <th>cant_ev</th>\n",
       "      <th>check_tot</th>\n",
       "      <th>cant_entradas</th>\n",
       "      <th>cant_mes_5</th>\n",
       "      <th>entradas_30_dias</th>\n",
       "      <th>cant_mes</th>\n",
       "      <th>cant_dia_freq</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.008493</td>\n",
       "      <td>0.029724</td>\n",
       "      <td>14</td>\n",
       "      <td>26</td>\n",
       "      <td>114</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>63</td>\n",
       "      <td>189</td>\n",
       "      <td>15</td>\n",
       "      <td>471</td>\n",
       "      <td>290</td>\n",
       "      <td>358</td>\n",
       "      <td>290</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.114583</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>79</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>54</td>\n",
       "      <td>64</td>\n",
       "      <td>54</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>67</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>54</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>46</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>62</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>26</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   promedio_por_mes  promedio_por_dia  cant_dias_dist  modelos_dist  \\\n",
       "0          0.058824          0.058824               1             1   \n",
       "1          0.008493          0.029724              14            26   \n",
       "2          0.031250          0.114583              11             6   \n",
       "3          0.055556          0.111111               6             6   \n",
       "4          0.052632          0.052632               2             9   \n",
       "\n",
       "   distan_dias  cant_city  cant_src  cant_eng  cant_mod  cant_ev  check_tot  \\\n",
       "0            0          1         1         1         4        9          1   \n",
       "1          114         12        17        12        63      189         15   \n",
       "2           79          8         4         6        20       52          1   \n",
       "3           67          5        10        10         8       17          3   \n",
       "4           62          2         2         1         3       17          1   \n",
       "\n",
       "   cant_entradas  cant_mes_5  entradas_30_dias  cant_mes  cant_dia_freq  label  \n",
       "0             17          17                16        17             17      0  \n",
       "1            471         290               358       290             72      0  \n",
       "2             96          54                64        54             17      0  \n",
       "3             54           5                26        46             22      0  \n",
       "4             38          26                25        26             26      0  "
      ]
     },
     "execution_count": 953,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge\n",
    "\n",
    "labels_con_promedios = pd.merge(entradas_tot_y_meses, entradas_tot_y_dias, on=\"person\", how=\"inner\")\n",
    "labels_con_promedios = pd.merge(labels_con_promedios, df_con_dias_dist, on=\"person\", how=\"inner\")\n",
    "labels_con_promedios_num = labels_con_promedios.drop(columns=\"person\")\n",
    "labels_con_promedios_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 954,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 954,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veo cuantas personas a predecir pierdo\n",
    "entradas_tot_y_meses_predecir = pd.merge(entradas_tot_y_meses, df_persons, on=\"person\", how=\"inner\")\n",
    "entradas_tot_y_meses_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1036,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = labels_con_promedios_num.iloc[:,:-1], labels_con_promedios_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y, weight={1: 1, 0: 0.1})\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1037,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, eval_metric = \"auc\", min_child_weight=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1038,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=5, missing=None,\n",
       "       n_estimators=6, n_jobs=1, nthread=None, objective='binary:hinge',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 1038,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1039,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1040,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8833635982679146\n",
      "Test acuracy:  0.8804469273743016\n",
      "ROC auc score:  0.6328544963100191\n",
      "Confusion matrix: \n",
      "[[1555  178]\n",
      " [  36   21]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos \n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1041,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8833635982679146\n",
      "Test acuracy:  0.8804469273743016\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.90      0.94      1733\n",
      "           1       0.11      0.37      0.16        57\n",
      "\n",
      "   micro avg       0.88      0.88      0.88      1790\n",
      "   macro avg       0.54      0.63      0.55      1790\n",
      "weighted avg       0.95      0.88      0.91      1790\n",
      "\n",
      "\n",
      "Precision Score:  0.10552763819095477\n",
      "Recall Score:  0.3684210526315789\n",
      "F1 Score:  0.1640625\n",
      "Cohen Kappa Score:  0.12052236921254311\n",
      "ROC auc score:  0.6328544963100191\n",
      "Confusion matrix: \n",
      "[[1555  178]\n",
      " [  36   21]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\\\n",
    "                            f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "# Pruebo todas las metricas.\n",
    "# accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\n",
    "# f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "\n",
    "trainAccuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "testAccuracy = accuracy_score(y_test, preds)\n",
    "\n",
    "meanSquaredError = mean_squared_error(y_test, preds)\n",
    "classificationReport = classification_report(y_test, preds)\n",
    "precisionScore = precision_score(y_test, preds)\n",
    "recallScore = recall_score(y_test, preds)\n",
    "f1Score = f1_score(y_test, preds)\n",
    "cohenKappaScore = cohen_kappa_score(y_test, preds)\n",
    "areaDebajoDeCurva = roc_auc_score(y_test, preds)\n",
    "matrizDeConfusion = confusion_matrix(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", trainAccuracy)\n",
    "print(\"Test acuracy: \", testAccuracy)\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(classificationReport)\n",
    "print()\n",
    "print(\"Precision Score: \",precisionScore)\n",
    "print(\"Recall Score: \",recallScore)\n",
    "print(\"F1 Score: \",f1Score)\n",
    "print(\"Cohen Kappa Score: \",cohenKappaScore)\n",
    "print(\"ROC auc score: \", areaDebajoDeCurva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matrizDeConfusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Duplico los compradores (label = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = labels_con_promedios_num.iloc[:,:-1], labels_con_promedios_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "#data_dmatrix = xgb.DMatrix(data=X,label=y, weight={1: 1, 0: 0.1})\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplico los compradores\n",
    "\n",
    "y_train_df = y_train.to_frame()\n",
    "X_train_df = X_train.reset_index()\n",
    "train = pd.merge(X_train, y_train_df, how=\"inner\", left_index=True, right_index=True)\n",
    "train_compradores = train.loc[train[\"label\"] == 1]\n",
    "train_dup = pd.concat([train, train_compradores], ignore_index=True)\n",
    "X_train, y_train = train_dup.drop(columns=\"label\"), train_dup[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBClassifier(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, eval_metric = \"auc\", min_child_weight=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=1, missing=None,\n",
       "       n_estimators=6, n_jobs=1, nthread=None, objective='binary:hinge',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 1175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1177,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.681266846361186\n",
      "Test acuracy:  0.6849162011173184\n",
      "ROC auc score:  0.6676081432664177\n",
      "Confusion matrix: \n",
      "[[1189  544]\n",
      " [  20   37]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos \n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.681266846361186\n",
      "Test acuracy:  0.6849162011173184\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.69      0.81      1733\n",
      "           1       0.06      0.65      0.12        57\n",
      "\n",
      "   micro avg       0.68      0.68      0.68      1790\n",
      "   macro avg       0.52      0.67      0.46      1790\n",
      "weighted avg       0.95      0.68      0.79      1790\n",
      "\n",
      "\n",
      "Precision Score:  0.06368330464716007\n",
      "Recall Score:  0.6491228070175439\n",
      "F1 Score:  0.11598746081504703\n",
      "Cohen Kappa Score:  0.06156057059675446\n",
      "ROC auc score:  0.6676081432664177\n",
      "Confusion matrix: \n",
      "[[1189  544]\n",
      " [  20   37]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\\\n",
    "                            f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "# Pruebo todas las metricas.\n",
    "# accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\n",
    "# f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "\n",
    "trainAccuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "testAccuracy = accuracy_score(y_test, preds)\n",
    "\n",
    "meanSquaredError = mean_squared_error(y_test, preds)\n",
    "classificationReport = classification_report(y_test, preds)\n",
    "precisionScore = precision_score(y_test, preds)\n",
    "recallScore = recall_score(y_test, preds)\n",
    "f1Score = f1_score(y_test, preds)\n",
    "cohenKappaScore = cohen_kappa_score(y_test, preds)\n",
    "areaDebajoDeCurva = roc_auc_score(y_test, preds)\n",
    "matrizDeConfusion = confusion_matrix(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", trainAccuracy)\n",
    "print(\"Test acuracy: \", testAccuracy)\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(classificationReport)\n",
    "print()\n",
    "print(\"Precision Score: \",precisionScore)\n",
    "print(\"Recall Score: \",recallScore)\n",
    "print(\"F1 Score: \",f1Score)\n",
    "print(\"Cohen Kappa Score: \",cohenKappaScore)\n",
    "print(\"ROC auc score: \", areaDebajoDeCurva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matrizDeConfusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = labels_con_promedios_num.iloc[:,:-1], labels_con_promedios_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "#data_dmatrix = xgb.DMatrix(data=X,label=y, weight={1: 1, 0: 0.1})\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "sm = SMOTE(k_neighbors=90, sampling_strategy='minority')\n",
    "X_train_res, y_train_res = sm.fit_sample(X_train, y_train.ravel())\n",
    "X_train_res_df = pd.DataFrame(X_train_res)\n",
    "X_train_res_df.columns = X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1146,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBClassifier(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, eval_metric = \"auc\", min_child_weight=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=1, missing=None,\n",
       "       n_estimators=6, n_jobs=1, nthread=None, objective='binary:hinge',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 1147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train_res_df ,y_train_res.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1148,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.6190924905769788\n",
      "Test acuracy:  0.25977653631284914\n",
      "ROC auc score:  0.6007481195776515\n",
      "Confusion matrix: \n",
      "[[ 410 1323]\n",
      " [   2   55]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos \n",
    "train_accuracy = accuracy_score(y_train_res, xg_reg.predict(X_train_res_df))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1150,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.6190924905769788\n",
      "Test acuracy:  0.25977653631284914\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.24      0.38      1733\n",
      "           1       0.04      0.96      0.08        57\n",
      "\n",
      "   micro avg       0.26      0.26      0.26      1790\n",
      "   macro avg       0.52      0.60      0.23      1790\n",
      "weighted avg       0.96      0.26      0.37      1790\n",
      "\n",
      "\n",
      "Precision Score:  0.03991291727140784\n",
      "Recall Score:  0.9649122807017544\n",
      "F1 Score:  0.07665505226480837\n",
      "Cohen Kappa Score:  0.016507170882889777\n",
      "ROC auc score:  0.6007481195776515\n",
      "Confusion matrix: \n",
      "[[ 410 1323]\n",
      " [   2   55]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\\\n",
    "                            f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "# Pruebo todas las metricas.\n",
    "# accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\n",
    "# f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "\n",
    "trainAccuracy = accuracy_score(y_train_res, xg_reg.predict(X_train_res_df))\n",
    "testAccuracy = accuracy_score(y_test, preds)\n",
    "\n",
    "meanSquaredError = mean_squared_error(y_test, preds)\n",
    "classificationReport = classification_report(y_test, preds)\n",
    "precisionScore = precision_score(y_test, preds)\n",
    "recallScore = recall_score(y_test, preds)\n",
    "f1Score = f1_score(y_test, preds)\n",
    "cohenKappaScore = cohen_kappa_score(y_test, preds)\n",
    "areaDebajoDeCurva = roc_auc_score(y_test, preds)\n",
    "matrizDeConfusion = confusion_matrix(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", trainAccuracy)\n",
    "print(\"Test acuracy: \", testAccuracy)\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(classificationReport)\n",
    "print()\n",
    "print(\"Precision Score: \",precisionScore)\n",
    "print(\"Recall Score: \",recallScore)\n",
    "print(\"F1 Score: \",f1Score)\n",
    "print(\"Cohen Kappa Score: \",cohenKappaScore)\n",
    "print(\"ROC auc score: \", areaDebajoDeCurva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matrizDeConfusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = labels_con_promedios_num.iloc[:,:-1], labels_con_promedios_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "#data_dmatrix = xgb.DMatrix(data=X,label=y, weight={1: 1, 0: 0.1})\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(random_state=2)\n",
    "X_train_res, y_train_res = ros.fit_sample(X, y)\n",
    "X_train_res_df = pd.DataFrame(X_train_res)\n",
    "X_train_res_df.columns = X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBClassifier(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, eval_metric = \"auc\", min_child_weight=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=1, missing=None,\n",
       "       n_estimators=6, n_jobs=1, nthread=None, objective='binary:hinge',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 1161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train_res_df ,y_train_res.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.5532962576758197\n",
      "Test acuracy:  0.13072625698324022\n",
      "ROC auc score:  0.5510675129832661\n",
      "Confusion matrix: \n",
      "[[ 177 1556]\n",
      " [   0   57]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos \n",
    "train_accuracy = accuracy_score(y_train_res, xg_reg.predict(X_train_res_df))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1158,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.5074730622175878\n",
      "Test acuracy:  0.04860335195530726\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.02      0.03      1733\n",
      "           1       0.03      1.00      0.06        57\n",
      "\n",
      "   micro avg       0.05      0.05      0.05      1790\n",
      "   macro avg       0.52      0.51      0.05      1790\n",
      "weighted avg       0.97      0.05      0.03      1790\n",
      "\n",
      "\n",
      "Precision Score:  0.03238636363636364\n",
      "Recall Score:  1.0\n",
      "F1 Score:  0.06274078150798018\n",
      "Cohen Kappa Score:  0.0011206537802405103\n",
      "ROC auc score:  0.5086555106751298\n",
      "Confusion matrix: \n",
      "[[  30 1703]\n",
      " [   0   57]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\\\n",
    "                            f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "# Pruebo todas las metricas.\n",
    "# accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\n",
    "# f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "\n",
    "trainAccuracy = accuracy_score(y_train_res, xg_reg.predict(X_train_res_df))\n",
    "testAccuracy = accuracy_score(y_test, preds)\n",
    "\n",
    "meanSquaredError = mean_squared_error(y_test, preds)\n",
    "classificationReport = classification_report(y_test, preds)\n",
    "precisionScore = precision_score(y_test, preds)\n",
    "recallScore = recall_score(y_test, preds)\n",
    "f1Score = f1_score(y_test, preds)\n",
    "cohenKappaScore = cohen_kappa_score(y_test, preds)\n",
    "areaDebajoDeCurva = roc_auc_score(y_test, preds)\n",
    "matrizDeConfusion = confusion_matrix(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", trainAccuracy)\n",
    "print(\"Test acuracy: \", testAccuracy)\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(classificationReport)\n",
    "print()\n",
    "print(\"Precision Score: \",precisionScore)\n",
    "print(\"Recall Score: \",recallScore)\n",
    "print(\"F1 Score: \",f1Score)\n",
    "print(\"Cohen Kappa Score: \",cohenKappaScore)\n",
    "print(\"ROC auc score: \", areaDebajoDeCurva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matrizDeConfusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = labels_con_promedios_num.iloc[:,:-1], labels_con_promedios_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "#data_dmatrix = xgb.DMatrix(data=X,label=y, weight={1: 1, 0: 0.1})\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1166,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "ros = RandomUnderSampler(random_state=2)\n",
    "X_train_res, y_train_res = ros.fit_sample(X, y)\n",
    "X_train_res_df = pd.DataFrame(X_train_res)\n",
    "X_train_res_df.columns = X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1167,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBClassifier(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, eval_metric = \"auc\", min_child_weight=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=1, missing=None,\n",
       "       n_estimators=6, n_jobs=1, nthread=None, objective='binary:hinge',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 1168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train_res_df ,y_train_res.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1170,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.5424528301886793\n",
      "Test acuracy:  0.08659217877094973\n",
      "ROC auc score:  0.5282746682054241\n",
      "Confusion matrix: \n",
      "[[  98 1635]\n",
      " [   0   57]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos \n",
    "train_accuracy = accuracy_score(y_train_res, xg_reg.predict(X_train_res_df))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1171,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.5424528301886793\n",
      "Test acuracy:  0.08659217877094973\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.06      0.11      1733\n",
      "           1       0.03      1.00      0.07        57\n",
      "\n",
      "   micro avg       0.09      0.09      0.09      1790\n",
      "   macro avg       0.52      0.53      0.09      1790\n",
      "weighted avg       0.97      0.09      0.11      1790\n",
      "\n",
      "\n",
      "Precision Score:  0.03368794326241135\n",
      "Recall Score:  1.0\n",
      "F1 Score:  0.06518010291595197\n",
      "Cohen Kappa Score:  0.0038028171890603923\n",
      "ROC auc score:  0.5282746682054241\n",
      "Confusion matrix: \n",
      "[[  98 1635]\n",
      " [   0   57]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\\\n",
    "                            f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "# Pruebo todas las metricas.\n",
    "# accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\n",
    "# f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "\n",
    "trainAccuracy = accuracy_score(y_train_res, xg_reg.predict(X_train_res_df))\n",
    "testAccuracy = accuracy_score(y_test, preds)\n",
    "\n",
    "meanSquaredError = mean_squared_error(y_test, preds)\n",
    "classificationReport = classification_report(y_test, preds)\n",
    "precisionScore = precision_score(y_test, preds)\n",
    "recallScore = recall_score(y_test, preds)\n",
    "f1Score = f1_score(y_test, preds)\n",
    "cohenKappaScore = cohen_kappa_score(y_test, preds)\n",
    "areaDebajoDeCurva = roc_auc_score(y_test, preds)\n",
    "matrizDeConfusion = confusion_matrix(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", trainAccuracy)\n",
    "print(\"Test acuracy: \", testAccuracy)\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(classificationReport)\n",
    "print()\n",
    "print(\"Precision Score: \",precisionScore)\n",
    "print(\"Recall Score: \",recallScore)\n",
    "print(\"F1 Score: \",f1Score)\n",
    "print(\"Cohen Kappa Score: \",cohenKappaScore)\n",
    "print(\"ROC auc score: \", areaDebajoDeCurva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matrizDeConfusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cantidad de eventos particulares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ad campaign hit</th>\n",
       "      <th>search engine hit</th>\n",
       "      <th>promedio_por_mes</th>\n",
       "      <th>promedio_por_dia</th>\n",
       "      <th>cant_dias_dist</th>\n",
       "      <th>modelos_dist</th>\n",
       "      <th>distan_dias</th>\n",
       "      <th>cant_city</th>\n",
       "      <th>cant_src</th>\n",
       "      <th>cant_eng</th>\n",
       "      <th>cant_mod</th>\n",
       "      <th>cant_ev</th>\n",
       "      <th>check_tot</th>\n",
       "      <th>cant_entradas</th>\n",
       "      <th>cant_mes_5</th>\n",
       "      <th>entradas_30_dias</th>\n",
       "      <th>cant_mes</th>\n",
       "      <th>cant_dia_freq</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>29.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.008493</td>\n",
       "      <td>0.029724</td>\n",
       "      <td>14</td>\n",
       "      <td>26</td>\n",
       "      <td>114</td>\n",
       "      <td>12</td>\n",
       "      <td>17</td>\n",
       "      <td>12</td>\n",
       "      <td>63</td>\n",
       "      <td>189</td>\n",
       "      <td>15</td>\n",
       "      <td>471</td>\n",
       "      <td>290</td>\n",
       "      <td>358</td>\n",
       "      <td>290</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.031250</td>\n",
       "      <td>0.114583</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>79</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>54</td>\n",
       "      <td>64</td>\n",
       "      <td>54</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>67</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>54</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>46</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>62</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>26</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ad campaign hit  search engine hit  promedio_por_mes  promedio_por_dia  \\\n",
       "0              1.0                1.0          0.058824          0.058824   \n",
       "1             29.0               13.0          0.008493          0.029724   \n",
       "2              7.0                6.0          0.031250          0.114583   \n",
       "3             13.0               10.0          0.055556          0.111111   \n",
       "4              2.0                1.0          0.052632          0.052632   \n",
       "\n",
       "   cant_dias_dist  modelos_dist  distan_dias  cant_city  cant_src  cant_eng  \\\n",
       "0               1             1            0          1         1         1   \n",
       "1              14            26          114         12        17        12   \n",
       "2              11             6           79          8         4         6   \n",
       "3               6             6           67          5        10        10   \n",
       "4               2             9           62          2         2         1   \n",
       "\n",
       "   cant_mod  cant_ev  check_tot  cant_entradas  cant_mes_5  entradas_30_dias  \\\n",
       "0         4        9          1             17          17                16   \n",
       "1        63      189         15            471         290               358   \n",
       "2        20       52          1             96          54                64   \n",
       "3         8       17          3             54           5                26   \n",
       "4         3       17          1             38          26                25   \n",
       "\n",
       "   cant_mes  cant_dia_freq  label  \n",
       "0        17             17      0  \n",
       "1       290             72      0  \n",
       "2        54             17      0  \n",
       "3        46             22      0  \n",
       "4        26             26      0  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_events = df[[\"person\", \"event\"]]\n",
    "cant_por_evento = pd.concat([pd.get_dummies(df_events['event']),df_events[['person']]],axis = 1).groupby('person')\\\n",
    "    .sum().reset_index()\n",
    "cant_por_evento_short = cant_por_evento[[\"person\", \"ad campaign hit\", \"search engine hit\"]]\n",
    "\n",
    "# Merge ... \"search engine hit\", \"generic listing\", \"searched products\" \"ad campaign hit\", \"brand listing\"\n",
    "\n",
    "labels_con_eventos = pd.merge(cant_por_evento_short, labels_con_promedios, on=\"person\", how=\"inner\")\n",
    "labels_con_eventos_num = labels_con_eventos.drop(columns=\"person\")\n",
    "labels_con_eventos_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veo cuantas personas a predecir pierdo\n",
    "cant_por_evento_short_predecir = pd.merge(cant_por_evento_short, df_persons, on=\"person\", how=\"inner\")\n",
    "cant_por_evento_short_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = labels_con_eventos_num.iloc[:,:-1], labels_con_eventos_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y, weight={1: 1, 0: 0.1})\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, eval_metric = \"auc\", min_child_weight=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=15, missing=None,\n",
       "       n_estimators=6, n_jobs=1, nthread=None, objective='binary:hinge',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 588,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8842017041486241\n",
      "Test acuracy:  0.8776536312849162\n",
      "ROC auc score:  0.6229284983954404\n",
      "Confusion matrix: \n",
      "[[1551  182]\n",
      " [  37   20]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos \n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visitas a productos segun condicion, color y almacenamiento de producto.\n",
    "copiado de santi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_events_visitas_prod = df.loc[df['event'] == 'viewed product']\n",
    "df_events_visitas_prod = df_events_visitas_prod[['person','storage','color','condition']]\n",
    "\n",
    "df_events_visitas_prod_condition_storage = pd.concat([df_events_visitas_prod['person'],\\\n",
    "           pd.get_dummies(df_events_visitas_prod['storage']),\\\n",
    "           pd.get_dummies(df_events_visitas_prod['condition'])],axis = 1).groupby('person').sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>128GB</th>\n",
       "      <th>16GB</th>\n",
       "      <th>256GB</th>\n",
       "      <th>32GB</th>\n",
       "      <th>4GB</th>\n",
       "      <th>512MB</th>\n",
       "      <th>64GB</th>\n",
       "      <th>8GB</th>\n",
       "      <th>Bom</th>\n",
       "      <th>...</th>\n",
       "      <th>Azul</th>\n",
       "      <th>Branco</th>\n",
       "      <th>Cinza espacial</th>\n",
       "      <th>Dourado</th>\n",
       "      <th>Ouro Rosa</th>\n",
       "      <th>Prata</th>\n",
       "      <th>Prateado</th>\n",
       "      <th>Preto</th>\n",
       "      <th>Preto Matte</th>\n",
       "      <th>Rosa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00091926</td>\n",
       "      <td>48.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091a7a</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000ba417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000c79fe</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000e4d9e</td>\n",
       "      <td>1.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>208.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  128GB   16GB  256GB   32GB  4GB  512MB  64GB   8GB    Bom  ...   \\\n",
       "0  00091926   48.0  104.0   10.0  132.0  0.0    0.0  78.0   0.0  102.0  ...    \n",
       "1  00091a7a    1.0    1.0    0.0    0.0  0.0    0.0   1.0   0.0    1.0  ...    \n",
       "2  000ba417    0.0  108.0    1.0   20.0  1.0    0.0   1.0  22.0  110.0  ...    \n",
       "3  000c79fe    3.0    0.0    0.0    0.0  0.0    0.0   0.0   0.0    3.0  ...    \n",
       "4  000e4d9e    1.0  108.0    1.0  208.0  0.0    0.0  21.0   0.0  124.0  ...    \n",
       "\n",
       "   Azul  Branco  Cinza espacial  Dourado  Ouro Rosa  Prata  Prateado  Preto  \\\n",
       "0   3.0     3.0            65.0    101.0       28.0    1.0      43.0   79.0   \n",
       "1   0.0     0.0             1.0      1.0        1.0    0.0       0.0    0.0   \n",
       "2   4.0    15.0             1.0     14.0        0.0    0.0       0.0   71.0   \n",
       "3   0.0     0.0             0.0      0.0        0.0    0.0       0.0    0.0   \n",
       "4  23.0    85.0            14.0     46.0        2.0    6.0       1.0  149.0   \n",
       "\n",
       "   Preto Matte  Rosa  \n",
       "0         29.0   3.0  \n",
       "1          0.0   0.0  \n",
       "2          0.0   7.0  \n",
       "3          3.0   0.0  \n",
       "4          0.0   9.0  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_10_colores = df_events_visitas_prod['color'].value_counts().head(10).index\n",
    "\n",
    "\n",
    "df_events_visitas_prod_color = df_events_visitas_prod.loc[df_events_visitas_prod['color'].isin(top_10_colores)]\n",
    "df_events_visitas_prod_color = pd.concat([df_events_visitas_prod_color['person'],\\\n",
    "                                          pd.get_dummies(df_events_visitas_prod_color['color'])],axis = 1)\n",
    "\n",
    "df_events_visitas_prod_color = df_events_visitas_prod_color.groupby('person').sum().reset_index()\n",
    "\n",
    "df_events_visitas_prod_color_storage_condition = pd.merge(df_events_visitas_prod_condition_storage,\\\n",
    "                        df_events_visitas_prod_color, on = 'person', how = 'inner')\n",
    "\n",
    "\n",
    "df_events_visitas_prod_color_storage_condition = pd.merge(df_events_visitas_prod_color_storage_condition, todas_las_personas, on=\"person\", how=\"right\").fillna(0)\n",
    "df_events_visitas_prod_color_storage_condition.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veo cuantas personas a predecir pierdo\n",
    "visitas_prod_color_storage_condition_predecir = pd.merge(df_events_visitas_prod_color_storage_condition, df_persons, on=\"person\", how=\"inner\")\n",
    "visitas_prod_color_storage_condition_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>128GB</th>\n",
       "      <th>16GB</th>\n",
       "      <th>256GB</th>\n",
       "      <th>32GB</th>\n",
       "      <th>4GB</th>\n",
       "      <th>512MB</th>\n",
       "      <th>64GB</th>\n",
       "      <th>8GB</th>\n",
       "      <th>Bom</th>\n",
       "      <th>Bom - Sem Touch ID</th>\n",
       "      <th>...</th>\n",
       "      <th>cant_eng</th>\n",
       "      <th>cant_mod</th>\n",
       "      <th>cant_ev</th>\n",
       "      <th>check_tot</th>\n",
       "      <th>cant_entradas</th>\n",
       "      <th>cant_mes_5</th>\n",
       "      <th>entradas_30_dias</th>\n",
       "      <th>cant_mes</th>\n",
       "      <th>cant_dia_freq</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>63</td>\n",
       "      <td>189</td>\n",
       "      <td>15</td>\n",
       "      <td>471</td>\n",
       "      <td>290</td>\n",
       "      <td>358</td>\n",
       "      <td>290</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>54</td>\n",
       "      <td>64</td>\n",
       "      <td>54</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>54</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>46</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>26</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   128GB  16GB  256GB  32GB  4GB  512MB  64GB   8GB    Bom  \\\n",
       "0    3.0   0.0    0.0   0.0  0.0    0.0   0.0   0.0    3.0   \n",
       "1    0.0  94.0    0.0  14.0  0.0    0.0   0.0  81.0  105.0   \n",
       "2    8.0  19.0    4.0  11.0  0.0    0.0  10.0   0.0    9.0   \n",
       "3    1.0   8.0    0.0   4.0  0.0    0.0   3.0   1.0    9.0   \n",
       "4    0.0   5.0    0.0   2.0  0.0    0.0   0.0   5.0   12.0   \n",
       "\n",
       "   Bom - Sem Touch ID  ...    cant_eng  cant_mod  cant_ev  check_tot  \\\n",
       "0                 0.0  ...           1         4        9          1   \n",
       "1                 0.0  ...          12        63      189         15   \n",
       "2                 0.0  ...           6        20       52          1   \n",
       "3                 5.0  ...          10         8       17          3   \n",
       "4                 0.0  ...           1         3       17          1   \n",
       "\n",
       "   cant_entradas  cant_mes_5  entradas_30_dias  cant_mes  cant_dia_freq  label  \n",
       "0             17          17                16        17             17      0  \n",
       "1            471         290               358       290             72      0  \n",
       "2             96          54                64        54             17      0  \n",
       "3             54           5                26        46             22      0  \n",
       "4             38          26                25        26             26      0  \n",
       "\n",
       "[5 rows x 42 columns]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge\n",
    "\n",
    "labels_con_storage_color = pd.merge(df_events_visitas_prod_color_storage_condition, labels_con_eventos, on=\"person\", how=\"inner\")\n",
    "labels_con_storage_color_num = labels_con_storage_color.drop(columns=\"person\")\n",
    "labels_con_storage_color_num.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 631,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = labels_con_storage_color_num.iloc[:,:-1], labels_con_storage_color_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y, weight={1: 1, 0: 0.1})\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 665,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, eval_metric = \"auc\", min_child_weight=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 666,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=15, missing=None,\n",
       "       n_estimators=6, n_jobs=1, nthread=None, objective='binary:hinge',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 666,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.9234529962285235\n",
      "Test acuracy:  0.9067039106145252\n",
      "ROC auc score:  0.5351895357171299\n",
      "Confusion matrix: \n",
      "[[1615  117]\n",
      " [  50    8]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos \n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entro como 'new' en el mes 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>is_new</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4886f805</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d6288188</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4858040e</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a6538d3e</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b884c881</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  is_new\n",
       "0  4886f805     0.0\n",
       "1  d6288188     0.0\n",
       "2  4858040e     0.0\n",
       "3  a6538d3e     0.0\n",
       "4  b884c881     0.0"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mes_5 = df[[\"person\", \"month\", \"new_vs_returning\"]].loc[df[\"month\"] == 5]\n",
    "df_mes_5[\"is_new\"] = (df_mes_5[\"new_vs_returning\"] == \"New\") * 1\n",
    "df_mew_5 = df_mes_5[[\"person\", \"is_new\"]]\n",
    "df_mew_5 = df_mew_5.sort_values(\"is_new\", ascending=True)\n",
    "df_mew_5 = df_mew_5.drop_duplicates(subset=['person'])\n",
    "df_mew_5 = pd.merge(df_mew_5, todas_las_personas, on=\"person\", how=\"right\").fillna(0)\n",
    "df_mew_5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veo cuantas personas a predecir pierdo\n",
    "df_mew_5_predecir = pd.merge(df_mew_5, df_persons, on=\"person\", how=\"inner\")\n",
    "df_mew_5_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge\n",
    "\n",
    "labels_con_new_mes5 = pd.merge(df_mew_5, labels_con_storage_color, on=\"person\", how=\"inner\")\n",
    "labels_con_new_mes5_num = labels_con_new_mes5.drop(columns=\"person\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = labels_con_new_mes5_num.iloc[:,:-1], labels_con_new_mes5_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y, weight={1: 1, 0: 0.1})\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 694,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, eval_metric = \"auc\", min_child_weight=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 695,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=4, missing=None,\n",
       "       n_estimators=6, n_jobs=1, nthread=None, objective='binary:hinge',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 695,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 697,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8963542394189132\n",
      "Test acuracy:  0.8698324022346369\n",
      "ROC auc score:  0.6033637873754153\n",
      "Confusion matrix: \n",
      "[[1535  185]\n",
      " [  48   22]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos \n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -- Agrego cosas de Santi --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cantidad de visitas a los 15 modelos mas visitados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ad93850f</td>\n",
       "      <td>iPhone 5s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0297fc1e</td>\n",
       "      <td>iPhone 6S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2d681dd8</td>\n",
       "      <td>iPhone 7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1b9f7cf6</td>\n",
       "      <td>iPhone 6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>29ebb414</td>\n",
       "      <td>iPhone 6 Plus</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person          model\n",
       "1  ad93850f      iPhone 5s\n",
       "2  0297fc1e      iPhone 6S\n",
       "3  2d681dd8       iPhone 7\n",
       "6  1b9f7cf6       iPhone 6\n",
       "7  29ebb414  iPhone 6 Plus"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_visitas_producto = df.loc[df['event'] == 'viewed product']\n",
    "top_15 = df_visitas_producto['model'].value_counts().head(15).index\n",
    "df_15_productos_mas_visitados = df_visitas_producto.loc[df_visitas_producto['model'].isin(top_15)]\n",
    "\n",
    "df_15_productos_mas_visitados = df_15_productos_mas_visitados[['person','model']]\n",
    "df_15_productos_mas_visitados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>Samsung Galaxy J5</th>\n",
       "      <th>Samsung Galaxy S6 Edge</th>\n",
       "      <th>Samsung Galaxy S6 Flat</th>\n",
       "      <th>Samsung Galaxy S7</th>\n",
       "      <th>Samsung Galaxy S7 Edge</th>\n",
       "      <th>Samsung Galaxy S8</th>\n",
       "      <th>iPhone 5c</th>\n",
       "      <th>iPhone 5s</th>\n",
       "      <th>iPhone 6</th>\n",
       "      <th>iPhone 6 Plus</th>\n",
       "      <th>iPhone 6S</th>\n",
       "      <th>iPhone 6S Plus</th>\n",
       "      <th>iPhone 7</th>\n",
       "      <th>iPhone 7 Plus</th>\n",
       "      <th>iPhone SE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00091926</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091a7a</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000ba417</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000c79fe</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000e4d9e</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  Samsung Galaxy J5  Samsung Galaxy S6 Edge  \\\n",
       "0  00091926                1.0                     3.0   \n",
       "1  00091a7a                0.0                     0.0   \n",
       "2  000ba417               11.0                     0.0   \n",
       "3  000c79fe                0.0                     0.0   \n",
       "4  000e4d9e                1.0                     5.0   \n",
       "\n",
       "   Samsung Galaxy S6 Flat  Samsung Galaxy S7  Samsung Galaxy S7 Edge  \\\n",
       "0                    15.0                1.0                     9.0   \n",
       "1                     0.0                0.0                     0.0   \n",
       "2                     1.0                0.0                     0.0   \n",
       "3                     0.0                0.0                     0.0   \n",
       "4                   139.0               22.0                     2.0   \n",
       "\n",
       "   Samsung Galaxy S8  iPhone 5c  iPhone 5s  iPhone 6  iPhone 6 Plus  \\\n",
       "0                5.0        0.0        0.0       5.0           41.0   \n",
       "1                0.0        0.0        0.0       1.0            0.0   \n",
       "2                0.0        6.0        1.0       0.0            0.0   \n",
       "3                0.0        0.0        0.0       0.0            0.0   \n",
       "4                9.0        0.0        7.0       0.0            0.0   \n",
       "\n",
       "   iPhone 6S  iPhone 6S Plus  iPhone 7  iPhone 7 Plus  iPhone SE  \n",
       "0       94.0            51.0      45.0            9.0        3.0  \n",
       "1        1.0             0.0       0.0            0.0        1.0  \n",
       "2        0.0             0.0       1.0            0.0        0.0  \n",
       "3        0.0             0.0       3.0            0.0        0.0  \n",
       "4        1.0             0.0       1.0            0.0       11.0  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_15_productos_mas_visitados = pd.concat([df_15_productos_mas_visitados,\\\n",
    "                    pd.get_dummies(df_15_productos_mas_visitados['model'])],axis = 1)\n",
    "\n",
    "df_15_productos_mas_visitados = df_15_productos_mas_visitados.groupby('person').sum().reset_index()\n",
    "df_15_productos_mas_visitados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>vis_vis_Samsung Galaxy J5</th>\n",
       "      <th>vis_vis_Samsung Galaxy S6 Edge</th>\n",
       "      <th>vis_vis_Samsung Galaxy S6 Flat</th>\n",
       "      <th>vis_vis_Samsung Galaxy S7</th>\n",
       "      <th>vis_vis_Samsung Galaxy S7 Edge</th>\n",
       "      <th>vis_vis_Samsung Galaxy S8</th>\n",
       "      <th>vis_vis_iPhone 5c</th>\n",
       "      <th>vis_vis_iPhone 5s</th>\n",
       "      <th>vis_vis_iPhone 6</th>\n",
       "      <th>vis_vis_iPhone 6 Plus</th>\n",
       "      <th>vis_vis_iPhone 6S</th>\n",
       "      <th>vis_vis_iPhone 6S Plus</th>\n",
       "      <th>vis_vis_iPhone 7</th>\n",
       "      <th>vis_vis_iPhone 7 Plus</th>\n",
       "      <th>vis_vis_iPhone SE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00091926</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091a7a</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000ba417</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000c79fe</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000e4d9e</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  vis_vis_Samsung Galaxy J5  vis_vis_Samsung Galaxy S6 Edge  \\\n",
       "0  00091926                        1.0                             3.0   \n",
       "1  00091a7a                        0.0                             0.0   \n",
       "2  000ba417                       11.0                             0.0   \n",
       "3  000c79fe                        0.0                             0.0   \n",
       "4  000e4d9e                        1.0                             5.0   \n",
       "\n",
       "   vis_vis_Samsung Galaxy S6 Flat  vis_vis_Samsung Galaxy S7  \\\n",
       "0                            15.0                        1.0   \n",
       "1                             0.0                        0.0   \n",
       "2                             1.0                        0.0   \n",
       "3                             0.0                        0.0   \n",
       "4                           139.0                       22.0   \n",
       "\n",
       "   vis_vis_Samsung Galaxy S7 Edge  vis_vis_Samsung Galaxy S8  \\\n",
       "0                             9.0                        5.0   \n",
       "1                             0.0                        0.0   \n",
       "2                             0.0                        0.0   \n",
       "3                             0.0                        0.0   \n",
       "4                             2.0                        9.0   \n",
       "\n",
       "   vis_vis_iPhone 5c  vis_vis_iPhone 5s  vis_vis_iPhone 6  \\\n",
       "0                0.0                0.0               5.0   \n",
       "1                0.0                0.0               1.0   \n",
       "2                6.0                1.0               0.0   \n",
       "3                0.0                0.0               0.0   \n",
       "4                0.0                7.0               0.0   \n",
       "\n",
       "   vis_vis_iPhone 6 Plus  vis_vis_iPhone 6S  vis_vis_iPhone 6S Plus  \\\n",
       "0                   41.0               94.0                    51.0   \n",
       "1                    0.0                1.0                     0.0   \n",
       "2                    0.0                0.0                     0.0   \n",
       "3                    0.0                0.0                     0.0   \n",
       "4                    0.0                1.0                     0.0   \n",
       "\n",
       "   vis_vis_iPhone 7  vis_vis_iPhone 7 Plus  vis_vis_iPhone SE  \n",
       "0              45.0                    9.0                3.0  \n",
       "1               0.0                    0.0                1.0  \n",
       "2               1.0                    0.0                0.0  \n",
       "3               3.0                    0.0                0.0  \n",
       "4               1.0                    0.0               11.0  "
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vis = visitas\n",
    "nombres_columnas = ['vis_'+columna for columna in df_15_productos_mas_visitados.columns]\n",
    "nombres_columnas[0] = 'person'\n",
    "df_15_productos_mas_visitados.columns = nombres_columnas\n",
    "\n",
    "df_15_productos_mas_visitados = pd.merge(df_15_productos_mas_visitados, todas_las_personas, on=\"person\", how=\"right\").fillna(0)\n",
    "\n",
    "df_15_productos_mas_visitados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veo cuantas personas a predecir pierdo\n",
    "df_15_productos_mas_visitados_predecir = pd.merge(df_15_productos_mas_visitados, df_persons, on=\"person\", how=\"inner\")\n",
    "df_15_productos_mas_visitados_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 38829 entries, 0 to 38828\n",
      "Data columns (total 27 columns):\n",
      "person                            38829 non-null object\n",
      "vis_vis_Samsung Galaxy J5         38829 non-null float64\n",
      "vis_vis_Samsung Galaxy S6 Edge    38829 non-null float64\n",
      "vis_vis_Samsung Galaxy S6 Flat    38829 non-null float64\n",
      "vis_vis_Samsung Galaxy S7         38829 non-null float64\n",
      "vis_vis_Samsung Galaxy S7 Edge    38829 non-null float64\n",
      "vis_vis_Samsung Galaxy S8         38829 non-null float64\n",
      "vis_vis_iPhone 5c                 38829 non-null float64\n",
      "vis_vis_iPhone 5s                 38829 non-null float64\n",
      "vis_vis_iPhone 6                  38829 non-null float64\n",
      "vis_vis_iPhone 6 Plus             38829 non-null float64\n",
      "vis_vis_iPhone 6S                 38829 non-null float64\n",
      "vis_vis_iPhone 6S Plus            38829 non-null float64\n",
      "vis_vis_iPhone 7                  38829 non-null float64\n",
      "vis_vis_iPhone 7 Plus             38829 non-null float64\n",
      "vis_vis_iPhone SE                 38829 non-null float64\n",
      "ad campaign hit                   38829 non-null float64\n",
      "brand listing                     38829 non-null float64\n",
      "checkout                          38829 non-null float64\n",
      "conversion                        38829 non-null float64\n",
      "generic listing                   38829 non-null float64\n",
      "lead                              38829 non-null float64\n",
      "search engine hit                 38829 non-null float64\n",
      "searched products                 38829 non-null float64\n",
      "staticpage                        38829 non-null float64\n",
      "viewed product                    38829 non-null float64\n",
      "visited site                      38829 non-null float64\n",
      "dtypes: float64(26), object(1)\n",
      "memory usage: 8.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train_sin_labels = pd.merge(df_15_productos_mas_visitados,cant_por_evento,on = 'person',how = 'outer')\n",
    "\n",
    "df_train_sin_labels.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probar 2 alternativas\n",
    "df_train_sin_labels1 = df_train_sin_labels.dropna()\n",
    "df_train_sin_labels2 = df_train_sin_labels.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge\n",
    "\n",
    "labels_con_15_modelos = pd.merge(df_15_productos_mas_visitados, labels_con_new_mes5, on=\"person\", how=\"inner\")\n",
    "labels_con_15_modelos_num = labels_con_15_modelos.drop(columns=\"person\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 700,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = labels_con_15_modelos_num.iloc[:,:-1], labels_con_15_modelos_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y, weight={1: 1, 0: 0.1})\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 731,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, eval_metric = \"auc\", min_child_weight=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=10, missing=None,\n",
       "       n_estimators=6, n_jobs=1, nthread=None, objective='binary:hinge',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 732,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 733,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8914652884481072\n",
      "Test acuracy:  0.8787709497206704\n",
      "ROC auc score:  0.6136569380069524\n",
      "Confusion matrix: \n",
      "[[1552  174]\n",
      " [  43   21]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos \n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- Aca baj de 65 a 60!! ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estado(region) del usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Sao Paulo',\n",
       " 'Minas Gerais',\n",
       " 'Rio de Janeiro',\n",
       " 'Bahia',\n",
       " 'Pernambuco',\n",
       " 'Ceara',\n",
       " 'Parana',\n",
       " 'Rio Grande do Sul',\n",
       " 'Espirito Santo',\n",
       " 'Federal District',\n",
       " 'Maranhao',\n",
       " 'Goias',\n",
       " 'Santa Catarina',\n",
       " 'Para',\n",
       " 'Rio Grande do Norte',\n",
       " 'Paraba',\n",
       " 'Piaui',\n",
       " 'Alagoas',\n",
       " 'Sergipe',\n",
       " 'Amazonas']"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_20_estados = list(df['region'].value_counts().head(21).index)\n",
    "del top_20_estados[1]\n",
    "top_20_estados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2151588</th>\n",
       "      <td>0869b313</td>\n",
       "      <td>Pernambuco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150498</th>\n",
       "      <td>78561ee9</td>\n",
       "      <td>Sao Paulo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2294065</th>\n",
       "      <td>540e67b1</td>\n",
       "      <td>Pernambuco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2248029</th>\n",
       "      <td>041627fe</td>\n",
       "      <td>Federal District</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2151706</th>\n",
       "      <td>62acae45</td>\n",
       "      <td>Minas Gerais</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           person            region\n",
       "2151588  0869b313        Pernambuco\n",
       "2150498  78561ee9         Sao Paulo\n",
       "2294065  540e67b1        Pernambuco\n",
       "2248029  041627fe  Federal District\n",
       "2151706  62acae45      Minas Gerais"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_estado = df[['person','region','month']]\n",
    "df_estado = df_estado.sort_values('month',ascending = True).dropna()\n",
    "\n",
    "df_estado = df_estado.loc[df_estado['region'].isin(top_20_estados)]\n",
    "\n",
    "\n",
    "df_estado = df_estado.drop_duplicates(subset = 'person', keep = 'last').drop(columns = ['month'])\n",
    "\n",
    "df_estado.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROBAR 2 OPCIONES (LabelEncoder o con One hot encoding)\n",
    "from sklearn import preprocessing\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "df_estado1 = df_estado.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0869b313</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>78561ee9</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>540e67b1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>041627fe</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62acae45</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  region\n",
       "0  0869b313      12\n",
       "1  78561ee9      18\n",
       "2  540e67b1      12\n",
       "3  041627fe       5\n",
       "4  62acae45       8"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_estado1['region'] = le.fit_transform(df_estado1['region'])\n",
    "df_estado1 = pd.merge(df_estado1, todas_las_personas, on=\"person\", how=\"right\").fillna(0)\n",
    "\n",
    "df_estado1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>Alagoas</th>\n",
       "      <th>Amazonas</th>\n",
       "      <th>Bahia</th>\n",
       "      <th>Ceara</th>\n",
       "      <th>Espirito Santo</th>\n",
       "      <th>Federal District</th>\n",
       "      <th>Goias</th>\n",
       "      <th>Maranhao</th>\n",
       "      <th>Minas Gerais</th>\n",
       "      <th>...</th>\n",
       "      <th>Parana</th>\n",
       "      <th>Paraba</th>\n",
       "      <th>Pernambuco</th>\n",
       "      <th>Piaui</th>\n",
       "      <th>Rio Grande do Norte</th>\n",
       "      <th>Rio Grande do Sul</th>\n",
       "      <th>Rio de Janeiro</th>\n",
       "      <th>Santa Catarina</th>\n",
       "      <th>Sao Paulo</th>\n",
       "      <th>Sergipe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0869b313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>78561ee9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>540e67b1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>041627fe</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62acae45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  Alagoas  Amazonas  Bahia  Ceara  Espirito Santo  \\\n",
       "0  0869b313      0.0       0.0    0.0    0.0             0.0   \n",
       "1  78561ee9      0.0       0.0    0.0    0.0             0.0   \n",
       "2  540e67b1      0.0       0.0    0.0    0.0             0.0   \n",
       "3  041627fe      0.0       0.0    0.0    0.0             0.0   \n",
       "4  62acae45      0.0       0.0    0.0    0.0             0.0   \n",
       "\n",
       "   Federal District  Goias  Maranhao  Minas Gerais   ...     Parana  Paraba  \\\n",
       "0               0.0    0.0       0.0           0.0   ...        0.0      0.0   \n",
       "1               0.0    0.0       0.0           0.0   ...        0.0      0.0   \n",
       "2               0.0    0.0       0.0           0.0   ...        0.0      0.0   \n",
       "3               1.0    0.0       0.0           0.0   ...        0.0      0.0   \n",
       "4               0.0    0.0       0.0           1.0   ...        0.0      0.0   \n",
       "\n",
       "   Pernambuco  Piaui  Rio Grande do Norte  Rio Grande do Sul  Rio de Janeiro  \\\n",
       "0         1.0    0.0                  0.0                0.0             0.0   \n",
       "1         0.0    0.0                  0.0                0.0             0.0   \n",
       "2         1.0    0.0                  0.0                0.0             0.0   \n",
       "3         0.0    0.0                  0.0                0.0             0.0   \n",
       "4         0.0    0.0                  0.0                0.0             0.0   \n",
       "\n",
       "   Santa Catarina  Sao Paulo  Sergipe  \n",
       "0             0.0        0.0      0.0  \n",
       "1             0.0        1.0      0.0  \n",
       "2             0.0        0.0      0.0  \n",
       "3             0.0        0.0      0.0  \n",
       "4             0.0        0.0      0.0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_estado2 = 0\n",
    "df_estado2 = pd.concat([df_estado['person'],pd.get_dummies(df_estado['region'])],axis=1)\n",
    "df_estado2 = pd.merge(df_estado2, todas_las_personas, on=\"person\", how=\"right\").fillna(0)\n",
    "df_estado2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veo cuantas personas a predecir pierdo\n",
    "df_estado2_predecir = pd.merge(df_estado2, df_persons, on=\"person\", how=\"inner\")\n",
    "df_estado2_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veo cuantas personas a predecir pierdo\n",
    "df_estado1_predecir = pd.merge(df_estado1, df_persons, on=\"person\", how=\"inner\")\n",
    "df_estado1_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge\n",
    "\n",
    "labels_con_regiones = pd.merge(df_estado2, labels_con_15_modelos, on=\"person\", how=\"inner\")\n",
    "labels_con_regiones_num = labels_con_regiones.drop(columns=\"person\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = labels_con_regiones_num.iloc[:,:-1], labels_con_regiones_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y, weight={1: 1, 0: 0.1})\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, eval_metric = \"auc\", min_child_weight=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 741,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=1, missing=None,\n",
       "       n_estimators=6, n_jobs=1, nthread=None, objective='binary:hinge',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 741,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 743,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.9460818550076826\n",
      "Test acuracy:  0.9374301675977653\n",
      "ROC auc score:  0.5083471760797342\n",
      "Confusion matrix: \n",
      "[[1675   45]\n",
      " [  67    3]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos \n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " --- ?? aca se cag todo, paso a 0.5, wtf. Tanto con LE como con OHE ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cantidad de veces que accede desde cada dispositivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>Computer</th>\n",
       "      <th>Smartphone</th>\n",
       "      <th>Tablet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008ed71</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091926</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00091a7a</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000ba417</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000c79fe</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  Computer  Smartphone  Tablet\n",
       "0  0008ed71       2.0         0.0     0.0\n",
       "1  00091926      34.0         0.0     0.0\n",
       "2  00091a7a       0.0         1.0     0.0\n",
       "3  000ba417       6.0         0.0     0.0\n",
       "4  000c79fe       0.0         1.0     0.0"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_device = df.loc[df['event'] == 'visited site']\n",
    "\n",
    "df_device = df_device[['person','device_type']]\n",
    "\n",
    "df_device = pd.concat([df_device['person'],pd.get_dummies(df_device['device_type'])],axis = 1)\n",
    "\n",
    "df_device.drop(columns = ['Unknown'],inplace = True)\n",
    "\n",
    "df_device = df_device.groupby('person').sum().reset_index()\n",
    "\n",
    "df_device = pd.merge(df_device, todas_las_personas, on=\"person\", how=\"right\").fillna(0)\n",
    "\n",
    "\n",
    "df_device.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lo mismo se podria hacer pero considerando las visitas a producto desde cada movil.\n",
    "# Ver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veo cuantas personas a predecir pierdo\n",
    "df_device_predecir = pd.merge(df_device, df_persons, on=\"person\", how=\"inner\")\n",
    "df_device_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge\n",
    "\n",
    "labels_con_dispositivos = pd.merge(df_device, labels_con_15_modelos, on=\"person\", how=\"inner\")\n",
    "labels_con_dispositivos_num = labels_con_dispositivos.drop(columns=\"person\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = labels_con_dispositivos_num.iloc[:,:-1], labels_con_dispositivos_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y, weight={1: 1, 0: 0.1})\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 777,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, eval_metric = \"auc\", min_child_weight=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=20, missing=None,\n",
       "       n_estimators=6, n_jobs=1, nthread=None, objective='binary:hinge',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 778,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 779,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8675792708478838\n",
      "Test acuracy:  0.8664804469273742\n",
      "ROC auc score:  0.634124983549468\n",
      "Confusion matrix: \n",
      "[[1529  204]\n",
      " [  35   22]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos \n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visitas a la pagina segun resolucion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>1024x768</th>\n",
       "      <th>1360x768</th>\n",
       "      <th>1366x768</th>\n",
       "      <th>1440x900</th>\n",
       "      <th>1600x900</th>\n",
       "      <th>1920x1080</th>\n",
       "      <th>320x534</th>\n",
       "      <th>320x568</th>\n",
       "      <th>320x570</th>\n",
       "      <th>360x640</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008ed71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091926</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00091a7a</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000ba417</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000c79fe</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  1024x768  1360x768  1366x768  1440x900  1600x900  1920x1080  \\\n",
       "0  0008ed71       0.0       0.0       0.0       0.0       0.0        2.0   \n",
       "1  00091926      34.0       0.0       0.0       0.0       0.0        0.0   \n",
       "2  00091a7a       0.0       0.0       0.0       0.0       0.0        0.0   \n",
       "3  000ba417       6.0       0.0       0.0       0.0       0.0        0.0   \n",
       "4  000c79fe       0.0       0.0       0.0       0.0       0.0        0.0   \n",
       "\n",
       "   320x534  320x568  320x570  360x640  \n",
       "0      0.0      0.0      0.0      0.0  \n",
       "1      0.0      0.0      0.0      0.0  \n",
       "2      0.0      0.0      0.0      1.0  \n",
       "3      0.0      0.0      0.0      0.0  \n",
       "4      0.0      0.0      0.0      1.0  "
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resolucion = df.loc[df['event'] == 'visited site']\n",
    "df_resolucion = df_resolucion[['person','screen_resolution']].dropna()\n",
    "\n",
    "top_5_resoluciones = df_resolucion['screen_resolution'].value_counts().head(10).index\n",
    "df_resolucion = df_resolucion.loc[df_resolucion['screen_resolution'].isin(top_5_resoluciones)]\n",
    "df_resolucion = pd.concat([df_resolucion['person'],\\\n",
    "        pd.get_dummies(df_resolucion['screen_resolution'])],axis = 1).groupby('person').sum().reset_index()\n",
    "\n",
    "df_resolucion = pd.merge(df_resolucion, todas_las_personas, on=\"person\", how=\"right\").fillna(0)\n",
    "\n",
    "df_resolucion.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1024x768</th>\n",
       "      <th>1360x768</th>\n",
       "      <th>1366x768</th>\n",
       "      <th>1440x900</th>\n",
       "      <th>1600x900</th>\n",
       "      <th>1920x1080</th>\n",
       "      <th>320x534</th>\n",
       "      <th>320x568</th>\n",
       "      <th>320x570</th>\n",
       "      <th>360x640</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>32373.000000</td>\n",
       "      <td>32373.000000</td>\n",
       "      <td>32373.000000</td>\n",
       "      <td>32373.00000</td>\n",
       "      <td>32373.000000</td>\n",
       "      <td>32373.000000</td>\n",
       "      <td>32373.000000</td>\n",
       "      <td>32373.000000</td>\n",
       "      <td>32373.000000</td>\n",
       "      <td>32373.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.185031</td>\n",
       "      <td>0.204244</td>\n",
       "      <td>1.537083</td>\n",
       "      <td>0.17076</td>\n",
       "      <td>0.189664</td>\n",
       "      <td>0.245513</td>\n",
       "      <td>0.235752</td>\n",
       "      <td>0.136873</td>\n",
       "      <td>0.159763</td>\n",
       "      <td>2.262194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.860610</td>\n",
       "      <td>2.087674</td>\n",
       "      <td>5.612604</td>\n",
       "      <td>1.75788</td>\n",
       "      <td>2.111903</td>\n",
       "      <td>2.313731</td>\n",
       "      <td>2.016357</td>\n",
       "      <td>1.443385</td>\n",
       "      <td>1.590214</td>\n",
       "      <td>7.019321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>105.000000</td>\n",
       "      <td>133.000000</td>\n",
       "      <td>246.000000</td>\n",
       "      <td>99.00000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>146.000000</td>\n",
       "      <td>124.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>293.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           1024x768      1360x768      1366x768     1440x900      1600x900  \\\n",
       "count  32373.000000  32373.000000  32373.000000  32373.00000  32373.000000   \n",
       "mean       0.185031      0.204244      1.537083      0.17076      0.189664   \n",
       "std        1.860610      2.087674      5.612604      1.75788      2.111903   \n",
       "min        0.000000      0.000000      0.000000      0.00000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.00000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.00000      0.000000   \n",
       "75%        0.000000      0.000000      1.000000      0.00000      0.000000   \n",
       "max      105.000000    133.000000    246.000000     99.00000    116.000000   \n",
       "\n",
       "          1920x1080       320x534       320x568       320x570       360x640  \n",
       "count  32373.000000  32373.000000  32373.000000  32373.000000  32373.000000  \n",
       "mean       0.245513      0.235752      0.136873      0.159763      2.262194  \n",
       "std        2.313731      2.016357      1.443385      1.590214      7.019321  \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000  \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000  \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000  \n",
       "75%        0.000000      0.000000      0.000000      0.000000      2.000000  \n",
       "max      146.000000    124.000000     78.000000     75.000000    293.000000  "
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resolucion.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creo que es mucho 20 resoluciones, probar (quizas empeore).."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veo cuantas personas a predecir pierdo\n",
    "df_resolucion_predecir = pd.merge(df_resolucion, df_persons, on=\"person\", how=\"inner\")\n",
    "df_resolucion_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge\n",
    "\n",
    "labels_con_resoluciones = pd.merge(df_resolucion, labels_con_dispositivos, on=\"person\", how=\"inner\")\n",
    "labels_con_resoluciones_num = labels_con_resoluciones.drop(columns=\"person\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8949, 72)"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_con_resoluciones.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_sistema' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-141-9ddb9fc86da9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m      \u001b[1;33m,\u001b[0m \u001b[0mdistancia_dias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcant_modelos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcant_dias_dist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentradas_tot_y_dias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mentradas_tot_y_meses\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m       \u001b[0mdf_events_visitas_prod_color_storage_condition\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_mew_5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_device\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf_resolucion\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m       df_sistema]\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mdf_mejor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdfs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_sistema' is not defined"
     ]
    }
   ],
   "source": [
    "# Super Merge\n",
    "dfs=0\n",
    "dfs =[mes_dia_mas_entradas, entradas_30_dias_df, df_con_mes_5, entradas_tot,\\\n",
    "      cant_checkouts_tot, mayor_ciudad, mayor_camp, mayor_engine, mayor_modelo, mayor_evento, df_con_check\\\n",
    "     , distancia_dias, cant_modelos, cant_dias_dist, entradas_tot_y_dias, entradas_tot_y_meses,\\\n",
    "      df_events_visitas_prod_color_storage_condition, df_mew_5, df_device, df_resolucion,\\\n",
    "      df_sistema]\n",
    "\n",
    "df_mejor = pd.concat(dfs, axis=1).reset_index()\n",
    "\n",
    "df_final = reduce(lambda left,right: pd.merge(left,right,on='person', how='inner'), dfs)\n",
    "df_mejor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 781,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = labels_con_resoluciones_num.iloc[:,:-1], labels_con_resoluciones_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y, weight={1: 1, 0: 0.1})\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, eval_metric = \"auc\", min_child_weight=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 799,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=16, missing=None,\n",
       "       n_estimators=6, n_jobs=1, nthread=None, objective='binary:hinge',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 799,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 800,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.9187037295711692\n",
      "Test acuracy:  0.9067039106145252\n",
      "ROC auc score:  0.6144307481743921\n",
      "Confusion matrix: \n",
      "[[1603  120]\n",
      " [  47   20]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos \n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " --- Aumento un toke, bien ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visitas a la pagina segun sistema operativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 977,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>Android 6</th>\n",
       "      <th>Android 6.0.1</th>\n",
       "      <th>Android 7</th>\n",
       "      <th>Windows 10</th>\n",
       "      <th>Windows 7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008ed71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091926</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000ba417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000c79fe</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000e4d9e</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  Android 6  Android 6.0.1  Android 7  Windows 10   Windows 7 \n",
       "0  0008ed71        0.0            0.0        0.0          2.0         0.0\n",
       "1  00091926        0.0            0.0        0.0          0.0        34.0\n",
       "2  000ba417        0.0            0.0        0.0          6.0         0.0\n",
       "3  000c79fe        0.0            0.0        1.0          0.0         0.0\n",
       "4  000e4d9e        0.0            0.0        0.0         13.0         0.0"
      ]
     },
     "execution_count": 977,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sistema = df.loc[df['event'] == 'visited site']\n",
    "df_sistema = df_sistema[['person','operating_system_version']].dropna()\n",
    "\n",
    "top_5_sistemas = df_sistema['operating_system_version'].value_counts().head(5).index\n",
    "df_sistema = df_sistema.loc[df_sistema['operating_system_version'].isin(top_5_sistemas)]\n",
    "df_sistema = pd.concat([df_sistema['person'],\\\n",
    "        pd.get_dummies(df_sistema['operating_system_version'])],axis = 1).groupby('person').sum().reset_index()\n",
    "\n",
    "df_sistema = pd.merge(df_sistema, todas_las_personas, on=\"person\", how=\"right\").fillna(0)\n",
    "df_sistema.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 978,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 978,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veo cuantas personas a predecir pierdo\n",
    "df_sistema_predecir = pd.merge(df_sistema, df_persons, on=\"person\", how=\"inner\")\n",
    "df_sistema_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 979,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge\n",
    "\n",
    "labels_con_SO = pd.merge(df_sistema, labels_con_resoluciones, on=\"person\", how=\"inner\")\n",
    "labels_con_SO_num = labels_con_SO.drop(columns=\"person\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 980,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8949, 77)"
      ]
     },
     "execution_count": 980,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_con_SO.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 981,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = labels_con_SO_num.iloc[:,:-1], labels_con_SO_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "#data_dmatrix = xgb.DMatrix(data=X,label=y, weight={1: 1, 0: 0.1})\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 982,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25.514814814814816"
      ]
     },
     "execution_count": 982,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBClassifier(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, eval_metric = \"auc\", min_child_weight=9, scale_pos_weight=ratio)\n",
    "ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 983,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=9, missing=None,\n",
       "       n_estimators=6, n_jobs=1, nthread=None, objective='binary:hinge',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=25.514814814814816, seed=None, silent=True,\n",
       "       subsample=1)"
      ]
     },
     "execution_count": 983,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 984,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 985,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8833635982679146\n",
      "Test acuracy:  0.882122905027933\n",
      "ROC auc score:  0.6152889399158056\n",
      "Confusion matrix: \n",
      "[[1563  179]\n",
      " [  32   16]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos \n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 986,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = labels_con_SO_num.iloc[:,:-1], labels_con_SO_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "#data_dmatrix = xgb.DMatrix(data=X,label=y, weight={1: 1, 0: 0.1})\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 987,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplico los compradores\n",
    "\n",
    "y_train_df = y_train.to_frame()\n",
    "X_train_df = X_train.reset_index()\n",
    "train = pd.merge(X_train, y_train_df, how=\"inner\", left_index=True, right_index=True)\n",
    "train_compradores = train.loc[train[\"label\"] == 1]\n",
    "train_dup = pd.concat([train, train_compradores], ignore_index=True)\n",
    "X_train, y_train = train_dup.drop(columns=\"label\"), train_dup[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 988,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.757407407407408"
      ]
     },
     "execution_count": 988,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBClassifier(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, eval_metric = \"auc\", min_child_weight=10)\n",
    "ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 989,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=10, missing=None,\n",
       "       n_estimators=6, n_jobs=1, nthread=None, objective='binary:hinge',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 989,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 990,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 991,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.704401669134473\n",
      "Test acuracy:  0.7\n",
      "ROC auc score:  0.6635332950631458\n",
      "Confusion matrix: \n",
      "[[1223  519]\n",
      " [  18   30]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos \n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visitas a la pagina segun version del navegador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>Chrome 65.0</th>\n",
       "      <th>Chrome 66.0</th>\n",
       "      <th>Chrome Mobile 64.0</th>\n",
       "      <th>Chrome Mobile 65.0</th>\n",
       "      <th>Chrome Mobile 66.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008ed71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091926</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000ba417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000c79fe</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000e619d</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  Chrome 65.0  Chrome 66.0  Chrome Mobile 64.0  Chrome Mobile 65.0  \\\n",
       "0  0008ed71          0.0          2.0                 0.0                 0.0   \n",
       "1  00091926          0.0         34.0                 0.0                 0.0   \n",
       "2  000ba417          0.0          6.0                 0.0                 0.0   \n",
       "3  000c79fe          0.0          0.0                 0.0                 0.0   \n",
       "4  000e619d          0.0          5.0                 0.0                 0.0   \n",
       "\n",
       "   Chrome Mobile 66.0  \n",
       "0                 0.0  \n",
       "1                 0.0  \n",
       "2                 0.0  \n",
       "3                 1.0  \n",
       "4                 0.0  "
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_navegador = df.loc[df['event'] == 'visited site']\n",
    "df_navegador = df_navegador[['person','browser_version']].dropna()\n",
    "\n",
    "top_5_navegadores = df_navegador['browser_version'].value_counts().head(5).index\n",
    "df_navegador = df_navegador.loc[df_navegador['browser_version'].isin(top_5_navegadores)]\n",
    "df_navegador = pd.concat([df_navegador['person'],\\\n",
    "        pd.get_dummies(df_navegador['browser_version'])],axis = 1).groupby('person').sum().reset_index()\n",
    "\n",
    "df_navegador = pd.merge(df_navegador, todas_las_personas, on=\"person\", how=\"right\").fillna(0)\n",
    "\n",
    "df_navegador.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veo cuantas personas a predecir pierdo\n",
    "df_navegador_predecir = pd.merge(df_navegador, df_persons, on=\"person\", how=\"inner\")\n",
    "df_navegador_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge\n",
    "\n",
    "labels_con_navegador = pd.merge(df_navegador, labels_con_SO, on=\"person\", how=\"inner\")\n",
    "labels_con_navegador_num = labels_con_navegador.drop(columns=\"person\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = labels_con_navegador_num.iloc[:,:-1], labels_con_navegador_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y, weight={1: 1, 0: 0.1})\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, eval_metric = \"auc\", min_child_weight=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=1000, missing=None,\n",
       "       n_estimators=6, n_jobs=1, nthread=None, objective='binary:hinge',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8446710434418215\n",
      "Test acuracy:  0.8480446927374302\n",
      "ROC auc score:  0.6010071663761378\n",
      "Confusion matrix: \n",
      "[[1495  226]\n",
      " [  46   23]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos \n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " --- Baj, :( ---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visitas a producto por mes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00091926</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>372.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091a7a</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000ba417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>153.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000c79fe</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000e4d9e</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>339.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person    1    2    3    4      5\n",
       "0  00091926  0.0  0.0  0.0  0.0  372.0\n",
       "1  00091a7a  0.0  0.0  3.0  0.0    0.0\n",
       "2  000ba417  0.0  0.0  0.0  0.0  153.0\n",
       "3  000c79fe  0.0  0.0  0.0  0.0    3.0\n",
       "4  000e4d9e  0.0  0.0  0.0  0.0  339.0"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_visitas_producto_por_mes = df.loc[df_events['event'] == 'viewed product']\n",
    "df_visitas_producto_por_mes = df_visitas_producto_por_mes[['person','month']]\n",
    "\n",
    "df_visitas_producto_por_mes = pd.concat([pd.get_dummies(df_visitas_producto_por_mes['month'])\\\n",
    "                                         ,df_visitas_producto_por_mes[['person']]],axis = 1).groupby('person')\\\n",
    "                                        .sum().reset_index()\n",
    "\n",
    "df_visitas_producto_por_mes = pd.merge(df_visitas_producto_por_mes, todas_las_personas, on=\"person\", how=\"right\").fillna(0)\n",
    "\n",
    "df_visitas_producto_por_mes.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [],
   "source": [
    "nombres_columnas = ['mes_'+str(columna) for columna in df_visitas_producto_por_mes.columns]\n",
    "nombres_columnas[0] = 'person'\n",
    "df_visitas_producto_por_mes.columns = nombres_columnas\n",
    "\n",
    "# Merge \n",
    "labels_con_meses = pd.merge(df_visitas_producto_por_mes, labels_con_SO, on=\"person\", how=\"inner\")\n",
    "labels_con_meses_num = labels_con_meses.drop(columns=\"person\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veo cuantas personas a predecir pierdo\n",
    "df_visitas_producto_por_mes_predecir = pd.merge(df_visitas_producto_por_mes, df_persons, on=\"person\", how=\"inner\")\n",
    "df_visitas_producto_por_mes_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_con_meses.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = labels_con_meses_num.iloc[:,:-1], labels_con_meses_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y, weight={1: 1, 0: 0.1})\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, eval_metric = \"auc\", min_child_weight=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=1000, missing=None,\n",
       "       n_estimators=6, n_jobs=1, nthread=None, objective='binary:hinge',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8393630395306607\n",
      "Test acuracy:  0.8312849162011173\n",
      "ROC auc score:  0.5932299390344373\n",
      "Confusion matrix: \n",
      "[[1469  265]\n",
      " [  37   19]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos \n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dia de la semana que accede"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 998,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008ed71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091926</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00091a7a</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000ba417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000c79fe</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person    0    1    2    3    4    5     6\n",
       "0  0008ed71  0.0  0.0  0.0  2.0  0.0  0.0   0.0\n",
       "1  00091926  2.0  4.0  3.0  6.0  3.0  5.0  11.0\n",
       "2  00091a7a  1.0  0.0  0.0  0.0  0.0  0.0   0.0\n",
       "3  000ba417  0.0  0.0  0.0  4.0  0.0  2.0   0.0\n",
       "4  000c79fe  0.0  1.0  0.0  0.0  0.0  0.0   0.0"
      ]
     },
     "execution_count": 998,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['day_of_week'] = df[\"timestamp\"].dt.dayofweek\n",
    "df_dia_visita = df.loc[df['event'] == 'visited site']\n",
    "df_dia_visita = df_dia_visita[['person','day_of_week']]\n",
    "\n",
    "df_dia_visita = pd.concat([df_dia_visita['person'],\\\n",
    "                                 pd.get_dummies(df_dia_visita['day_of_week'])],axis = 1)\\\n",
    "                                .groupby('person').sum().reset_index()\n",
    "\n",
    "df_dia_visita = pd.merge(df_dia_visita, todas_las_personas, on=\"person\", how=\"right\").fillna(0)\n",
    "\n",
    "\n",
    "df_dia_visita.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 999,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 999,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veo cuantas personas a predecir pierdo\n",
    "df_dia_visita_predecir = pd.merge(df_dia_visita, df_persons, on=\"person\", how=\"inner\")\n",
    "df_dia_visita_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1000,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2341681 entries, 0 to 2341680\n",
      "Data columns (total 26 columns):\n",
      "timestamp                   datetime64[ns]\n",
      "event                       object\n",
      "person                      object\n",
      "url                         object\n",
      "sku                         float64\n",
      "model                       object\n",
      "condition                   object\n",
      "storage                     object\n",
      "color                       object\n",
      "skus                        object\n",
      "search_term                 object\n",
      "staticpage                  object\n",
      "campaign_source             object\n",
      "search_engine               object\n",
      "channel                     object\n",
      "new_vs_returning            object\n",
      "city                        object\n",
      "region                      object\n",
      "country                     object\n",
      "device_type                 object\n",
      "screen_resolution           object\n",
      "operating_system_version    object\n",
      "browser_version             object\n",
      "month                       int64\n",
      "day                         int64\n",
      "day_of_week                 int64\n",
      "dtypes: datetime64[ns](1), float64(1), int64(3), object(21)\n",
      "memory usage: 464.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1001,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge\n",
    "\n",
    "labels_con_dia_semana = pd.merge(df_dia_visita, labels_con_navegador, on=\"person\", how=\"inner\")\n",
    "labels_con_dia_semana_num = labels_con_dia_semana.drop(columns=\"person\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1016,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = labels_con_dia_semana_num.iloc[:,:-1], labels_con_dia_semana_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y, weight={1: 1, 0: 0.1})\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1017,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, eval_metric = \"auc\", min_child_weight=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1018,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=1000, missing=None,\n",
       "       n_estimators=6, n_jobs=1, nthread=None, objective='binary:hinge',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 1018,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1019,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1020,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8195278670205336\n",
      "Test acuracy:  0.8240223463687151\n",
      "ROC auc score:  0.6630981666514816\n",
      "Confusion matrix: \n",
      "[[1447  286]\n",
      " [  29   28]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos \n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1021,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8195278670205336\n",
      "Test acuracy:  0.8240223463687151\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.83      0.90      1733\n",
      "           1       0.09      0.49      0.15        57\n",
      "\n",
      "   micro avg       0.82      0.82      0.82      1790\n",
      "   macro avg       0.53      0.66      0.53      1790\n",
      "weighted avg       0.95      0.82      0.88      1790\n",
      "\n",
      "\n",
      "Precision Score:  0.08917197452229299\n",
      "Recall Score:  0.49122807017543857\n",
      "F1 Score:  0.1509433962264151\n",
      "Cohen Kappa Score:  0.10256981604153481\n",
      "ROC auc score:  0.6630981666514816\n",
      "Confusion matrix: \n",
      "[[1447  286]\n",
      " [  29   28]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\\\n",
    "                            f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "# Pruebo todas las metricas.\n",
    "# accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\n",
    "# f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "\n",
    "trainAccuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "testAccuracy = accuracy_score(y_test, preds)\n",
    "\n",
    "meanSquaredError = mean_squared_error(y_test, preds)\n",
    "classificationReport = classification_report(y_test, preds)\n",
    "precisionScore = precision_score(y_test, preds)\n",
    "recallScore = recall_score(y_test, preds)\n",
    "f1Score = f1_score(y_test, preds)\n",
    "cohenKappaScore = cohen_kappa_score(y_test, preds)\n",
    "areaDebajoDeCurva = roc_auc_score(y_test, preds)\n",
    "matrizDeConfusion = confusion_matrix(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", trainAccuracy)\n",
    "print(\"Test acuracy: \", testAccuracy)\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(classificationReport)\n",
    "print()\n",
    "print(\"Precision Score: \",precisionScore)\n",
    "print(\"Recall Score: \",recallScore)\n",
    "print(\"F1 Score: \",f1Score)\n",
    "print(\"Cohen Kappa Score: \",cohenKappaScore)\n",
    "print(\"ROC auc score: \", areaDebajoDeCurva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matrizDeConfusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba duplicando los compradores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = labels_con_dia_semana_num.iloc[:,:-1], labels_con_dia_semana_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y, weight={1: 1, 0: 0.1})\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1234,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplico los compradores\n",
    "\n",
    "train = pd.merge(X_train, y_train_df, how=\"inner\", left_index=True, right_index=True)\n",
    "train_compradores = train.loc[train[\"label\"] == 1]\n",
    "train_dup = pd.concat([train, train_compradores], ignore_index=True)\n",
    "X_train, y_train = train_dup.drop(columns=\"label\"), train_dup[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1235,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, eval_metric = \"auc\", min_child_weight=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=1, missing=None,\n",
       "       n_estimators=6, n_jobs=1, nthread=None, objective='binary:hinge',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 1236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1238,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.6818059299191375\n",
      "Test acuracy:  0.6865921787709497\n",
      "ROC auc score:  0.7108907583442159\n",
      "Confusion matrix: \n",
      "[[1187  546]\n",
      " [  15   42]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos \n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.6818059299191375\n",
      "Test acuracy:  0.6865921787709497\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.68      0.81      1733\n",
      "           1       0.07      0.74      0.13        57\n",
      "\n",
      "   micro avg       0.69      0.69      0.69      1790\n",
      "   macro avg       0.53      0.71      0.47      1790\n",
      "weighted avg       0.96      0.69      0.79      1790\n",
      "\n",
      "\n",
      "Precision Score:  0.07142857142857142\n",
      "Recall Score:  0.7368421052631579\n",
      "F1 Score:  0.13023255813953488\n",
      "Cohen Kappa Score:  0.07662218004667487\n",
      "ROC auc score:  0.7108907583442159\n",
      "Confusion matrix: \n",
      "[[1187  546]\n",
      " [  15   42]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\\\n",
    "                            f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "# Pruebo todas las metricas.\n",
    "# accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\n",
    "# f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "\n",
    "trainAccuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "testAccuracy = accuracy_score(y_test, preds)\n",
    "\n",
    "meanSquaredError = mean_squared_error(y_test, preds)\n",
    "classificationReport = classification_report(y_test, preds)\n",
    "precisionScore = precision_score(y_test, preds)\n",
    "recallScore = recall_score(y_test, preds)\n",
    "f1Score = f1_score(y_test, preds)\n",
    "cohenKappaScore = cohen_kappa_score(y_test, preds)\n",
    "areaDebajoDeCurva = roc_auc_score(y_test, preds)\n",
    "matrizDeConfusion = confusion_matrix(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", trainAccuracy)\n",
    "print(\"Test acuracy: \", testAccuracy)\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(classificationReport)\n",
    "print()\n",
    "print(\"Precision Score: \",precisionScore)\n",
    "print(\"Recall Score: \",recallScore)\n",
    "print(\"F1 Score: \",f1Score)\n",
    "print(\"Cohen Kappa Score: \",cohenKappaScore)\n",
    "print(\"ROC auc score: \", areaDebajoDeCurva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matrizDeConfusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lo mejor que llegu ahora si: 71"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time features de Santi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hora"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cantidad de eventos por hora. (Todas las horas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1182,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"day\"] = df[\"timestamp\"].dt.day\n",
    "df[\"day_of_week\"] = df['timestamp'].dt.weekday_name\n",
    "df['day_of_year'] = df['timestamp'].dt.dayofyear\n",
    "df['hour'] = df['timestamp'].dt.hour\n",
    "df['minute'] = df['timestamp'].dt.minute\n",
    "#df_events['second'] = df_events['timestamp'].dt.second\n",
    "df['week_of_year'] = df['timestamp'].dt.weekofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1183,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hour = df[['person','hour']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1184,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008ed71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091926</td>\n",
       "      <td>117.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00091a7a</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000ba417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000c79fe</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     person      0      1     2     3     4    5    6    7    8  ...     14  \\\n",
       "0  0008ed71    0.0    0.0   0.0   0.0   0.0  0.0  0.0  0.0  0.0  ...    0.0   \n",
       "1  00091926  117.0  122.0  33.0  15.0  26.0  0.0  0.0  0.0  0.0  ...    0.0   \n",
       "2  00091a7a    0.0    0.0   0.0   0.0   0.0  0.0  0.0  0.0  0.0  ...   10.0   \n",
       "3  000ba417    0.0    0.0   0.0   0.0   0.0  0.0  0.0  0.0  0.0  ...    0.0   \n",
       "4  000c79fe   17.0    0.0   0.0   0.0   0.0  0.0  0.0  0.0  0.0  ...    0.0   \n",
       "\n",
       "    15    16    17    18    19   20   21   22    23  \n",
       "0  0.0   3.0   0.0   0.0   0.0  0.0  0.0  0.0   0.0  \n",
       "1  0.0   0.0   0.0  50.0  10.0  0.0  3.0  7.0  65.0  \n",
       "2  0.0   0.0   0.0   0.0   0.0  0.0  0.0  0.0   0.0  \n",
       "3  0.0  59.0  22.0   0.0   0.0  0.0  0.0  0.0   0.0  \n",
       "4  0.0   0.0   0.0   0.0   0.0  0.0  0.0  0.0   0.0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 1184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hour1 = pd.concat([df_hour['person'],pd.get_dummies(df_hour['hour'])],axis = 1).groupby('person').sum()\\\n",
    "            .reset_index()\n",
    "df_hour1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge\n",
    "\n",
    "labels_con_horas = pd.merge(df_hour1, labels_con_dia_semana, on=\"person\", how=\"inner\")\n",
    "labels_con_horas_num = labels_con_horas.drop(columns=\"person\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = labels_con_horas_num.iloc[:,:-1], labels_con_horas_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y, weight={1: 1, 0: 0.1})\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1187,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, eval_metric = \"auc\", min_child_weight=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=1000, missing=None,\n",
       "       n_estimators=6, n_jobs=1, nthread=None, objective='binary:hinge',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 1188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1190,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8449504120687247\n",
      "Test acuracy:  0.8558659217877095\n",
      "ROC auc score:  0.6371265729239428\n",
      "Confusion matrix: \n",
      "[[1509  224]\n",
      " [  34   23]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos \n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1191,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8449504120687247\n",
      "Test acuracy:  0.8558659217877095\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.87      0.92      1733\n",
      "           1       0.09      0.40      0.15        57\n",
      "\n",
      "   micro avg       0.86      0.86      0.86      1790\n",
      "   macro avg       0.54      0.64      0.54      1790\n",
      "weighted avg       0.95      0.86      0.90      1790\n",
      "\n",
      "\n",
      "Precision Score:  0.0931174089068826\n",
      "Recall Score:  0.40350877192982454\n",
      "F1 Score:  0.1513157894736842\n",
      "Cohen Kappa Score:  0.10500346897880242\n",
      "ROC auc score:  0.6371265729239428\n",
      "Confusion matrix: \n",
      "[[1509  224]\n",
      " [  34   23]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\\\n",
    "                            f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "# Pruebo todas las metricas.\n",
    "# accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\n",
    "# f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "\n",
    "trainAccuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "testAccuracy = accuracy_score(y_test, preds)\n",
    "\n",
    "meanSquaredError = mean_squared_error(y_test, preds)\n",
    "classificationReport = classification_report(y_test, preds)\n",
    "precisionScore = precision_score(y_test, preds)\n",
    "recallScore = recall_score(y_test, preds)\n",
    "f1Score = f1_score(y_test, preds)\n",
    "cohenKappaScore = cohen_kappa_score(y_test, preds)\n",
    "areaDebajoDeCurva = roc_auc_score(y_test, preds)\n",
    "matrizDeConfusion = confusion_matrix(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", trainAccuracy)\n",
    "print(\"Test acuracy: \", testAccuracy)\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(classificationReport)\n",
    "print()\n",
    "print(\"Precision Score: \",precisionScore)\n",
    "print(\"Recall Score: \",recallScore)\n",
    "print(\"F1 Score: \",f1Score)\n",
    "print(\"Cohen Kappa Score: \",cohenKappaScore)\n",
    "print(\"ROC auc score: \", areaDebajoDeCurva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matrizDeConfusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba duplicando los compradores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1326,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = labels_con_horas_num.iloc[:,:-1], labels_con_horas_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y, weight={1: 1, 0: 0.1})\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1327,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplico los compradores\n",
    "y_train_df = pd.DataFrame(y_train)\n",
    "y_train_df.columns = [\"label\"]\n",
    "train = pd.merge(X_train, y_train_df, how=\"inner\", left_index=True, right_index=True)\n",
    "train_compradores = train.loc[train[\"label\"] == 1]\n",
    "train_dup = pd.concat([train, train_compradores], ignore_index=True)\n",
    "X_train, y_train = train_dup.drop(columns=\"label\"), train_dup[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1328,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, eval_metric = \"auc\", min_child_weight=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=1, missing=None,\n",
       "       n_estimators=6, n_jobs=1, nthread=None, objective='binary:hinge',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 1329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1330,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1331,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.6777628032345013\n",
      "Test acuracy:  0.6815642458100558\n",
      "ROC auc score:  0.69981069233962\n",
      "Confusion matrix: \n",
      "[[1179  554]\n",
      " [  16   41]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos \n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.6777628032345013\n",
      "Test acuracy:  0.6815642458100558\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.68      0.81      1733\n",
      "           1       0.07      0.72      0.13        57\n",
      "\n",
      "   micro avg       0.68      0.68      0.68      1790\n",
      "   macro avg       0.53      0.70      0.47      1790\n",
      "weighted avg       0.96      0.68      0.78      1790\n",
      "\n",
      "\n",
      "Precision Score:  0.06890756302521009\n",
      "Recall Score:  0.7192982456140351\n",
      "F1 Score:  0.1257668711656442\n",
      "Cohen Kappa Score:  0.07182169661132576\n",
      "ROC auc score:  0.69981069233962\n",
      "Confusion matrix: \n",
      "[[1179  554]\n",
      " [  16   41]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\\\n",
    "                            f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "# Pruebo todas las metricas.\n",
    "# accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\n",
    "# f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "\n",
    "trainAccuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "testAccuracy = accuracy_score(y_test, preds)\n",
    "\n",
    "meanSquaredError = mean_squared_error(y_test, preds)\n",
    "classificationReport = classification_report(y_test, preds)\n",
    "precisionScore = precision_score(y_test, preds)\n",
    "recallScore = recall_score(y_test, preds)\n",
    "f1Score = f1_score(y_test, preds)\n",
    "cohenKappaScore = cohen_kappa_score(y_test, preds)\n",
    "areaDebajoDeCurva = roc_auc_score(y_test, preds)\n",
    "matrizDeConfusion = confusion_matrix(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", trainAccuracy)\n",
    "print(\"Test acuracy: \", testAccuracy)\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(classificationReport)\n",
    "print()\n",
    "print(\"Precision Score: \",precisionScore)\n",
    "print(\"Recall Score: \",recallScore)\n",
    "print(\"F1 Score: \",f1Score)\n",
    "print(\"Cohen Kappa Score: \",cohenKappaScore)\n",
    "print(\"ROC auc score: \", areaDebajoDeCurva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matrizDeConfusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cantidad de eventos en fin de semana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1201,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_day_of_week3 = df[['person','day_of_week']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1202,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seba\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_day_of_week3['fin_de_semana'] = df_day_of_week3['day_of_week'].isin(['Saturday','Sunday'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1203,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_day_of_week3 = df_day_of_week3.groupby('person').sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge\n",
    "\n",
    "labels_con_findes = pd.merge(df_day_of_week3, labels_con_horas, on=\"person\", how=\"inner\")\n",
    "labels_con_findes_num = labels_con_findes.drop(columns=\"person\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1321,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = labels_con_findes_num.iloc[:,:-1], labels_con_findes_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y, weight={1: 1, 0: 0.1})\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1322,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, eval_metric = \"auc\", min_child_weight=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=1000, missing=None,\n",
       "       n_estimators=6, n_jobs=1, nthread=None, objective='binary:hinge',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 1323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1324,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1325,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8876938119849141\n",
      "Test acuracy:  0.9005586592178771\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.92      0.95      1733\n",
      "           1       0.12      0.35      0.18        57\n",
      "\n",
      "   micro avg       0.90      0.90      0.90      1790\n",
      "   macro avg       0.55      0.63      0.57      1790\n",
      "weighted avg       0.95      0.90      0.92      1790\n",
      "\n",
      "\n",
      "Precision Score:  0.12422360248447205\n",
      "Recall Score:  0.3508771929824561\n",
      "F1 Score:  0.18348623853211007\n",
      "Cohen Kappa Score:  0.14318598634992175\n",
      "ROC auc score:  0.6347576963181178\n",
      "Confusion matrix: \n",
      "[[1592  141]\n",
      " [  37   20]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\\\n",
    "                            f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "# Pruebo todas las metricas.\n",
    "# accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\n",
    "# f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "\n",
    "trainAccuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "testAccuracy = accuracy_score(y_test, preds)\n",
    "\n",
    "meanSquaredError = mean_squared_error(y_test, preds)\n",
    "classificationReport = classification_report(y_test, preds)\n",
    "precisionScore = precision_score(y_test, preds)\n",
    "recallScore = recall_score(y_test, preds)\n",
    "f1Score = f1_score(y_test, preds)\n",
    "cohenKappaScore = cohen_kappa_score(y_test, preds)\n",
    "areaDebajoDeCurva = roc_auc_score(y_test, preds)\n",
    "matrizDeConfusion = confusion_matrix(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", trainAccuracy)\n",
    "print(\"Test acuracy: \", testAccuracy)\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(classificationReport)\n",
    "print()\n",
    "print(\"Precision Score: \",precisionScore)\n",
    "print(\"Recall Score: \",recallScore)\n",
    "print(\"F1 Score: \",f1Score)\n",
    "print(\"Cohen Kappa Score: \",cohenKappaScore)\n",
    "print(\"ROC auc score: \", areaDebajoDeCurva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matrizDeConfusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba duplicando los compradores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1315,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = labels_con_findes_num.iloc[:,:-1], labels_con_findes_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y, weight={1: 1, 0: 0.1})\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1316,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplico los compradores\n",
    "y_train_df = pd.DataFrame(y_train)\n",
    "y_train_df.columns = [\"label\"]\n",
    "train = pd.merge(X_train, y_train_df, how=\"inner\", left_index=True, right_index=True)\n",
    "train_compradores = train.loc[train[\"label\"] == 1]\n",
    "train_dup = pd.concat([train, train_compradores], ignore_index=True)\n",
    "X_train, y_train = train_dup.drop(columns=\"label\"), train_dup[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1317,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, eval_metric = \"auc\", min_child_weight=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=1, missing=None,\n",
       "       n_estimators=6, n_jobs=1, nthread=None, objective='binary:hinge',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 1318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1319,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.6842318059299192\n",
      "Test acuracy:  0.6916201117318436\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.69      0.81      1733\n",
      "           1       0.07      0.74      0.13        57\n",
      "\n",
      "   micro avg       0.69      0.69      0.69      1790\n",
      "   macro avg       0.53      0.71      0.47      1790\n",
      "weighted avg       0.96      0.69      0.79      1790\n",
      "\n",
      "\n",
      "Precision Score:  0.07253886010362694\n",
      "Recall Score:  0.7368421052631579\n",
      "F1 Score:  0.13207547169811318\n",
      "Cohen Kappa Score:  0.07865658865720404\n",
      "ROC auc score:  0.713487411546755\n",
      "Confusion matrix: \n",
      "[[1196  537]\n",
      " [  15   42]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\\\n",
    "                            f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "# Pruebo todas las metricas.\n",
    "# accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\n",
    "# f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "\n",
    "trainAccuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "testAccuracy = accuracy_score(y_test, preds)\n",
    "\n",
    "meanSquaredError = mean_squared_error(y_test, preds)\n",
    "classificationReport = classification_report(y_test, preds)\n",
    "precisionScore = precision_score(y_test, preds)\n",
    "recallScore = recall_score(y_test, preds)\n",
    "f1Score = f1_score(y_test, preds)\n",
    "cohenKappaScore = cohen_kappa_score(y_test, preds)\n",
    "areaDebajoDeCurva = roc_auc_score(y_test, preds)\n",
    "matrizDeConfusion = confusion_matrix(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", trainAccuracy)\n",
    "print(\"Test acuracy: \", testAccuracy)\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(classificationReport)\n",
    "print()\n",
    "print(\"Precision Score: \",precisionScore)\n",
    "print(\"Recall Score: \",recallScore)\n",
    "print(\"F1 Score: \",f1Score)\n",
    "print(\"Cohen Kappa Score: \",cohenKappaScore)\n",
    "print(\"ROC auc score: \", areaDebajoDeCurva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matrizDeConfusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cantidad de eventos en rango de horas (Morning , Afternoon, Evening y Night) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Morning     5 a 12  \n",
    "\n",
    "Afternoon     12 a 17\n",
    "\n",
    "Evening     17 a 21\n",
    "\n",
    "Night         21 a 4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1259,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hour_rango2 = df_hour.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1260,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hour_rango2['Morning'] = (df_hour_rango2['hour'].isin(list(range(5,13)))).astype(int)\n",
    "df_hour_rango2['Afternoon'] = (df_hour_rango2['hour'].isin(list(range(13,18)))).astype(int)\n",
    "df_hour_rango2['Evening'] = (df_hour_rango2['hour'].isin(list(range(18,21)))).astype(int)\n",
    "df_hour_rango2['Night'] = (df_hour_rango2['hour'].isin([22,23,0,1,2,3,4])).astype(int)\n",
    "df_hour_rango2.drop(columns = ['hour'],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1261,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hour_rango2a = df_hour_rango2.groupby('person').sum().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visita la pagina en rango de horas (Morning , Afternoon, Evening y Night) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1262,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_hour_rango2b = df_hour_rango2.drop_duplicates().groupby('person').sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1264,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge\n",
    "\n",
    "labels_con_rango_horario = pd.merge(df_hour_rango2b, labels_con_findes, on=\"person\", how=\"inner\")\n",
    "labels_con_rango_horario_num = labels_con_rango_horario.drop(columns=\"person\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = labels_con_rango_horario_num.iloc[:,:-1], labels_con_rango_horario_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y, weight={1: 1, 0: 0.1})\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1266,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, eval_metric = \"auc\", min_child_weight=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=1000, missing=None,\n",
       "       n_estimators=6, n_jobs=1, nthread=None, objective='binary:hinge',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 1267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1268,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1269,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.7929878474647297\n",
      "Test acuracy:  0.7938547486033519\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.80      0.88      1733\n",
      "           1       0.08      0.51      0.14        57\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      1790\n",
      "   macro avg       0.53      0.66      0.51      1790\n",
      "weighted avg       0.95      0.79      0.86      1790\n",
      "\n",
      "\n",
      "Precision Score:  0.07837837837837838\n",
      "Recall Score:  0.5087719298245614\n",
      "F1 Score:  0.1358313817330211\n",
      "Cohen Kappa Score:  0.08535622793048525\n",
      "ROC auc score:  0.656001660238305\n",
      "Confusion matrix: \n",
      "[[1392  341]\n",
      " [  28   29]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\\\n",
    "                            f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "# Pruebo todas las metricas.\n",
    "# accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\n",
    "# f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "\n",
    "trainAccuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "testAccuracy = accuracy_score(y_test, preds)\n",
    "\n",
    "meanSquaredError = mean_squared_error(y_test, preds)\n",
    "classificationReport = classification_report(y_test, preds)\n",
    "precisionScore = precision_score(y_test, preds)\n",
    "recallScore = recall_score(y_test, preds)\n",
    "f1Score = f1_score(y_test, preds)\n",
    "cohenKappaScore = cohen_kappa_score(y_test, preds)\n",
    "areaDebajoDeCurva = roc_auc_score(y_test, preds)\n",
    "matrizDeConfusion = confusion_matrix(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", trainAccuracy)\n",
    "print(\"Test acuracy: \", testAccuracy)\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(classificationReport)\n",
    "print()\n",
    "print(\"Precision Score: \",precisionScore)\n",
    "print(\"Recall Score: \",recallScore)\n",
    "print(\"F1 Score: \",f1Score)\n",
    "print(\"Cohen Kappa Score: \",cohenKappaScore)\n",
    "print(\"ROC auc score: \", areaDebajoDeCurva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matrizDeConfusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba duplicando los compradores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1309,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = labels_con_rango_horario_num.iloc[:,:-1], labels_con_rango_horario_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y, weight={1: 1, 0: 0.1})\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplico los compradores\n",
    "y_train_df = pd.DataFrame(y_train)\n",
    "y_train_df.columns = [\"label\"]\n",
    "train = pd.merge(X_train, y_train_df, how=\"inner\", left_index=True, right_index=True)\n",
    "train_compradores = train.loc[train[\"label\"] == 1]\n",
    "train_dup = pd.concat([train, train_compradores], ignore_index=True)\n",
    "X_train, y_train = train_dup.drop(columns=\"label\"), train_dup[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1311,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, eval_metric = \"auc\", min_child_weight=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=1, missing=None,\n",
       "       n_estimators=6, n_jobs=1, nthread=None, objective='binary:hinge',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 1312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1313,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1314,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.6490566037735849\n",
      "Test acuracy:  0.6581005586592179\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.65      0.79      1733\n",
      "         1.0       0.07      0.77      0.13        57\n",
      "\n",
      "   micro avg       0.66      0.66      0.66      1790\n",
      "   macro avg       0.53      0.71      0.46      1790\n",
      "weighted avg       0.96      0.66      0.77      1790\n",
      "\n",
      "\n",
      "Precision Score:  0.06842923794712286\n",
      "Recall Score:  0.7719298245614035\n",
      "F1 Score:  0.12571428571428572\n",
      "Cohen Kappa Score:  0.07138945730178403\n",
      "ROC auc score:  0.7131432158006094\n",
      "Confusion matrix: \n",
      "[[1134  599]\n",
      " [  13   44]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\\\n",
    "                            f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "# Pruebo todas las metricas.\n",
    "# accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\n",
    "# f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "\n",
    "trainAccuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "testAccuracy = accuracy_score(y_test, preds)\n",
    "\n",
    "meanSquaredError = mean_squared_error(y_test, preds)\n",
    "classificationReport = classification_report(y_test, preds)\n",
    "precisionScore = precision_score(y_test, preds)\n",
    "recallScore = recall_score(y_test, preds)\n",
    "f1Score = f1_score(y_test, preds)\n",
    "cohenKappaScore = cohen_kappa_score(y_test, preds)\n",
    "areaDebajoDeCurva = roc_auc_score(y_test, preds)\n",
    "matrizDeConfusion = confusion_matrix(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", trainAccuracy)\n",
    "print(\"Test acuracy: \", testAccuracy)\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(classificationReport)\n",
    "print()\n",
    "print(\"Precision Score: \",precisionScore)\n",
    "print(\"Recall Score: \",recallScore)\n",
    "print(\"F1 Score: \",f1Score)\n",
    "print(\"Cohen Kappa Score: \",cohenKappaScore)\n",
    "print(\"ROC auc score: \", areaDebajoDeCurva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matrizDeConfusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Con los datos transformados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1283,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = labels_con_rango_horario.loc[:,labels_con_rango_horario.columns != 'person']\n",
    "maxAbsScaler = preprocessing.MaxAbsScaler()\n",
    "x_scaled = maxAbsScaler.fit_transform(x)\n",
    "labels_con_rango_horario = pd.concat([labels_con_rango_horario['person'],pd.DataFrame(x_scaled)],axis = 1)\n",
    "labels_con_rango_horario_num = labels_con_rango_horario.drop(columns=\"person\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1284,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = labels_con_rango_horario_num.iloc[:,:-1], labels_con_rango_horario_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y, weight={1: 1, 0: 0.1})\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1285,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, eval_metric = \"auc\", min_child_weight=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=1000, missing=None,\n",
       "       n_estimators=6, n_jobs=1, nthread=None, objective='binary:hinge',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 1286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1287,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1288,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.7929878474647297\n",
      "Test acuracy:  0.7938547486033519\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.80      0.88      1733\n",
      "         1.0       0.08      0.51      0.14        57\n",
      "\n",
      "   micro avg       0.79      0.79      0.79      1790\n",
      "   macro avg       0.53      0.66      0.51      1790\n",
      "weighted avg       0.95      0.79      0.86      1790\n",
      "\n",
      "\n",
      "Precision Score:  0.07837837837837838\n",
      "Recall Score:  0.5087719298245614\n",
      "F1 Score:  0.1358313817330211\n",
      "Cohen Kappa Score:  0.08535622793048525\n",
      "ROC auc score:  0.656001660238305\n",
      "Confusion matrix: \n",
      "[[1392  341]\n",
      " [  28   29]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\\\n",
    "                            f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "# Pruebo todas las metricas.\n",
    "# accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\n",
    "# f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "\n",
    "trainAccuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "testAccuracy = accuracy_score(y_test, preds)\n",
    "\n",
    "meanSquaredError = mean_squared_error(y_test, preds)\n",
    "classificationReport = classification_report(y_test, preds)\n",
    "precisionScore = precision_score(y_test, preds)\n",
    "recallScore = recall_score(y_test, preds)\n",
    "f1Score = f1_score(y_test, preds)\n",
    "cohenKappaScore = cohen_kappa_score(y_test, preds)\n",
    "areaDebajoDeCurva = roc_auc_score(y_test, preds)\n",
    "matrizDeConfusion = confusion_matrix(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", trainAccuracy)\n",
    "print(\"Test acuracy: \", testAccuracy)\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(classificationReport)\n",
    "print()\n",
    "print(\"Precision Score: \",precisionScore)\n",
    "print(\"Recall Score: \",recallScore)\n",
    "print(\"F1 Score: \",f1Score)\n",
    "print(\"Cohen Kappa Score: \",cohenKappaScore)\n",
    "print(\"ROC auc score: \", areaDebajoDeCurva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matrizDeConfusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba duplicando los compradores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1301,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = labels_con_rango_horario_num.iloc[:,:-1], labels_con_rango_horario_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y, weight={1: 1, 0: 0.1})\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1304,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplico los compradores\n",
    "y_train_df = pd.DataFrame(y_train)\n",
    "y_train_df.columns = [\"label\"]\n",
    "train = pd.merge(X_train, y_train_df, how=\"inner\", left_index=True, right_index=True)\n",
    "train_compradores = train.loc[train[\"label\"] == 1]\n",
    "train_dup = pd.concat([train, train_compradores], ignore_index=True)\n",
    "X_train, y_train = train_dup.drop(columns=\"label\"), train_dup[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1305,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, eval_metric = \"auc\", min_child_weight=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=1, missing=None,\n",
       "       n_estimators=6, n_jobs=1, nthread=None, objective='binary:hinge',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 1306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1307,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1308,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.5872576177285319\n",
      "Test acuracy:  0.5687150837988827\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.56      0.72      1733\n",
      "         1.0       0.06      0.84      0.11        57\n",
      "\n",
      "   micro avg       0.57      0.57      0.57      1790\n",
      "   macro avg       0.52      0.70      0.41      1790\n",
      "weighted avg       0.96      0.57      0.70      1790\n",
      "\n",
      "\n",
      "Precision Score:  0.059186189889025895\n",
      "Recall Score:  0.8421052631578947\n",
      "F1 Score:  0.11059907834101382\n",
      "Cohen Kappa Score:  0.054326864513373874\n",
      "ROC auc score:  0.7009141434081453\n",
      "Confusion matrix: \n",
      "[[970 763]\n",
      " [  9  48]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\\\n",
    "                            f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "# Pruebo todas las metricas.\n",
    "# accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\n",
    "# f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "\n",
    "trainAccuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "testAccuracy = accuracy_score(y_test, preds)\n",
    "\n",
    "meanSquaredError = mean_squared_error(y_test, preds)\n",
    "classificationReport = classification_report(y_test, preds)\n",
    "precisionScore = precision_score(y_test, preds)\n",
    "recallScore = recall_score(y_test, preds)\n",
    "f1Score = f1_score(y_test, preds)\n",
    "cohenKappaScore = cohen_kappa_score(y_test, preds)\n",
    "areaDebajoDeCurva = roc_auc_score(y_test, preds)\n",
    "matrizDeConfusion = confusion_matrix(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", trainAccuracy)\n",
    "print(\"Test acuracy: \", testAccuracy)\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(classificationReport)\n",
    "print()\n",
    "print(\"Precision Score: \",precisionScore)\n",
    "print(\"Recall Score: \",recallScore)\n",
    "print(\"F1 Score: \",f1Score)\n",
    "print(\"Cohen Kappa Score: \",cohenKappaScore)\n",
    "print(\"ROC auc score: \", areaDebajoDeCurva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matrizDeConfusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------- Borrador -----------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.plot_importance(xg_reg)\n",
    "plt.rcParams['figure.figsize'] = [10, 10]\n",
    "plt.show()\n",
    "\n",
    "objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, eval_metric = \"auc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"objective\":\"binary:hinge\",'colsample_bytree': 0.8,\n",
    "          'learning_rate': 0.1, 'max_depth': 5, \"n_estimators\" : 6}\n",
    "\n",
    "cv_results = xgb.cv(dtrain=data_dmatrix, params=params, nfold=10,\n",
    "                    num_boost_round=10,\n",
    "                    metrics=\"auc\", as_pandas=True, seed=123);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv_results.sort_values(\"train-auc-mean\", ascending=False)\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_test = pd.read_csv(\"trocafone_kaggle_test.csv\")\n",
    "tf_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cantidad de entradas desde campaas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>criteo</th>\n",
       "      <th>emblue</th>\n",
       "      <th>google</th>\n",
       "      <th>rtbhouse</th>\n",
       "      <th>zanox</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00091926</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091a7a</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000ba417</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000c79fe</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000e4d9e</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  criteo  emblue  google  rtbhouse  zanox\n",
       "0  00091926     1.0     0.0    13.0       1.0    0.0\n",
       "1  00091a7a     0.0     0.0     1.0       0.0    0.0\n",
       "2  000ba417     0.0     0.0     1.0       0.0    0.0\n",
       "3  000c79fe     0.0     0.0     1.0       0.0    0.0\n",
       "4  000e4d9e     0.0     0.0     4.0       0.0    9.0"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_events_campaign = df[['person','campaign_source']].dropna()\n",
    "\n",
    "\n",
    "top_5_campanias = df_events_campaign['campaign_source'].value_counts().head(5).index\n",
    "df_events_campaign = df_events_campaign.loc[df_events_campaign['campaign_source'].isin(top_5_campanias)]\n",
    "df_events_campaign = pd.concat([df_events_campaign['person'],\\\n",
    "        pd.get_dummies(df_events_campaign['campaign_source'])],axis = 1).groupby('person').sum().reset_index()\n",
    "\n",
    "df_events_campaign = pd.merge(df_events_campaign, todas_las_personas, on=\"person\", how=\"right\").fillna(0)\n",
    "\n",
    "\n",
    "df_events_campaign.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veo cuantas personas a predecir pierdo\n",
    "df_events_campaign_predecir = pd.merge(df_events_campaign, df_persons, on=\"person\", how=\"inner\")\n",
    "df_events_campaign_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>criteo</th>\n",
       "      <th>emblue</th>\n",
       "      <th>google</th>\n",
       "      <th>rtbhouse</th>\n",
       "      <th>zanox</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>...</th>\n",
       "      <th>cant_eng</th>\n",
       "      <th>cant_mod</th>\n",
       "      <th>cant_ev</th>\n",
       "      <th>check_tot</th>\n",
       "      <th>cant_entradas</th>\n",
       "      <th>cant_mes_5</th>\n",
       "      <th>entradas_30_dias</th>\n",
       "      <th>cant_mes</th>\n",
       "      <th>cant_dia_freq</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>63</td>\n",
       "      <td>189</td>\n",
       "      <td>15</td>\n",
       "      <td>471</td>\n",
       "      <td>290</td>\n",
       "      <td>358</td>\n",
       "      <td>290</td>\n",
       "      <td>72</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>54</td>\n",
       "      <td>64</td>\n",
       "      <td>54</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>54</td>\n",
       "      <td>5</td>\n",
       "      <td>26</td>\n",
       "      <td>46</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>38</td>\n",
       "      <td>26</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   criteo  emblue  google  rtbhouse  zanox    0    1    2    3    4  ...    \\\n",
       "0     0.0     0.0     1.0       0.0    0.0  0.0  1.0  0.0  0.0  0.0  ...     \n",
       "1     5.0     0.0    17.0       7.0    0.0  3.0  6.0  2.0  2.0  3.0  ...     \n",
       "2     3.0     0.0     4.0       0.0    0.0  0.0  3.0  6.0  3.0  0.0  ...     \n",
       "3     2.0     0.0    10.0       0.0    0.0  0.0  1.0  0.0  2.0  0.0  ...     \n",
       "4     0.0     0.0     2.0       0.0    0.0  0.0  0.0  0.0  1.0  1.0  ...     \n",
       "\n",
       "   cant_eng  cant_mod  cant_ev  check_tot  cant_entradas  cant_mes_5  \\\n",
       "0         1         4        9          1             17          17   \n",
       "1        12        63      189         15            471         290   \n",
       "2         6        20       52          1             96          54   \n",
       "3        10         8       17          3             54           5   \n",
       "4         1         3       17          1             38          26   \n",
       "\n",
       "   entradas_30_dias  cant_mes  cant_dia_freq  label  \n",
       "0                16        17             17      0  \n",
       "1               358       290             72      0  \n",
       "2                64        54             17      0  \n",
       "3                26        46             22      0  \n",
       "4                25        26             26      0  \n",
       "\n",
       "[5 rows x 93 columns]"
      ]
     },
     "execution_count": 405,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge\n",
    "labels_con_camps = pd.merge(df_events_campaign, labels_con_dia_semana, on=\"person\", how=\"inner\")\n",
    "labels_con_camps_num = labels_con_camps.drop(columns=\"person\")\n",
    "labels_con_camps_num.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = labels_con_camps_num.iloc[:,:-1], labels_con_camps_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y, weight={1: 1, 0: 0.1})\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, eval_metric = \"auc\", min_child_weight=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=1000, missing=None,\n",
       "       n_estimators=6, n_jobs=1, nthread=None, objective='binary:hinge',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 408,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8869953904176561\n",
      "Test acuracy:  0.8748603351955307\n",
      "ROC auc score:  0.5785714285714286\n",
      "Confusion matrix: \n",
      "[[1548  172]\n",
      " [  52   18]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos \n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cantidad de visitas a productos Apple y Samsung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>vistas_samsung</th>\n",
       "      <th>vistas_apple</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6abd2bf1</td>\n",
       "      <td>2051.0</td>\n",
       "      <td>2051.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b1f4dbf6</td>\n",
       "      <td>1866.0</td>\n",
       "      <td>1866.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9bf968c5</td>\n",
       "      <td>1557.0</td>\n",
       "      <td>1557.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bfb74b38</td>\n",
       "      <td>1526.0</td>\n",
       "      <td>1526.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6f19cfd9</td>\n",
       "      <td>1442.0</td>\n",
       "      <td>1442.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  vistas_samsung  vistas_apple\n",
       "0  6abd2bf1          2051.0        2051.0\n",
       "1  b1f4dbf6          1866.0        1866.0\n",
       "2  9bf968c5          1557.0        1557.0\n",
       "3  bfb74b38          1526.0        1526.0\n",
       "4  6f19cfd9          1442.0        1442.0"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_productos = df[[\"person\", \"event\", \"model\"]]\n",
    "df_productos = df_productos.loc[df_productos[\"event\"] == \"viewed product\"]\n",
    "df_productos = df_productos.loc[(df_productos[\"model\"].str.contains(\"iPhone\") )|( df_productos[\"model\"].str.contains(\"Samsung\") )]\n",
    "df_productos.head()\n",
    "\n",
    "df_apple = df_productos.loc[df_productos[\"model\"].str.contains(\"iPhone\")]\n",
    "df_samsung = df_productos.loc[df_productos[\"model\"].str.contains(\"Samsung\")]                           \n",
    "\n",
    "vistas_apple = df_apple[\"person\"].value_counts().reset_index()\n",
    "vistas_apple.columns = [\"person\", \"vistas_apple\"]\n",
    "\n",
    "vistas_samsung = df_apple[\"person\"].value_counts().reset_index()\n",
    "vistas_samsung.columns = [\"person\", \"vistas_samsung\"]\n",
    "\n",
    "vistas_prods = pd.merge(vistas_samsung, vistas_apple, on=\"person\", how=\"inner\")\n",
    "\n",
    "vistas_prods = pd.merge(vistas_prods, todas_las_personas, on=\"person\", how=\"right\").fillna(0)\n",
    "\n",
    "vistas_prods.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 366,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veo cuantas personas a predecir pierdo\n",
    "vistas_prods_predecir = pd.merge(vistas_prods, df_persons, on=\"person\", how=\"inner\")\n",
    "vistas_prods_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge\n",
    "\n",
    "df_con_vistas_prods = pd.merge(vistas_prods,labels_con_dia_semana, on=\"person\", how=\"inner\")\n",
    "\n",
    "df_con_vistas_prods_num = df_con_vistas_prods.drop(columns=\"person\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = df_con_vistas_prods_num.iloc[:,:-1], df_con_vistas_prods_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y)\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=6,\n",
       "       n_jobs=1, nthread=None, objective='binary:hinge', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.9113004609582344\n",
      "Test acuracy:  0.9016759776536313\n",
      "ROC auc score:  0.582583419606594\n",
      "Confusion matrix: \n",
      "[[1600  132]\n",
      " [  44   14]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos \n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cantidad de busquedas en 'searched products' y 'search engine hit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_search = df.loc[(df[\"event\"] == \"searched products\" )| (df[\"event\"] == \"search engine hit\" )]\n",
    "\n",
    "searched_products = df_search.loc[df_search[\"event\"] == \"searched products\"]\n",
    "cant_searched_products = searched_products[\"person\"].value_counts().reset_index()\n",
    "cant_searched_products.columns = [\"person\", \"cant_search_prod\"]\n",
    "\n",
    "engine_hit = df_search.loc[df_search[\"event\"] == \"search engine hit\"]\n",
    "cant_engine_hit = engine_hit[\"person\"].value_counts().reset_index()\n",
    "cant_engine_hit.columns = [\"person\", \"cant_engine_hit\"]\n",
    "\n",
    "cant_busquedas = pd.merge(cant_engine_hit, cant_searched_products, on=\"person\", how=\"inner\")\n",
    "\n",
    "cant_busquedas = pd.merge(cant_busquedas, todas_las_personas, on=\"person\", how=\"right\").fillna(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veo cuantas personas a predecir pierdo\n",
    "cant_busquedas_predecir = pd.merge(cant_busquedas, df_persons, on=\"person\", how=\"inner\")\n",
    "cant_busquedas_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cant_engine_hit</th>\n",
       "      <th>cant_search_prod</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>Chrome 65.0</th>\n",
       "      <th>...</th>\n",
       "      <th>cant_eng</th>\n",
       "      <th>cant_mod</th>\n",
       "      <th>cant_ev</th>\n",
       "      <th>check_tot</th>\n",
       "      <th>cant_entradas</th>\n",
       "      <th>cant_mes_5</th>\n",
       "      <th>entradas_30_dias</th>\n",
       "      <th>cant_mes</th>\n",
       "      <th>cant_dia_freq</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>245.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>245</td>\n",
       "      <td>170</td>\n",
       "      <td>744</td>\n",
       "      <td>47</td>\n",
       "      <td>2006</td>\n",
       "      <td>388</td>\n",
       "      <td>378</td>\n",
       "      <td>861</td>\n",
       "      <td>198</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>136.0</td>\n",
       "      <td>739.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>136</td>\n",
       "      <td>61</td>\n",
       "      <td>739</td>\n",
       "      <td>10</td>\n",
       "      <td>1609</td>\n",
       "      <td>1609</td>\n",
       "      <td>1608</td>\n",
       "      <td>1609</td>\n",
       "      <td>191</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>130.0</td>\n",
       "      <td>214.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>130</td>\n",
       "      <td>87</td>\n",
       "      <td>214</td>\n",
       "      <td>4</td>\n",
       "      <td>855</td>\n",
       "      <td>760</td>\n",
       "      <td>759</td>\n",
       "      <td>760</td>\n",
       "      <td>138</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>102.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>102</td>\n",
       "      <td>130</td>\n",
       "      <td>450</td>\n",
       "      <td>2</td>\n",
       "      <td>1025</td>\n",
       "      <td>103</td>\n",
       "      <td>105</td>\n",
       "      <td>585</td>\n",
       "      <td>102</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93.0</td>\n",
       "      <td>121.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>...</td>\n",
       "      <td>93</td>\n",
       "      <td>416</td>\n",
       "      <td>692</td>\n",
       "      <td>17</td>\n",
       "      <td>1593</td>\n",
       "      <td>412</td>\n",
       "      <td>420</td>\n",
       "      <td>956</td>\n",
       "      <td>216</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  90 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cant_engine_hit  cant_search_prod     0     1     2     3     4     5  \\\n",
       "0            245.0               3.0  22.0  15.0  22.0  16.0  28.0  19.0   \n",
       "1            136.0             739.0   9.0   8.0  14.0  13.0   6.0  10.0   \n",
       "2            130.0             214.0  18.0  14.0  12.0  14.0   7.0   9.0   \n",
       "3            102.0               2.0  17.0  21.0  24.0  24.0  21.0  14.0   \n",
       "4             93.0             121.0  26.0  23.0  33.0  20.0  33.0  23.0   \n",
       "\n",
       "      6  Chrome 65.0  ...    cant_eng  cant_mod  cant_ev  check_tot  \\\n",
       "0  19.0          4.0  ...         245       170      744         47   \n",
       "1   6.0          0.0  ...         136        61      739         10   \n",
       "2  12.0          0.0  ...         130        87      214          4   \n",
       "3  14.0         29.0  ...         102       130      450          2   \n",
       "4   7.0         56.0  ...          93       416      692         17   \n",
       "\n",
       "   cant_entradas  cant_mes_5  entradas_30_dias  cant_mes  cant_dia_freq  label  \n",
       "0           2006         388               378       861            198      0  \n",
       "1           1609        1609              1608      1609            191      0  \n",
       "2            855         760               759       760            138      0  \n",
       "3           1025         103               105       585            102      0  \n",
       "4           1593         412               420       956            216      0  \n",
       "\n",
       "[5 rows x 90 columns]"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge\n",
    "\n",
    "labels_con_busq = pd.merge(cant_busquedas, labels_con_dia_semana, on=\"person\", how=\"inner\")\n",
    "labels_con_busq_num = labels_con_busq.drop(columns=\"person\")\n",
    "labels_con_busq_num.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = labels_con_busq_num.iloc[:,:-1], labels_con_busq_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y)\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, scale_pos_weight = 100, min_child_weight=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1000, missing=None, n_estimators=6,\n",
       "       n_jobs=1, nthread=None, objective='binary:hinge', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=100, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8112864925268892\n",
      "Test acuracy:  0.8011173184357542\n",
      "ROC auc score:  0.6384819951317123\n",
      "Confusion matrix: \n",
      "[[1403  320]\n",
      " [  36   31]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos \n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### duplico compradores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1022,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = labels_con_busq_num.iloc[:,:-1], labels_con_busq_num.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y, weight={1: 1, 0: 0.1})\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1023,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Duplico los compradores\n",
    "\n",
    "y_train_df = y_train.to_frame()\n",
    "X_train_df = X_train.reset_index()\n",
    "train = pd.merge(X_train, y_train_df, how=\"inner\", left_index=True, right_index=True)\n",
    "train_compradores = train.loc[train[\"label\"] == 1]\n",
    "train_dup = pd.concat([train, train_compradores], ignore_index=True)\n",
    "X_train, y_train = train_dup.drop(columns=\"label\"), train_dup[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1024,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBRegressor(objective ='binary:hinge', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, eval_metric = \"auc\", min_child_weight=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1025,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=1, missing=None,\n",
       "       n_estimators=6, n_jobs=1, nthread=None, objective='binary:hinge',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 1025,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1026,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1027,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.7886639676113361\n",
      "Test acuracy:  0.764804469273743\n",
      "ROC auc score:  0.6339645359967429\n",
      "Confusion matrix: \n",
      "[[1336  387]\n",
      " [  34   33]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos \n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1028,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.7886639676113361\n",
      "Test acuracy:  0.764804469273743\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.78      0.86      1723\n",
      "           1       0.08      0.49      0.14        67\n",
      "\n",
      "   micro avg       0.76      0.76      0.76      1790\n",
      "   macro avg       0.53      0.63      0.50      1790\n",
      "weighted avg       0.94      0.76      0.84      1790\n",
      "\n",
      "\n",
      "Precision Score:  0.07857142857142857\n",
      "Recall Score:  0.4925373134328358\n",
      "F1 Score:  0.135523613963039\n",
      "Cohen Kappa Score:  0.07585995462628004\n",
      "ROC auc score:  0.6339645359967429\n",
      "Confusion matrix: \n",
      "[[1336  387]\n",
      " [  34   33]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\\\n",
    "                            f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "# Pruebo todas las metricas.\n",
    "# accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\n",
    "# f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "\n",
    "trainAccuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "testAccuracy = accuracy_score(y_test, preds)\n",
    "\n",
    "meanSquaredError = mean_squared_error(y_test, preds)\n",
    "classificationReport = classification_report(y_test, preds)\n",
    "precisionScore = precision_score(y_test, preds)\n",
    "recallScore = recall_score(y_test, preds)\n",
    "f1Score = f1_score(y_test, preds)\n",
    "cohenKappaScore = cohen_kappa_score(y_test, preds)\n",
    "areaDebajoDeCurva = roc_auc_score(y_test, preds)\n",
    "matrizDeConfusion = confusion_matrix(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", trainAccuracy)\n",
    "print(\"Test acuracy: \", testAccuracy)\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(classificationReport)\n",
    "print()\n",
    "print(\"Precision Score: \",precisionScore)\n",
    "print(\"Recall Score: \",recallScore)\n",
    "print(\"F1 Score: \",f1Score)\n",
    "print(\"Cohen Kappa Score: \",cohenKappaScore)\n",
    "print(\"ROC auc score: \", areaDebajoDeCurva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matrizDeConfusion)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
