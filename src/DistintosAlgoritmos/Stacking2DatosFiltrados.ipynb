{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebo Stacking con los datos filtrados#\n",
    "\n",
    "El stack consiste de los siguientes modelos como 1º paso:\n",
    "\n",
    "    RandomForestClassifier\n",
    "\n",
    "    ExtraTreesClassifier\n",
    "\n",
    "    AdaBoostClassifier\n",
    "\n",
    "    GradientBoostingClassifier\n",
    "    \n",
    "    XGBClassifier\n",
    "    \n",
    "Y como 2º paso MLPClassifier\n",
    "\n",
    "Uso Random under sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in our libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import sklearn\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.metrics import SCORERS\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "# Going to use these 5 base models for the stacking\n",
    "from sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, \n",
    "                              GradientBoostingClassifier, ExtraTreesClassifier)\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.kernel_approximation import RBFSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargo los Features###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_f = pd.read_csv('../../data/labels_f_filtrado.csv')\n",
    "datos = pd.read_csv('../../data/datos_filtrado.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "atributos = labels_f.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "atributos.remove('person')\n",
    "atributos.remove('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = labels_f['label'].ravel()\n",
    "X = labels_f.loc[:,atributos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MaxAbsScaler().fit(X)\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_feature = RBFSampler(gamma=2,n_components= 300, random_state=123)\n",
    "X = rbf_feature.fit_transform(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicarSmote(X_train, y_train):\n",
    "    smote = SMOTE(ratio='minority')\n",
    "    X_smt_train, y_smt_train = smote.fit_sample(X_train, y_train)\n",
    "    return (X_smt_train, y_smt_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicarRus(X_train_p, y_train_p):\n",
    "    rus= RandomUnderSampler(return_indices=True)\n",
    "    #id_rus son los índices\n",
    "    X_rus_train, y_rus_train, id_rus = rus.fit_sample(X_train_p, y_train_p)\n",
    "    return(X_rus_train, y_rus_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.1, random_state= 123, stratify = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = aplicarRus(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrain = X_train.shape[0]\n",
    "ntest = X_test.shape[0]\n",
    "SEED = 0 # for reproducibility\n",
    "NFOLDS = 5 # set folds for out-of-fold prediction\n",
    "class SklearnHelper(object):\n",
    "    def __init__(self, clf, seed=0, params=None):\n",
    "        params['random_state'] = seed\n",
    "        self.clf = clf(**params)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        self.clf.fit(x_train, y_train)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.clf.predict(x)\n",
    "    \n",
    "    def fit(self,x,y):\n",
    "        return self.clf.fit(x,y)\n",
    "    \n",
    "    def feature_importances(self,x,y):\n",
    "        print(self.clf.fit(x,y).feature_importances_)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'    \\n    for i,(train_index, test_index) in enumerate(kf.split(X_transformed)):\\n        x_train, x_test = X_transformed[train_index], X_transformed[test_index]\\n        y_train, y_test = y[train_index], y[test_index]\\n        try:\\n            x_tr = x_train[train_index]\\n            y_tr = y_train[train_index]\\n            x_te = x_train[test_index]\\n            \\n'"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"    \n",
    "    for i,(train_index, test_index) in enumerate(kf.split(X_transformed)):\n",
    "        x_train, x_test = X_transformed[train_index], X_transformed[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        try:\n",
    "            x_tr = x_train[train_index]\n",
    "            y_tr = y_train[train_index]\n",
    "            x_te = x_train[test_index]\n",
    "            \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_oof(clf, x_train_p, y_train_p, x_test_p):\n",
    "    oof_train = np.zeros((ntrain,))\n",
    "    oof_test = np.zeros((ntest,))\n",
    "    oof_test_skf = np.empty((NFOLDS, ntest))\n",
    "    \n",
    "    kf = KFold(n_splits= NFOLDS, random_state=SEED)\n",
    "    kf = kf.split(x_train_p)\n",
    "    i = 0\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf):\n",
    "        x_tr = x_train_p[train_index]\n",
    "        y_tr = y_train_p[train_index]\n",
    "        x_te = x_train_p[test_index]\n",
    "        clf.fit(x_tr, y_tr)\n",
    "        oof_train[test_index] = clf.predict(x_te)\n",
    "        oof_test_skf[i, :] = clf.predict(x_test_p)\n",
    "        i+=1\n",
    "        #print(i)\n",
    "\n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_params = {'bootstrap': True, 'class_weight': None, 'criterion': 'gini',\n",
    "            'max_depth': 9, 'max_features': 'auto', 'max_leaf_nodes': None,\n",
    "            'min_impurity_decrease': 0.0, 'min_impurity_split': None,\n",
    "            'min_samples_leaf': 1, 'min_samples_split': 2,\n",
    "            'min_weight_fraction_leaf': 0.0, 'n_estimators': 1444, 'n_jobs': None,\n",
    "            'oob_score': False, 'verbose': 0,\n",
    "            'warm_start': False\n",
    "}#'n_jobs': -1,\n",
    "\n",
    "# Extra Trees Parameters\n",
    "et_params = {'bootstrap': False, 'class_weight': None, 'criterion': 'gini',\n",
    "          'max_depth': 100, 'max_features': 'auto','max_leaf_nodes': None,\n",
    "           'min_impurity_decrease': 0.0, 'min_impurity_split': None,\n",
    "           'min_samples_leaf': 5, 'min_samples_split': 5,\n",
    "           'min_weight_fraction_leaf': 0.0, 'n_estimators': 200,'n_jobs': 4}\n",
    "\n",
    "# AdaBoost parameters\n",
    "ada_params = {'algorithm': 'SAMME.R', 'base_estimator': None,\n",
    "          'learning_rate': 0.01, 'n_estimators': 977, 'random_state': None}\n",
    "\n",
    "# Gradient Boosting parameters\n",
    "gb_params = {\n",
    "    'n_estimators': 500,\n",
    "    'max_depth': 5,\n",
    "    'min_samples_leaf': 2,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "xgb_params = {'colsample_bylevel': 0.8805332918491438, 'colsample_bytree': 0.9352504152264935, 'gamma': 9.881437744998433e-06, 'learning_rate': 0.19933863096197899, 'max_delta_step': 6, 'max_depth': 18, 'min_child_weight': 3, 'n_estimators': 61, 'reg_alpha': 7.871401820904661e-05, 'reg_lambda': 1000.0, 'scale_pos_weight': 5.390140010639928, 'subsample': 1.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 5 objects that represent our 4 models\n",
    "rf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\n",
    "et = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\n",
    "ada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\n",
    "gb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\n",
    "xgb =  SklearnHelper(clf=XGBClassifier, seed=SEED, params=xgb_params)\n",
    "#svc = SklearnHelper(clf=SVC, seed=SEED, params=svc_params)\n",
    "#nn = SklearnHelper(clf = MLPClassifier, seed = SEED, params = nn_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is complete\n"
     ]
    }
   ],
   "source": [
    "# Create our OOF train and test predictions. These base results will be used as new features\n",
    "et_oof_train, et_oof_test = get_oof(et, X_train, y_train, X_test) # Extra Trees\n",
    "rf_oof_train, rf_oof_test = get_oof(rf,X_train, y_train, X_test) # Random Forest\n",
    "ada_oof_train, ada_oof_test = get_oof(ada, X_train, y_train, X_test) # AdaBoost \n",
    "gb_oof_train, gb_oof_test = get_oof(gb,X_train, y_train, X_test) # Gradient Boost\n",
    "xgb_oof_train,xgb_oof_test = get_oof(xgb,X_train, y_train, X_test) # Support Vector Classifier\n",
    "#nn_oof_train, nn_oof_test = get_oof(nn,X_train, y_train, X_test)\n",
    "print(\"Training is complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.concatenate(( et_oof_train, rf_oof_train, ada_oof_train, gb_oof_train,xgb_oof_train ), axis=1) #\n",
    "x_test = np.concatenate(( et_oof_test, rf_oof_test, ada_oof_test, gb_oof_test,xgb_oof_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = MLPClassifier( early_stopping=False, random_state=123).fit(x_train, y_train)#, early_stopping_rounds = 5, eval_set=[(x_test, y_test)])\n",
    "#bag_class =BaggingClassifier(nn).fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acurracy: \n",
      "0.6649659863945578\n",
      "test acurracy: \n",
      "0.586508753861998\n",
      "Matriz de confusión: \n",
      "[[1054  790]\n",
      " [  13   85]]\n",
      "Área bajo la curva: \n",
      "0.7585937845854177\n"
     ]
    }
   ],
   "source": [
    "preds = nn.predict(x_test)\n",
    "preds_prob = nn.predict_proba(x_test)[:,1]\n",
    "train_accuracy = accuracy_score(y_train, bag_class.predict(x_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds_prob)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "print('train acurracy: ')\n",
    "print(train_accuracy)\n",
    "print('test acurracy: ')\n",
    "print(test_accuracy)\n",
    "print('Matriz de confusión: ')\n",
    "print(matriz_de_confusion)\n",
    "print('Área bajo la curva: ')\n",
    "print(area_debajo_de_curva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
