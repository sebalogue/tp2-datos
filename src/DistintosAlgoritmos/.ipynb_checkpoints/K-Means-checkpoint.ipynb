{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import SCORERS\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import DistanceMetric\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from mlens.ensemble import SuperLearner \n",
    "\n",
    "from itertools import combinations\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "from sklearn.kernel_approximation import AdditiveChi2Sampler\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "from sklearn.cluster import KMeans\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = pd.read_csv('featuresMagui.csv') #mis features \n",
    "tf_seba = pd.read_csv('features_seba.csv') #los features de Seba\n",
    "tf_santi = pd.read_csv('santi_timefeatures.csv')\n",
    "tf_santi_2 = pd.read_csv('Santi_FeaturesConEventos.csv')\n",
    "#tf_2 = pd.read_csv('featuresMagui2.csv')\n",
    "labels = pd.read_csv('../data/labels_training_set.csv') #las personas de las cuales tengo Info\n",
    "personas =pd.read_csv('../data/trocafone_kaggle_test.csv') #las personas a las que le tengo que predecir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datos a entregar\n",
    "datos = pd.merge(tf, tf_seba, on = 'person', how = 'inner')\n",
    "datos = pd.merge(datos, tf_santi, on = 'person', how = 'inner')\n",
    "datos = pd.merge(datos, tf_santi_2, on = 'person', how = 'inner')\n",
    "#datos = pd.merge(datos, tf_2, on = 'person', how = 'inner')\n",
    "datos = pd.merge(personas, datos, on = 'person', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Datos para entrenar\n",
    "labels_f = pd.merge(tf,tf_seba, on = 'person',how = 'inner')\n",
    "labels_f = pd.merge(labels_f,tf_santi, on = 'person',how = 'inner')\n",
    "labels_f = pd.merge(labels_f,tf_santi_2, on = 'person',how = 'inner')\n",
    "#labels_f = pd.merge(labels_f,tf_2, on = 'person',how = 'inner')\n",
    "labels_f = pd.merge(labels, labels_f, on = 'person', how = 'inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['person', 'label', 'Unnamed: 0_x', 'esNuevo', 'cantidadDeVisitas',\n",
       "       'ingresoPorPublicidad', 'Facebook', 'FacebookAds', 'FacebookSocial',\n",
       "       'MARKETING SOCIAL',\n",
       "       ...\n",
       "       'adcampaignhit_bing', 'adcampaignhit_afilio', 'adcampaignhit_buscape',\n",
       "       'adcampaignhit_rakuten', 'adcampaignhit_FacebookAds',\n",
       "       'adcampaignhit_indexa', 'adcampaignhit_datacrush',\n",
       "       'adcampaignhit_emblue', 'adcampaignhit_blog', 'adcampaignhit_yotpo'],\n",
       "      dtype='object', length=406)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_f.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#labels_f  = labels_f.drop('viewed product', axis = 1)\n",
    "#print('viewed product' in labels_f.columns.tolist())\n",
    "y = labels_f.iloc[:,1:2]\n",
    "X = labels_f.iloc[:,3: 406]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "X = X.drop('device_type', axis = 1)\n",
    "print('viewed product' in X.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_feature = RBFSampler(gamma=2,n_components= 300, random_state=123)\n",
    "X_features = rbf_feature.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters=10, init='k-means++', n_init=3, max_iter=300, precompute_distances= True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "km.fit(X_features)\n",
    "X_means = km.transform(X_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = preprocessing.StandardScaler().fit(X_features)#(X_means)\n",
    "X_transformed = scaler.transform(X_features)#(X_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size= 0.1, random_state= 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicarSmote(X_train, y_train):\n",
    "    smote = SMOTE(ratio='minority')\n",
    "    X_smt_train, y_train = smote.fit_sample(X_train, y_train)\n",
    "    return (X_smt_train, y_smt_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicarRUS(X_Train, y_train):\n",
    "    rus= RandomUnderSampler(return_indices=True)\n",
    "    #id_rus son los índices\n",
    "    X_train, y_train, id_rus = rus.fit_sample(X_train, y_train)\n",
    "    return(X_rus_train, y_rus_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicarModelo(modelo,X_train, X_test, y_train, y_test):\n",
    "    modelo.fit(X_train, y_train)#, early_stopping_rounds = 5, eval_set=[(X_test, y_test)])\n",
    "    preds = modelo.predict(X_test)\n",
    "    preds_prob = modelo.predict_proba(X_test)[:,1]\n",
    "    train_accuracy = accuracy_score(y_train, modelo.predict(X_train))\n",
    "    test_accuracy = accuracy_score(y_test, preds)\n",
    "    area_debajo_de_curva = roc_auc_score(y_test, preds_prob)\n",
    "    matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "    print('train acurracy: ')\n",
    "    print(train_accuracy)\n",
    "    print('test acurracy: ')\n",
    "    print(test_accuracy)\n",
    "    print('Matriz de confusión: ')\n",
    "    print(matriz_de_confusion)\n",
    "    print('Área bajo la curva: ')\n",
    "    print(area_debajo_de_curva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/svm/base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acurracy: \n",
      "0.949290293040293\n",
      "test acurracy: \n",
      "0.9515962924819773\n",
      "Matriz de confusión: \n",
      "[[1848    0]\n",
      " [  94    0]]\n",
      "Área bajo la curva: \n",
      "0.455420466058764\n"
     ]
    }
   ],
   "source": [
    "# fit the model and get the separating hyperplane using weighted classes\n",
    "clf = svm.SVC(kernel='rbf', probability = True)\n",
    "\n",
    "aplicarModelo(clf,X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=22)\n",
    "aplicarModelo(knn,X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = MLPClassifier( early_stopping=False, random_state=123)\n",
    "\n",
    "aplicarModelo(nn,X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
