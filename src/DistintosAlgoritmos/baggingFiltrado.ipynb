{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebo Bagging con distintos algoritmos #\n",
    "\n",
    "Datos Filtrados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import SCORERS\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import DistanceMetric\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.under_sampling import ClusterCentroids\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from mlens.ensemble import SuperLearner \n",
    "\n",
    "from itertools import combinations\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import svm\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.kernel_approximation import RBFSampler\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_f = pd.read_csv('labels_f_filtrado.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos = pd.read_csv('datos_filtrado.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "atributos = labels_f.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "atributos.remove('person')\n",
    "atributos.remove('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = labels_f['label']#.ravel()\n",
    "X = labels_f.loc[:,atributos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MaxAbsScaler().fit(X)\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicarSmote(X_train_p, y_train_p, X_test):\n",
    "    smote = SMOTE(ratio='minority')\n",
    "    X_smt_train, y_smt_train = smote.fit_sample(X_train_p, y_train_p)\n",
    "    #X_smt_train = pd.DataFrame(X_smt_train)\n",
    "    #X_smt_train.columns = X_test.columns\n",
    "    return (X_smt_train, y_smt_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicarRus(X_train_p, y_train_p,X_test_p):\n",
    "    rus= RandomUnderSampler(return_indices=True)\n",
    "    #id_rus son los índices\n",
    "    X_rus_train, y_rus_train, id_rus = rus.fit_sample(X_train_p, y_train_p)\n",
    "    #X_rus_train = pd.DataFrame(X_rus_train)\n",
    "    #X_rus_train.columns = X_test_p.columns\n",
    "    return(X_rus_train, y_rus_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.1, random_state= 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, y_train = aplicarRus(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rus_train, y_rus_train = aplicarRus(X_train,y_train,X_test)\n",
    "X_smt_train, y_smt_train = aplicarSmote(X_train,y_train,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicarModelo(modelo,X_train_p, X_test_p, y_train_p, y_test_p, early = False):\n",
    "    if(early):\n",
    "        modelo.fit(X_train_p, y_train_p, early_stopping_rounds = 5, eval_set=[(X_test_p, y_test_p)])\n",
    "    else: \n",
    "        modelo.fit(X_train_p, y_train_p)\n",
    "    \n",
    "    preds = modelo.predict(X_test_p)\n",
    "    preds_prob = modelo.predict_proba(X_test_p)[:,1]\n",
    "    train_accuracy = accuracy_score(y_train_p, modelo.predict(X_train_p))\n",
    "    test_accuracy = accuracy_score(y_test_p, preds)\n",
    "    area_debajo_de_curva = roc_auc_score(y_test_p, preds_prob)\n",
    "    matriz_de_confusion = confusion_matrix(y_test_p, preds)\n",
    "    print('train acurracy: ')\n",
    "    print(train_accuracy)\n",
    "    print('test acurracy: ')\n",
    "    print(test_accuracy)\n",
    "    print('Matriz de confusión: ')\n",
    "    print(matriz_de_confusion)\n",
    "    print('Área bajo la curva: ')\n",
    "    print(area_debajo_de_curva)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pruebo con XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APLICO SMOTE\n",
      "[0]\tvalidation_0-error:0.371782\n",
      "Will train until validation_0-error hasn't improved in 5 rounds.\n",
      "[1]\tvalidation_0-error:0.357364\n",
      "[2]\tvalidation_0-error:0.364058\n",
      "[3]\tvalidation_0-error:0.363543\n",
      "[4]\tvalidation_0-error:0.346035\n",
      "[5]\tvalidation_0-error:0.345005\n",
      "train acurracy: \n",
      "0.8153563246111178\n",
      "test acurracy: \n",
      "0.654994850669413\n",
      "Matriz de confusión: \n",
      "[[1193  655]\n",
      " [  15   79]]\n",
      "Área bajo la curva: \n",
      "0.826701667127199\n",
      "\n",
      "APLICO RUS\n",
      "[0]\tvalidation_0-error:0.446447\n",
      "Will train until validation_0-error hasn't improved in 5 rounds.\n",
      "[1]\tvalidation_0-error:0.554583\n",
      "[2]\tvalidation_0-error:0.528836\n",
      "[3]\tvalidation_0-error:0.515448\n",
      "[4]\tvalidation_0-error:0.522142\n",
      "[5]\tvalidation_0-error:0.511843\n",
      "Stopping. Best iteration:\n",
      "[0]\tvalidation_0-error:0.446447\n",
      "\n",
      "train acurracy: \n",
      "0.7533860045146726\n",
      "test acurracy: \n",
      "0.5535530381050463\n",
      "Matriz de confusión: \n",
      "[[988 860]\n",
      " [  7  87]]\n",
      "Área bajo la curva: \n",
      "0.8238924196371005\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xg_reg = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, scale_pos_weight = 7, min_child_weight=15)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('APLICO SMOTE')\n",
    "aplicarModelo(xg_reg,X_smt_train, X_test, y_smt_train, y_test, True)\n",
    "print('APLICO RUS')\n",
    "aplicarModelo(xg_reg,X_rus_train, X_test, y_rus_train, y_test, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pruebo un Bagging de XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APLICO SMOTE\n",
      "train acurracy: \n",
      "0.8030567948872543\n",
      "test acurracy: \n",
      "0.6318228630278064\n",
      "Matriz de confusión: \n",
      "[[1146  702]\n",
      " [  13   81]]\n",
      "Área bajo la curva: \n",
      "0.823420373952289\n",
      "\n",
      "APLICO RUS\n",
      "train acurracy: \n",
      "0.739841986455982\n",
      "test acurracy: \n",
      "0.4979402677651905\n",
      "Matriz de confusión: \n",
      "[[876 972]\n",
      " [  3  91]]\n",
      "Área bajo la curva: \n",
      "0.844734387952473\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bag_class =BaggingClassifier(xg_reg)\n",
    "print('APLICO SMOTE')\n",
    "aplicarModelo(bag_class,X_smt_train, X_test, y_smt_train, y_test)\n",
    "print('APLICO RUS')\n",
    "aplicarModelo(bag_class,X_rus_train, X_test, y_rus_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pruebo con una red neuronal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APLICO SMOTE\n",
      "train acurracy: \n",
      "0.9481188954539973\n",
      "test acurracy: \n",
      "0.872811534500515\n",
      "Matriz de confusión: \n",
      "[[1659  189]\n",
      " [  58   36]]\n",
      "Área bajo la curva: \n",
      "0.7551176660219213\n",
      "\n",
      "APLICO RUS\n",
      "train acurracy: \n",
      "0.7923250564334086\n",
      "test acurracy: \n",
      "0.7842430484037075\n",
      "Matriz de confusión: \n",
      "[[1455  393]\n",
      " [  26   68]]\n",
      "Área bajo la curva: \n",
      "0.8325274016763379\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nn = MLPClassifier( early_stopping = True, random_state=123)\n",
    "\n",
    "\n",
    "print('APLICO SMOTE')\n",
    "aplicarModelo(nn,X_smt_train, X_test, y_smt_train, y_test)\n",
    "print('APLICO RUS')\n",
    "aplicarModelo(nn,X_rus_train, X_test, y_rus_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pruebo un Bagging de la red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "APLICO SMOTE\n",
      "train acurracy: \n",
      "0.8048956951645967\n",
      "test acurracy: \n",
      "0.635427394438723\n",
      "Matriz de confusión: \n",
      "[[1154  694]\n",
      " [  14   80]]\n",
      "Área bajo la curva: \n",
      "0.8235527770102238\n",
      "\n",
      "APLICO RUS\n",
      "train acurracy: \n",
      "0.7443566591422122\n",
      "test acurracy: \n",
      "0.49948506694129763\n",
      "Matriz de confusión: \n",
      "[[878 970]\n",
      " [  2  92]]\n",
      "Área bajo la curva: \n",
      "0.8468787418255503\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bag_class =BaggingClassifier(xg_reg)\n",
    "print('APLICO SMOTE')\n",
    "aplicarModelo(bag_class,X_smt_train, X_test, y_smt_train, y_test)\n",
    "print('APLICO RUS')\n",
    "aplicarModelo(bag_class,X_rus_train, X_test, y_rus_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Pruebo con SVM con The Kernel trick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "rbf_feature = RBFSampler(gamma=1,n_components= 100, random_state=123)\n",
    "X_features = rbf_feature.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y, test_size= 0.1, random_state= 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rus_train, y_rus_train = aplicarRus(X_train,y_train,X_test)\n",
    "X_smt_train, y_smt_train = aplicarSmote(X_train,y_train,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='linear', probability = True)\n",
    "\n",
    "print('APLICO SMOTE')\n",
    "aplicarModelo(clf,X_smt_train, X_test, y_smt_train, y_test)\n",
    "print('APLICO RUS')\n",
    "aplicarModelo(clf,X_rus_train, X_test, y_rus_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pruebo SVM con The Kernel trick y bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_class =BaggingClassifier(clf)\n",
    "\n",
    "print('APLICO SMOTE')\n",
    "aplicarModelo(bag_class,X_smt_train, X_test, y_smt_train, y_test)\n",
    "print('APLICO RUS')\n",
    "aplicarModelo(bag_class,X_rus_train, X_test, y_rus_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reduzco dimensiones (PCA) y aplico KNN. Esto se debe a que KNN sufre la maldición de la dimensionalidad. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=10).fit(X)\n",
    "X_reduce = pca.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_reduce, y, test_size= 0.1, random_state= 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rus_train, y_rus_train = aplicarRus(X_train,y_train,X_test)\n",
    "X_smt_train, y_smt_train = aplicarSmote(X_train,y_train,X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors= 80)\n",
    "\n",
    "print('APLICO SMOTE')\n",
    "aplicarModelo(knn,X_smt_train, X_test, y_smt_train, y_test)\n",
    "print('APLICO RUS')\n",
    "aplicarModelo(knn,X_rus_train, X_test, y_rus_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplico Bagging a KNN con PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_class =BaggingClassifier(knn)\n",
    "\n",
    "print('APLICO SMOTE')\n",
    "aplicarModelo(bag_class,X_smt_train, X_test, y_smt_train, y_test)\n",
    "print('APLICO RUS')\n",
    "aplicarModelo(bag_class,X_rus_train, X_test, y_rus_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplico RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.1, random_state= 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rus_train, y_rus_train = aplicarRus(X_train,y_train,X_test)\n",
    "X_smt_train, y_smt_train = aplicarSmote(X_train,y_train,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, max_depth=6, random_state=0)\n",
    "\n",
    "print('APLICO SMOTE')\n",
    "aplicarModelo(clf,X_smt_train, X_test, y_smt_train, y_test)\n",
    "print('APLICO RUS')\n",
    "aplicarModelo(clf,X_rus_train, X_test, y_rus_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aplico bagging y random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_class =BaggingClassifier(clf)\n",
    "\n",
    "print('APLICO SMOTE')\n",
    "aplicarModelo(bag_class,X_smt_train, X_test, y_smt_train, y_test)\n",
    "print('APLICO RUS')\n",
    "aplicarModelo(bag_class,X_rus_train, X_test, y_rus_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xgboost y PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=10).fit(X)\n",
    "X_reduce = pca.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_reduce, y, test_size= 0.1, random_state= 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_rus_train, y_rus_train = aplicarRus(X_train,y_train,X_test)\n",
    "X_smt_train, y_smt_train = aplicarSmote(X_train,y_train,X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, scale_pos_weight = 7, min_child_weight=15)\n",
    "\n",
    "\n",
    "print('APLICO SMOTE')\n",
    "aplicarModelo(xg_reg,X_smt_train, X_test, y_smt_train, y_test)\n",
    "print('APLICO RUS')\n",
    "aplicarModelo(xg_reg,X_rus_train, X_test, y_rus_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DE ACA EN ADELANTE NO MIRAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/bagging.py:621: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acurracy: \n",
      "0.840293453724605\n",
      "test acurracy: \n",
      "0.6848609680741503\n",
      "Matriz de confusión: \n",
      "[[1271  577]\n",
      " [  35   59]]\n",
      "Área bajo la curva: \n",
      "0.7283952749378282\n"
     ]
    }
   ],
   "source": [
    "bag_class =BaggingClassifier(xg_reg,max_samples = 1000)\n",
    "aplicarModelo(bag_class,X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hago un ensamble de Xgboost usando super learner (este lo sacao pq me dio mal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:219: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:252: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train acurracy: \n",
      "0.9536973443223443\n",
      "test acurracy: \n",
      "0.952626158599382\n",
      "Matriz de confusión: \n",
      "[[1847    1]\n",
      " [  91    3]]\n",
      "Área bajo la curva: \n",
      "0.5156868840379479\n"
     ]
    }
   ],
   "source": [
    "#xg_reg = xgb.XGBClassifier(learning_rate =0.05,n_estimators=10,max_depth=5,min_child_weight=1,gamma=0,\n",
    "                           subsample=0.8,colsample_bytree=0.8,objective= 'binary:logistic',nthread=4,\n",
    "                            seed=27)\n",
    "#xg_reg_2 = xgb.XGBClassifier(learning_rate =0.01,n_estimators=10,max_depth=5,min_child_weight=1,gamma=0,\n",
    "                           subsample=0.8,colsample_bytree=0.8,objective= 'binary:logistic',nthread=4,\n",
    "                            seed=27)\n",
    "#xg_reg_3 = xgb.XGBClassifier(learning_rate =0.1,n_estimators=100,max_depth=5,min_child_weight=1,gamma=0,\n",
    "                           subsample=0.8,colsample_bytree=0.8,objective= 'binary:logistic',nthread=4,\n",
    "                            seed=27)\n",
    "#gaussiano =GaussianNB()\n",
    "\n",
    "#clf = RandomForestClassifier(n_estimators=100, max_depth=2, random_state=0)\n",
    "\n",
    "#knn = KNeighborsClassifier(n_neighbors=4)\n",
    "\n",
    "#ensemble = SuperLearner(scorer = accuracy_score, random_state = 123, folds = 10)\n",
    "#ensemble.add(gaussiano)\n",
    "#ensemble.add(clf)\n",
    "#ensemble.add(knn)\n",
    "#ensemble.add(xg_reg_2)\n",
    "#ensemble.add(xg_reg_3)\n",
    "#ensemble.add_meta(xg_reg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
