{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pruebo Stacking con los datos sin  filtar#\n",
    "\n",
    "El stack consiste de los siguientes modelos como 1º paso:\n",
    "\n",
    "    RandomForestClassifier\n",
    "\n",
    "    ExtraTreesClassifier\n",
    "\n",
    "    AdaBoostClassifier\n",
    "\n",
    "    GradientBoostingClassifier\n",
    "    \n",
    "    XGBClassifier\n",
    "    \n",
    "Y como 2º paso MLPClassifier\n",
    "\n",
    "Uso Random under sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in our libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import sklearn\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.metrics import SCORERS\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "# Going to use these 5 base models for the stacking\n",
    "from sklearn.ensemble import (RandomForestClassifier, AdaBoostClassifier, \n",
    "                              GradientBoostingClassifier, ExtraTreesClassifier)\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargo los Features###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_f = pd.read_csv('labels_f.csv')\n",
    "datos = pd.read_csv('datos.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "atributos = labels_f.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "atributos.remove('person')\n",
    "atributos.remove('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = labels_f['label'].ravel()\n",
    "X = labels_f.loc[:,atributos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MaxAbsScaler().fit(X)\n",
    "X_transformed = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pca = PCA(n_components=10).fit(X)\n",
    "#X = pca.transform(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicarSmote(X_train, y_train):\n",
    "    smote = SMOTE(ratio='minority')\n",
    "    X_smt_train, y_smt_train = smote.fit_sample(X_train, y_train)\n",
    "    return (X_smt_train, y_smt_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicarRus(X_train_p, y_train_p):\n",
    "    rus= RandomUnderSampler(return_indices=True)\n",
    "    #id_rus son los índices\n",
    "    X_rus_train, y_rus_train, id_rus = rus.fit_sample(X_train_p, y_train_p)\n",
    "    return(X_rus_train, y_rus_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size= 0.1, random_state= 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = aplicarRus(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrain = X_train.shape[0]\n",
    "ntest = X_test.shape[0]\n",
    "SEED = 0 # for reproducibility\n",
    "NFOLDS = 5 # set folds for out-of-fold prediction\n",
    "class SklearnHelper(object):\n",
    "    def __init__(self, clf, seed=0, params=None):\n",
    "        params['random_state'] = seed\n",
    "        self.clf = clf(**params)\n",
    "\n",
    "    def train(self, x_train, y_train):\n",
    "        self.clf.fit(x_train, y_train)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.clf.predict(x)\n",
    "    \n",
    "    def fit(self,x,y):\n",
    "        return self.clf.fit(x,y)\n",
    "    \n",
    "    def feature_importances(self,x,y):\n",
    "        print(self.clf.fit(x,y).feature_importances_)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'    \\n    for i,(train_index, test_index) in enumerate(kf.split(X_transformed)):\\n        x_train, x_test = X_transformed[train_index], X_transformed[test_index]\\n        y_train, y_test = y[train_index], y[test_index]\\n        try:\\n            x_tr = x_train[train_index]\\n            y_tr = y_train[train_index]\\n            x_te = x_train[test_index]\\n            \\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"    \n",
    "    for i,(train_index, test_index) in enumerate(kf.split(X_transformed)):\n",
    "        x_train, x_test = X_transformed[train_index], X_transformed[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        try:\n",
    "            x_tr = x_train[train_index]\n",
    "            y_tr = y_train[train_index]\n",
    "            x_te = x_train[test_index]\n",
    "            \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_oof(clf, x_train, y_train, x_test):\n",
    "    oof_train = np.zeros((ntrain,))\n",
    "    oof_test = np.zeros((ntest,))\n",
    "    oof_test_skf = np.empty((NFOLDS, ntest))\n",
    "    \n",
    "    kf = KFold(n_splits= NFOLDS, random_state=SEED)\n",
    "    kf = kf.split(x_train)\n",
    "    i = 0\n",
    "\n",
    "    for i, (train_index, test_index) in enumerate(kf):\n",
    "        x_tr = x_train[train_index]\n",
    "        y_tr = y_train[train_index]\n",
    "        x_te = x_train[test_index]\n",
    "        clf.fit(x_tr, y_tr)\n",
    "        oof_train[test_index] = clf.predict(x_te)\n",
    "        oof_test_skf[i, :] = clf.predict(x_test)\n",
    "        i+=1\n",
    "        #print(i)\n",
    "\n",
    "    oof_test[:] = oof_test_skf.mean(axis=0)\n",
    "    return oof_train.reshape(-1, 1), oof_test.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put in our parameters for said classifiers\n",
    "# Random Forest parameters\n",
    "rf_params = {\n",
    "    'n_estimators': 500,\n",
    "    'max_depth': 6,\n",
    "}#'n_jobs': -1,\n",
    "\n",
    "# Extra Trees Parameters\n",
    "et_params = {\n",
    "    'n_estimators':500,\n",
    "    'max_features': 0.5,\n",
    "    'max_depth': 8,}\n",
    "#,'n_jobs': -1,\n",
    "\n",
    "# AdaBoost parameters\n",
    "ada_params = {\n",
    "    'n_estimators': 500,\n",
    "    'learning_rate' : 0.01\n",
    "}\n",
    "\n",
    "# Gradient Boosting parameters\n",
    "gb_params = {\n",
    "    'n_estimators': 500,\n",
    "    'max_depth': 5,\n",
    "    'min_samples_leaf': 2,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "xgb_params = {'learning_rate':0.05,'n_estimators':1000,'max_depth':5,'min_child_weight':1,'gamma':0,\n",
    "                           'subsample':0.8,'colsample_bytree':0.8,'objective': 'binary:logistic','nthread':4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 5 objects that represent our 4 models\n",
    "rf = SklearnHelper(clf=RandomForestClassifier, seed=SEED, params=rf_params)\n",
    "et = SklearnHelper(clf=ExtraTreesClassifier, seed=SEED, params=et_params)\n",
    "ada = SklearnHelper(clf=AdaBoostClassifier, seed=SEED, params=ada_params)\n",
    "gb = SklearnHelper(clf=GradientBoostingClassifier, seed=SEED, params=gb_params)\n",
    "xgb =  SklearnHelper(clf=XGBClassifier, seed=SEED, params=xgb_params)\n",
    "#svc = SklearnHelper(clf=SVC, seed=SEED, params=svc_params)\n",
    "#nn = SklearnHelper(clf = MLPClassifier, seed = SEED, params = nn_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training is complete\n"
     ]
    }
   ],
   "source": [
    "# Create our OOF train and test predictions. These base results will be used as new features\n",
    "et_oof_train, et_oof_test = get_oof(et, X_train, y_train, X_test) # Extra Trees\n",
    "rf_oof_train, rf_oof_test = get_oof(rf,X_train, y_train, X_test) # Random Forest\n",
    "ada_oof_train, ada_oof_test = get_oof(ada, X_train, y_train, X_test) # AdaBoost \n",
    "gb_oof_train, gb_oof_test = get_oof(gb,X_train, y_train, X_test) # Gradient Boost\n",
    "xgb_oof_train,xgb_oof_test = get_oof(xgb,X_train, y_train, X_test) # Support Vector Classifier\n",
    "#nn_oof_train, nn_oof_test = get_oof(nn,X_train, y_train, X_test)\n",
    "print(\"Training is complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.concatenate(( et_oof_train, rf_oof_train, ada_oof_train, gb_oof_train,xgb_oof_train ), axis=1) #\n",
    "x_test = np.concatenate(( et_oof_test, rf_oof_test, ada_oof_test, gb_oof_test,xgb_oof_test), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = MLPClassifier( early_stopping=False, random_state=123).fit(x_train, y_train)#, early_stopping_rounds = 5, eval_set=[(x_test, y_test)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión: \n",
      "[[1344  504]\n",
      " [  17   77]]\n",
      "Área bajo la curva: \n",
      "0.8339464170581192\n"
     ]
    }
   ],
   "source": [
    "preds = nn.predict(x_test)\n",
    "preds_prob = nn.predict_proba(x_test)[:,1]\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds_prob)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "print('Matriz de confusión: ')\n",
    "print(matriz_de_confusion)\n",
    "print('Área bajo la curva: ')\n",
    "print(area_debajo_de_curva)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uso como segundo Paso XGBOOST nuevamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg= XGBClassifierlearning_rate =0.05,n_estimators=1000,max_depth=5,min_child_weight=1,gamma=0,\n",
    "                           subsample=0.8,colsample_bytree=0.8,objective= 'binary:logistic',nthread=4,\n",
    "                            seed=27)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-error:0.2724\n",
      "Will train until validation_0-error hasn't improved in 5 rounds.\n",
      "[1]\tvalidation_0-error:0.267765\n",
      "[2]\tvalidation_0-error:0.27034\n",
      "[3]\tvalidation_0-error:0.26931\n",
      "[4]\tvalidation_0-error:0.27137\n",
      "[5]\tvalidation_0-error:0.27034\n",
      "[6]\tvalidation_0-error:0.2724\n",
      "Stopping. Best iteration:\n",
      "[1]\tvalidation_0-error:0.267765\n",
      "\n",
      "Matriz de confusión: \n",
      "[[1344  504]\n",
      " [  16   78]]\n",
      "Área bajo la curva: \n",
      "0.7927604310583034\n"
     ]
    }
   ],
   "source": [
    "xg_reg.fit(x_train, y_train, early_stopping_rounds = 5, eval_set=[(x_test, y_test)])\n",
    "preds = xg_reg.predict(x_test)\n",
    "preds_prob = xg_reg.predict_proba(x_test)[:,1]\n",
    "area_debajo_de_curva = roc_auc_score(y_test, preds_prob)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "print('Matriz de confusión: ')\n",
    "print(matriz_de_confusion)\n",
    "print('Área bajo la curva: ')\n",
    "print(area_debajo_de_curva)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
