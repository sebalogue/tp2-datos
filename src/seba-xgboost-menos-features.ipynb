{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd  \n",
    "import numpy as np  \n",
    "import matplotlib.pyplot as plt \n",
    "from datetime import timedelta\n",
    "%matplotlib inline\n",
    "\n",
    "#from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\\\n",
    "                            f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seba\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3020: DtypeWarning: Columns (3,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "labels = pd.read_csv(\"../../data/fiuba-trocafone-tp2-final-set/labels_training_set.csv\")\n",
    "df = pd.read_csv(\"../../data/fiuba-trocafone-tp2-final-set/events_up_to_01062018.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_persons = pd.read_csv(\"../../data/trocafone_kaggle_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"timestamp\"] = pd.to_datetime(df[\"timestamp\"])\n",
    "df[\"month\"] = df[\"timestamp\"].dt.month\n",
    "df[\"day\"] = df[\"timestamp\"].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "todas_las_personas = df[[\"person\"]].drop_duplicates(subset=\"person\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cantidad de veces que realiza un evento dado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ad campaign hit</th>\n",
       "      <th>brand listing</th>\n",
       "      <th>checkout</th>\n",
       "      <th>conversion</th>\n",
       "      <th>generic listing</th>\n",
       "      <th>search engine hit</th>\n",
       "      <th>searched products</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ad campaign hit  brand listing  checkout  conversion  generic listing  \\\n",
       "0              0.0            0.0       3.0         0.0              1.0   \n",
       "1              1.0            0.0       1.0         0.0              1.0   \n",
       "2              5.0            0.0       1.0         0.0              4.0   \n",
       "3             29.0          165.0      15.0         2.0             28.0   \n",
       "4              0.0            1.0       2.0         1.0              1.0   \n",
       "\n",
       "   search engine hit  searched products  label  \n",
       "0                0.0                0.0      0  \n",
       "1                1.0                9.0      0  \n",
       "2                0.0                4.0      0  \n",
       "3               13.0               11.0      0  \n",
       "4                0.0                0.0      0  "
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cant_por_evento = pd.concat([pd.get_dummies(df['event']),df[['person']]],axis = 1).groupby('person')\\\n",
    "    .sum().reset_index()\n",
    "\n",
    "df_train = pd.merge(cant_por_evento, labels, on=\"person\", how=\"inner\")\\\n",
    "            .drop(columns = ['person', 'viewed product', 'visited site', 'staticpage', 'lead'])\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#veo cuantos users pierdo\n",
    "cant_por_evento_predecir = pd.merge(cant_por_evento, df_persons, on=\"person\", how=\"inner\")\n",
    "cant_por_evento_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = df_train.iloc[:,:-1],df_train.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, scale_pos_weight = 10, min_child_weight=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=1, missing=None, n_estimators=6,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=10, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)\n",
    "proba = xg_reg.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8537763183310798\n",
      "Test acuracy:  0.8503734226113829\n",
      "ROC auc score:  0.8260601668812715\n",
      "Confusion matrix: \n",
      "[[3198  494]\n",
      " [  87  104]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos que onda\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, proba)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cantidad de veces que realiza un evento dado en el mes 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>ad campaign hit mes 5</th>\n",
       "      <th>brand listing mes 5</th>\n",
       "      <th>checkout mes 5</th>\n",
       "      <th>conversion mes 5</th>\n",
       "      <th>generic listing mes 5</th>\n",
       "      <th>lead mes 5</th>\n",
       "      <th>search engine hit mes 5</th>\n",
       "      <th>searched products mes 5</th>\n",
       "      <th>staticpage mes 5</th>\n",
       "      <th>viewed product mes 5</th>\n",
       "      <th>visited site mes 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008ed71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091926</td>\n",
       "      <td>15.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>372.0</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000ba417</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>153.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000c79fe</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000e4d9e</td>\n",
       "      <td>19.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>339.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  ad campaign hit mes 5  brand listing mes 5  checkout mes 5  \\\n",
       "0  0008ed71                    0.0                  0.0             3.0   \n",
       "1  00091926                   15.0                 25.0             2.0   \n",
       "2  000ba417                    1.0                 24.0             6.0   \n",
       "3  000c79fe                    1.0                  0.0             1.0   \n",
       "4  000e4d9e                   19.0                 17.0             1.0   \n",
       "\n",
       "   conversion mes 5  generic listing mes 5  lead mes 5  \\\n",
       "0               0.0                    1.0         0.0   \n",
       "1               0.0                    0.0         0.0   \n",
       "2               1.0                   14.0         0.0   \n",
       "3               0.0                    1.0         0.0   \n",
       "4               0.0                   17.0         0.0   \n",
       "\n",
       "   search engine hit mes 5  searched products mes 5  staticpage mes 5  \\\n",
       "0                      0.0                      0.0               0.0   \n",
       "1                      0.0                      0.0               0.0   \n",
       "2                      1.0                      0.0               0.0   \n",
       "3                      1.0                      9.0               0.0   \n",
       "4                      5.0                      0.0               0.0   \n",
       "\n",
       "   viewed product mes 5  visited site mes 5  \n",
       "0                   0.0                 2.0  \n",
       "1                 372.0                34.0  \n",
       "2                 153.0                 6.0  \n",
       "3                   3.0                 1.0  \n",
       "4                 339.0                13.0  "
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eventos_mes_cinco = df.loc[df[\"month\"] == 5]\n",
    "cant_por_evento_mes_cinco = pd.concat([pd.get_dummies(eventos_mes_cinco['event']),eventos_mes_cinco[['person']]],axis = 1).groupby('person')\\\n",
    "    .sum().reset_index()\n",
    "\n",
    "cant_por_evento_mes_cinco.columns = ['person', 'ad campaign hit mes 5', 'brand listing mes 5', 'checkout mes 5',\\\n",
    "                                     'conversion mes 5', 'generic listing mes 5', 'lead mes 5', 'search engine hit mes 5',\\\n",
    "                                     'searched products mes 5', 'staticpage mes 5', 'viewed product mes 5', 'visited site mes 5' ]\n",
    "\n",
    "cant_por_evento_mes_cinco = pd.merge(cant_por_evento_mes_cinco, todas_las_personas, on=\"person\", how='right')\n",
    "\n",
    "df_train = pd.merge(cant_por_evento_mes_cinco, labels, on=\"person\", how=\"inner\")\\\n",
    "            .drop(columns = ['person', 'viewed product mes 5', 'visited site mes 5', 'staticpage mes 5', 'lead mes 5'])\n",
    "cant_por_evento_mes_cinco.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_combino = pd.merge(cant_por_evento_mes_cinco, cant_por_evento, on='person', how='inner')\n",
    "\n",
    "df_train = pd.merge(df_combino, labels, on=\"person\", how=\"inner\")\\\n",
    "            .drop(columns = ['person','viewed product', 'visited site', 'staticpage', 'lead', 'viewed product',\\\n",
    "                             'visited site', 'staticpage mes 5', 'lead mes 5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#veo cuantos users pierdo\n",
    "cant_por_evento_predecir = pd.merge(cant_por_evento_mes_cinco, df_persons, on=\"person\", how=\"inner\")\n",
    "cant_por_evento_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ad campaign hit mes 5</th>\n",
       "      <th>brand listing mes 5</th>\n",
       "      <th>checkout mes 5</th>\n",
       "      <th>conversion mes 5</th>\n",
       "      <th>generic listing mes 5</th>\n",
       "      <th>search engine hit mes 5</th>\n",
       "      <th>searched products mes 5</th>\n",
       "      <th>viewed product mes 5</th>\n",
       "      <th>visited site mes 5</th>\n",
       "      <th>ad campaign hit</th>\n",
       "      <th>brand listing</th>\n",
       "      <th>checkout</th>\n",
       "      <th>conversion</th>\n",
       "      <th>generic listing</th>\n",
       "      <th>search engine hit</th>\n",
       "      <th>searched products</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ad campaign hit mes 5  brand listing mes 5  checkout mes 5  \\\n",
       "0                    0.0                  0.0             3.0   \n",
       "1                    1.0                  0.0             1.0   \n",
       "2                    5.0                  0.0             1.0   \n",
       "3                   16.0                113.0             4.0   \n",
       "4                    0.0                  1.0             2.0   \n",
       "\n",
       "   conversion mes 5  generic listing mes 5  search engine hit mes 5  \\\n",
       "0               0.0                    1.0                      0.0   \n",
       "1               0.0                    1.0                      1.0   \n",
       "2               0.0                    4.0                      0.0   \n",
       "3               1.0                   13.0                      7.0   \n",
       "4               1.0                    1.0                      0.0   \n",
       "\n",
       "   searched products mes 5  viewed product mes 5  visited site mes 5  \\\n",
       "0                      0.0                   0.0                 2.0   \n",
       "1                      9.0                   3.0                 1.0   \n",
       "2                      4.0                   4.0                 1.0   \n",
       "3                      1.0                 123.0                12.0   \n",
       "4                      0.0                   2.0                 0.0   \n",
       "\n",
       "   ad campaign hit  brand listing  checkout  conversion  generic listing  \\\n",
       "0              0.0            0.0       3.0         0.0              1.0   \n",
       "1              1.0            0.0       1.0         0.0              1.0   \n",
       "2              5.0            0.0       1.0         0.0              4.0   \n",
       "3             29.0          165.0      15.0         2.0             28.0   \n",
       "4              0.0            1.0       2.0         1.0              1.0   \n",
       "\n",
       "   search engine hit  searched products  label  \n",
       "0                0.0                0.0      0  \n",
       "1                1.0                9.0      0  \n",
       "2                0.0                4.0      0  \n",
       "3               13.0               11.0      0  \n",
       "4                0.0                0.0      0  "
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = df_train.iloc[:,:-1],df_train.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, scale_pos_weight = 5, min_child_weight=17)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=17, missing=None, n_estimators=6,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=5, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)\n",
    "proba = xg_reg.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.9083124074431782\n",
      "Test acuracy:  0.8956992016482102\n",
      "ROC auc score:  0.8517455322306225\n",
      "Confusion matrix: \n",
      "[[3391  279]\n",
      " [ 126   87]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos que onda\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, proba)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cantidad de eventos en un dia del mes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_day = pd.concat([df['person'],pd.get_dummies(df['day'])],axis = 1).groupby('person').sum().\\\n",
    "    reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas = ['dia_' + str(i) for i in range(1,32)]\n",
    "columnas.insert(0,'person')\n",
    "df_day.columns = columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_con_dias_del_mes = pd.merge(df_combino, df_day, on='person', how='inner')\n",
    "\n",
    "df_train = pd.merge(df_con_dias_del_mes, labels, on=\"person\", how=\"inner\")\\\n",
    "            .drop(columns = ['person','viewed product', 'visited site', 'staticpage', 'lead', 'viewed product',\\\n",
    "                             'visited site', 'staticpage mes 5', 'lead mes 5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = df_train.iloc[:,:-1],df_train.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, scale_pos_weight = 5, min_child_weight=17)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=17, missing=None, n_estimators=6,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=5, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 371,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)\n",
    "proba = xg_reg.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.9057369132702338\n",
      "Test acuracy:  0.8969868658253928\n",
      "ROC auc score:  0.8561512581392077\n",
      "Confusion matrix: \n",
      "[[3395  275]\n",
      " [ 125   88]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos que onda\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, proba)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cantidad de eventos en top K semanas del año."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 10\n",
    "df['week_of_year'] = df['timestamp'].dt.weekofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_week_of_year = df[['person','week_of_year']]\n",
    "\n",
    "top_K_week_of_year = df_week_of_year['week_of_year'].value_counts().head(K).index\n",
    "\n",
    "df_week_of_year = pd.concat([df_week_of_year,pd.get_dummies(df_week_of_year['week_of_year'])[top_K_week_of_year]],axis = 1)\n",
    "\n",
    "df_week_of_year.drop(columns = ['week_of_year'],inplace = True)\n",
    "\n",
    "df_week_of_year1 = df_week_of_year.groupby('person').sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_con_top_semanas = pd.merge(df_con_dias_del_mes, df_week_of_year1, on='person', how='inner')\n",
    "\n",
    "df_train = pd.merge(df_con_top_semanas, labels, on=\"person\", how=\"inner\")\\\n",
    "            .drop(columns = ['person','viewed product', 'visited site', 'staticpage', 'lead', 'viewed product',\\\n",
    "                             'visited site', 'staticpage mes 5', 'lead mes 5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ad campaign hit mes 5</th>\n",
       "      <th>brand listing mes 5</th>\n",
       "      <th>checkout mes 5</th>\n",
       "      <th>conversion mes 5</th>\n",
       "      <th>generic listing mes 5</th>\n",
       "      <th>search engine hit mes 5</th>\n",
       "      <th>searched products mes 5</th>\n",
       "      <th>viewed product mes 5</th>\n",
       "      <th>visited site mes 5</th>\n",
       "      <th>ad campaign hit</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>22</th>\n",
       "      <th>19</th>\n",
       "      <th>18</th>\n",
       "      <th>17</th>\n",
       "      <th>16</th>\n",
       "      <th>15</th>\n",
       "      <th>14</th>\n",
       "      <th>13</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>...</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ad campaign hit mes 5  brand listing mes 5  checkout mes 5  \\\n",
       "0                    0.0                  0.0             3.0   \n",
       "1                    1.0                  0.0             1.0   \n",
       "2                    5.0                  0.0             1.0   \n",
       "3                   16.0                113.0             4.0   \n",
       "4                    0.0                  1.0             2.0   \n",
       "\n",
       "   conversion mes 5  generic listing mes 5  search engine hit mes 5  \\\n",
       "0               0.0                    1.0                      0.0   \n",
       "1               0.0                    1.0                      1.0   \n",
       "2               0.0                    4.0                      0.0   \n",
       "3               1.0                   13.0                      7.0   \n",
       "4               1.0                    1.0                      0.0   \n",
       "\n",
       "   searched products mes 5  viewed product mes 5  visited site mes 5  \\\n",
       "0                      0.0                   0.0                 2.0   \n",
       "1                      9.0                   3.0                 1.0   \n",
       "2                      4.0                   4.0                 1.0   \n",
       "3                      1.0                 123.0                12.0   \n",
       "4                      0.0                   2.0                 0.0   \n",
       "\n",
       "   ad campaign hit  ...       20    22   19     18   17   16   15   14   13  \\\n",
       "0              0.0  ...      6.0   0.0  0.0    0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1              1.0  ...      0.0  17.0  0.0    0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2              5.0  ...      0.0  19.0  0.0    0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3             29.0  ...    181.0   0.0  0.0  108.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4              0.0  ...      0.0   0.0  0.0    0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   label  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = df_train.iloc[:,:-1],df_train.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, scale_pos_weight = 5, min_child_weight=17)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=17, missing=None, n_estimators=6,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=5, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)\n",
    "proba = xg_reg.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.9067671109394115\n",
      "Test acuracy:  0.8954416688127737\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.92      0.94      3670\n",
      "           1       0.24      0.41      0.30       213\n",
      "\n",
      "   micro avg       0.90      0.90      0.90      3883\n",
      "   macro avg       0.60      0.67      0.62      3883\n",
      "weighted avg       0.92      0.90      0.91      3883\n",
      "\n",
      "\n",
      "Precision Score:  0.23848238482384823\n",
      "Recall Score:  0.4131455399061033\n",
      "F1 Score:  0.3024054982817869\n",
      "Cohen Kappa Score:  0.25025490889860336\n",
      "ROC auc score:  0.8574055596065037\n",
      "Confusion matrix: \n",
      "[[3389  281]\n",
      " [ 125   88]]\n"
     ]
    }
   ],
   "source": [
    "# Pruebo todas las metricas.\n",
    "# accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\n",
    "# f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "\n",
    "trainAccuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "testAccuracy = accuracy_score(y_test, preds)\n",
    "\n",
    "meanSquaredError = mean_squared_error(y_test, preds)\n",
    "classificationReport = classification_report(y_test, preds)\n",
    "precisionScore = precision_score(y_test, preds)\n",
    "recallScore = recall_score(y_test, preds)\n",
    "f1Score = f1_score(y_test, preds)\n",
    "cohenKappaScore = cohen_kappa_score(y_test, preds)\n",
    "areaDebajoDeCurva = roc_auc_score(y_test, proba)\n",
    "matrizDeConfusion = confusion_matrix(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", trainAccuracy)\n",
    "print(\"Test acuracy: \", testAccuracy)\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(classificationReport)\n",
    "print()\n",
    "print(\"Precision Score: \",precisionScore)\n",
    "print(\"Recall Score: \",recallScore)\n",
    "print(\"F1 Score: \",f1Score)\n",
    "print(\"Cohen Kappa Score: \",cohenKappaScore)\n",
    "print(\"ROC auc score: \", areaDebajoDeCurva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matrizDeConfusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Usando random oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = df_train.iloc[:,:-1].fillna(0), df_train.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "#data_dmatrix = xgb.DMatrix(data=X,label=y, weight={1: 1, 0: 0.1})\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14764, 767)"
      ]
     },
     "execution_count": 517,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cant_ceros = np.sum(y_train == 0)\n",
    "cant_unos = np.sum(y_train == 1)\n",
    "cant_ceros, cant_unos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 518,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.any(np.isnan(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 519,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(np.isfinite(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state=2, sampling_strategy = {0: 14764, 1: 1200})\n",
    "X_train_res, y_train_res = ros.fit_sample(X_train, y_train)\n",
    "X_train_res_df = pd.DataFrame(X_train_res)\n",
    "X_train_res_df.columns = X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6,eval_metric = \"auc\", scale_pos_weight=5, min_child_weight=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 530,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=1, missing=None,\n",
       "       n_estimators=6, n_jobs=1, nthread=None, objective='binary:logistic',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=5,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 530,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train_res_df ,y_train_res.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)\n",
    "proba = xg_reg.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8484715610122776\n",
      "Test acuracy:  0.8411022405356683\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.85      0.91      3670\n",
      "           1       0.20      0.65      0.31       213\n",
      "\n",
      "   micro avg       0.84      0.84      0.84      3883\n",
      "   macro avg       0.59      0.75      0.61      3883\n",
      "weighted avg       0.93      0.84      0.88      3883\n",
      "\n",
      "\n",
      "Precision Score:  0.20381231671554254\n",
      "Recall Score:  0.6525821596244131\n",
      "F1 Score:  0.3106145251396648\n",
      "Cohen Kappa Score:  0.24772470580921035\n",
      "ROC auc score:  0.8582332322728377\n",
      "Confusion matrix: \n",
      "[[3127  543]\n",
      " [  74  139]]\n"
     ]
    }
   ],
   "source": [
    "# Pruebo todas las metricas.\n",
    "# accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\n",
    "# f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "\n",
    "trainAccuracy = accuracy_score(y_train_res, xg_reg.predict(X_train_res_df))\n",
    "testAccuracy = accuracy_score(y_test, preds)\n",
    "\n",
    "meanSquaredError = mean_squared_error(y_test, preds)\n",
    "classificationReport = classification_report(y_test, preds)\n",
    "precisionScore = precision_score(y_test, preds)\n",
    "recallScore = recall_score(y_test, preds)\n",
    "f1Score = f1_score(y_test, preds)\n",
    "cohenKappaScore = cohen_kappa_score(y_test, preds)\n",
    "areaDebajoDeCurva = roc_auc_score(y_test, proba)\n",
    "matrizDeConfusion = confusion_matrix(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", trainAccuracy)\n",
    "print(\"Test acuracy: \", testAccuracy)\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(classificationReport)\n",
    "print()\n",
    "print(\"Precision Score: \",precisionScore)\n",
    "print(\"Recall Score: \",recallScore)\n",
    "print(\"F1 Score: \",f1Score)\n",
    "print(\"Cohen Kappa Score: \",cohenKappaScore)\n",
    "print(\"ROC auc score: \", areaDebajoDeCurva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matrizDeConfusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visitas a la pagina segun resolucion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>1024x768</th>\n",
       "      <th>1360x768</th>\n",
       "      <th>1366x768</th>\n",
       "      <th>1440x900</th>\n",
       "      <th>1600x900</th>\n",
       "      <th>1920x1080</th>\n",
       "      <th>320x534</th>\n",
       "      <th>320x568</th>\n",
       "      <th>320x570</th>\n",
       "      <th>360x640</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008ed71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091926</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00091a7a</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000ba417</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000c79fe</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  1024x768  1360x768  1366x768  1440x900  1600x900  1920x1080  \\\n",
       "0  0008ed71       0.0       0.0       0.0       0.0       0.0        2.0   \n",
       "1  00091926      34.0       0.0       0.0       0.0       0.0        0.0   \n",
       "2  00091a7a       0.0       0.0       0.0       0.0       0.0        0.0   \n",
       "3  000ba417       6.0       0.0       0.0       0.0       0.0        0.0   \n",
       "4  000c79fe       0.0       0.0       0.0       0.0       0.0        0.0   \n",
       "\n",
       "   320x534  320x568  320x570  360x640  \n",
       "0      0.0      0.0      0.0      0.0  \n",
       "1      0.0      0.0      0.0      0.0  \n",
       "2      0.0      0.0      0.0      1.0  \n",
       "3      0.0      0.0      0.0      0.0  \n",
       "4      0.0      0.0      0.0      1.0  "
      ]
     },
     "execution_count": 671,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resolucion = df.loc[df['event'] == 'visited site']\n",
    "df_resolucion = df_resolucion[['person','screen_resolution']].dropna()\n",
    "\n",
    "top_5_resoluciones = df_resolucion['screen_resolution'].value_counts().head(10).index\n",
    "df_resolucion = df_resolucion.loc[df_resolucion['screen_resolution'].isin(top_5_resoluciones)]\n",
    "df_resolucion = pd.concat([df_resolucion['person'],\\\n",
    "        pd.get_dummies(df_resolucion['screen_resolution'])],axis = 1).groupby('person').sum().reset_index()\n",
    "\n",
    "df_resolucion = pd.merge(df_resolucion, todas_las_personas, on=\"person\", how=\"right\").fillna(0)\n",
    "\n",
    "df_resolucion.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creo que es mucho 20 resoluciones, probar (quizas empeore).."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 673,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veo cuantas personas a predecir pierdo\n",
    "df_resolucion_predecir = pd.merge(df_resolucion, df_persons, on=\"person\", how=\"inner\")\n",
    "df_resolucion_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge\n",
    "\n",
    "df_con_resoluciones = pd.merge(df_con_top_semanas, df_resolucion, on=\"person\", how=\"inner\") \n",
    "df_train = pd.merge(df_con_resoluciones, labels, on=\"person\", how=\"inner\")\\\n",
    "            .drop(columns = ['person','viewed product', 'visited site', 'staticpage', 'lead', 'viewed product',\\\n",
    "                             'visited site', 'staticpage mes 5', 'lead mes 5'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = df_train.iloc[:,:-1],df_train.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, scale_pos_weight = 5, min_child_weight=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=12, missing=None, n_estimators=6,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=5, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 716,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)\n",
    "proba = xg_reg.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 718,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.9311055308737364\n",
      "Test acuracy:  0.9175894926603142\n",
      "ROC auc score:  0.8584545419656907\n",
      "Confusion matrix: \n",
      "[[3500  170]\n",
      " [ 150   63]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos que onda\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, proba)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando random oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 719,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = df_train.iloc[:,:-1].fillna(0), df_train.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "#data_dmatrix = xgb.DMatrix(data=X,label=y, weight={1: 1, 0: 0.1})\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 720,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14764, 767)"
      ]
     },
     "execution_count": 720,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cant_ceros = np.sum(y_train == 0)\n",
    "cant_unos = np.sum(y_train == 1)\n",
    "cant_ceros, cant_unos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 721,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.any(np.isnan(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 722,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 722,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(np.isfinite(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 723,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state=2, sampling_strategy = {0: 14764, 1: 1200})\n",
    "X_train_res, y_train_res = ros.fit_sample(X_train, y_train)\n",
    "X_train_res_df = pd.DataFrame(X_train_res)\n",
    "X_train_res_df.columns = X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6,eval_metric = \"auc\", scale_pos_weight=5, min_child_weight=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=20, missing=None,\n",
       "       n_estimators=6, n_jobs=1, nthread=None, objective='binary:logistic',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=5,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 752,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train_res_df ,y_train_res.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)\n",
    "proba = xg_reg.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.8737158606865447\n",
      "Test acuracy:  0.871233582281741\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.89      0.93      3670\n",
      "           1       0.23      0.58      0.33       213\n",
      "\n",
      "   micro avg       0.87      0.87      0.87      3883\n",
      "   macro avg       0.60      0.73      0.63      3883\n",
      "weighted avg       0.93      0.87      0.90      3883\n",
      "\n",
      "\n",
      "Precision Score:  0.23076923076923078\n",
      "Recall Score:  0.5774647887323944\n",
      "F1 Score:  0.3297587131367293\n",
      "Cohen Kappa Score:  0.2727538338215353\n",
      "ROC auc score:  0.860972739251129\n",
      "Confusion matrix: \n",
      "[[3260  410]\n",
      " [  90  123]]\n"
     ]
    }
   ],
   "source": [
    "# Pruebo todas las metricas.\n",
    "# accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\n",
    "# f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "\n",
    "trainAccuracy = accuracy_score(y_train_res, xg_reg.predict(X_train_res_df))\n",
    "testAccuracy = accuracy_score(y_test, preds)\n",
    "\n",
    "meanSquaredError = mean_squared_error(y_test, preds)\n",
    "classificationReport = classification_report(y_test, preds)\n",
    "precisionScore = precision_score(y_test, preds)\n",
    "recallScore = recall_score(y_test, preds)\n",
    "f1Score = f1_score(y_test, preds)\n",
    "cohenKappaScore = cohen_kappa_score(y_test, preds)\n",
    "areaDebajoDeCurva = roc_auc_score(y_test, proba)\n",
    "matrizDeConfusion = confusion_matrix(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", trainAccuracy)\n",
    "print(\"Test acuracy: \", testAccuracy)\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(classificationReport)\n",
    "print()\n",
    "print(\"Precision Score: \",precisionScore)\n",
    "print(\"Recall Score: \",recallScore)\n",
    "print(\"F1 Score: \",f1Score)\n",
    "print(\"Cohen Kappa Score: \",cohenKappaScore)\n",
    "print(\"ROC auc score: \", areaDebajoDeCurva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matrizDeConfusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OCHENTA Y SEIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distancia entre ultima entrada al sitio y el ultimo dia que tenemos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 925,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>dias_hasta_ultimo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008ed71</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091926</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00091a7a</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000ba417</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000c79fe</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  dias_hasta_ultimo\n",
       "0  0008ed71                 14\n",
       "1  00091926                  0\n",
       "2  00091a7a                 66\n",
       "3  000ba417                  5\n",
       "4  000c79fe                  2"
      ]
     },
     "execution_count": 925,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamp_df = df[[\"person\", \"timestamp\"]]\n",
    "ultimo_dia_de_todos = timestamp_df[\"timestamp\"].max()\n",
    "ultima_entrada = timestamp_df.groupby(\"person\")[\"timestamp\"].max().rename(\"ultimo\").reset_index()\n",
    "ultima_entrada[\"dias_hasta_ultimo\"] = (ultimo_dia_de_todos - ultima_entrada[\"ultimo\"]).dt.days\n",
    "ultima_entrada = ultima_entrada[[\"person\", \"dias_hasta_ultimo\"]]\n",
    "ultima_entrada.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 926,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 926,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veo cuantas personas a predecir pierdo\n",
    "df_predecir = pd.merge(ultima_entrada, df_persons, on=\"person\", how=\"inner\")\n",
    "df_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1051,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge\n",
    "# df_con_resoluciones\n",
    "\n",
    "df_con_diatancia_hasta_ultimo = pd.merge(df_con_resoluciones, ultima_entrada, on=\"person\", how=\"inner\") \n",
    "df_train = pd.merge(df_con_diatancia_hasta_ultimo, labels, on=\"person\", how=\"inner\")\\\n",
    "            .drop(columns = ['person','viewed product', 'visited site', 'staticpage', 'lead', 'viewed product',\\\n",
    "                             'visited site', 'staticpage mes 5', 'lead mes 5'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1052,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = df_train.iloc[:,:-1],df_train.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1053,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "data_dmatrix = xgb.DMatrix(data=X,label=y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1054,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1055,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6, scale_pos_weight = 5, min_child_weight=12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1056,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=5, min_child_weight=12, missing=None, n_estimators=6,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=5, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 1056,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1057,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)\n",
    "proba = xg_reg.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1058,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.9307835941021183\n",
      "Test acuracy:  0.921452485191862\n",
      "ROC auc score:  0.8602141459108877\n",
      "Confusion matrix: \n",
      "[[3508  162]\n",
      " [ 143   70]]\n"
     ]
    }
   ],
   "source": [
    "# Vemos que onda\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, xg_reg.predict(X_train))\n",
    "test_accuracy = accuracy_score(y_test, preds)\n",
    "matriz_de_confusion = confusion_matrix(y_test, preds)\n",
    "area_debajo_de_curva = roc_auc_score(y_test, proba)\n",
    "\n",
    "print(\"Train accuracy: \", train_accuracy)\n",
    "print(\"Test acuracy: \", test_accuracy)\n",
    "print(\"ROC auc score: \", area_debajo_de_curva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matriz_de_confusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usando random oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1060,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separamos la variable a predecir\n",
    "\n",
    "X, y = df_train.iloc[:,:-1].fillna(0), df_train.iloc[:,-1]\n",
    "\n",
    "# Convertimos los datos a DMatrix\n",
    "\n",
    "#data_dmatrix = xgb.DMatrix(data=X,label=y, weight={1: 1, 0: 0.1})\n",
    "\n",
    "#Creamos set de entrenamiento y test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1061,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14764, 767)"
      ]
     },
     "execution_count": 1061,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cant_ceros = np.sum(y_train == 0)\n",
    "cant_unos = np.sum(y_train == 1)\n",
    "cant_ceros, cant_unos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1062,
   "metadata": {},
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(random_state=2, sampling_strategy = {0: 14764, 1: 784})\n",
    "X_train_res, y_train_res = ros.fit_sample(X_train, y_train)\n",
    "X_train_res_df = pd.DataFrame(X_train_res)\n",
    "X_train_res_df.columns = X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1063,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instanciamos el regresor de XGBoost\n",
    "\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "xg_reg = xgb.XGBClassifier(objective ='binary:logistic', \n",
    "                colsample_bytree = 0.8, learning_rate = 0.1,\n",
    "                max_depth = 5, n_estimators = 6,eval_metric = \"auc\", scale_pos_weight=5, min_child_weight=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1064,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=0.8, eval_metric='auc', gamma=0, learning_rate=0.1,\n",
       "       max_delta_step=0, max_depth=5, min_child_weight=10, missing=None,\n",
       "       n_estimators=6, n_jobs=1, nthread=None, objective='binary:logistic',\n",
       "       random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=5,\n",
       "       seed=None, silent=True, subsample=1)"
      ]
     },
     "execution_count": 1064,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Entrenamos\n",
    "\n",
    "xg_reg.fit(X_train_res_df ,y_train_res.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1065,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos\n",
    "\n",
    "preds = xg_reg.predict(X_test)\n",
    "proba = xg_reg.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1067,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:  0.928222279392848\n",
      "Test acuracy:  0.9173319598248777\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96      3670\n",
      "           1       0.28      0.33      0.30       213\n",
      "\n",
      "   micro avg       0.92      0.92      0.92      3883\n",
      "   macro avg       0.62      0.64      0.63      3883\n",
      "weighted avg       0.92      0.92      0.92      3883\n",
      "\n",
      "\n",
      "Precision Score:  0.28225806451612906\n",
      "Recall Score:  0.3286384976525822\n",
      "F1 Score:  0.3036876355748373\n",
      "Cohen Kappa Score:  0.2600143076379633\n",
      "ROC auc score:  0.8628461961597013\n",
      "Confusion matrix: \n",
      "[[3492  178]\n",
      " [ 143   70]]\n"
     ]
    }
   ],
   "source": [
    "# Pruebo todas las metricas.\n",
    "# accuracy_score, roc_auc_score, mean_squared_error, confusion_matrix,\n",
    "# f1_score,precision_score,recall_score,classification_report,cohen_kappa_score\n",
    "\n",
    "trainAccuracy = accuracy_score(y_train_res, xg_reg.predict(X_train_res_df))\n",
    "testAccuracy = accuracy_score(y_test, preds)\n",
    "\n",
    "meanSquaredError = mean_squared_error(y_test, preds)\n",
    "classificationReport = classification_report(y_test, preds)\n",
    "precisionScore = precision_score(y_test, preds)\n",
    "recallScore = recall_score(y_test, preds)\n",
    "f1Score = f1_score(y_test, preds)\n",
    "cohenKappaScore = cohen_kappa_score(y_test, preds)\n",
    "areaDebajoDeCurva = roc_auc_score(y_test, proba)\n",
    "matrizDeConfusion = confusion_matrix(y_test, preds)\n",
    "\n",
    "print(\"Train accuracy: \", trainAccuracy)\n",
    "print(\"Test acuracy: \", testAccuracy)\n",
    "print()\n",
    "print(\"Classification Report:\")\n",
    "print(classificationReport)\n",
    "print()\n",
    "print(\"Precision Score: \",precisionScore)\n",
    "print(\"Recall Score: \",recallScore)\n",
    "print(\"F1 Score: \",f1Score)\n",
    "print(\"Cohen Kappa Score: \",cohenKappaScore)\n",
    "print(\"ROC auc score: \", areaDebajoDeCurva)\n",
    "print(\"Confusion matrix: \")\n",
    "print(matrizDeConfusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " OCHENTA Y SEIS DOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -- Otros features que tal vez sirvan --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distancia en dias de 1er y ultimo dia de entrada al sitio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>distan_dias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008ed71</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091926</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00091a7a</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000ba417</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000c79fe</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  distan_dias\n",
       "0  0008ed71            0\n",
       "1  00091926           27\n",
       "2  00091a7a            0\n",
       "3  000ba417            9\n",
       "4  000c79fe            0"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamp_df = df[[\"person\", \"timestamp\"]]\n",
    "ultimo_dia = timestamp_df.groupby(\"person\")[\"timestamp\"].max().rename(\"ultimo\").reset_index()\n",
    "primer_dia = timestamp_df.groupby(\"person\")[\"timestamp\"].min().rename(\"primer\").reset_index()\n",
    "distancia_dias = pd.merge(primer_dia, ultimo_dia, on=\"person\", how=\"inner\")\n",
    "distancia_dias[\"distan_dias\"] = (distancia_dias[\"ultimo\"] - distancia_dias[\"primer\"]).dt.days\n",
    "distancia_dias = distancia_dias[[\"person\", \"distan_dias\"]]\n",
    "distancia_dias.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Merge\n",
    "#df_con_mes_5\n",
    "df_con_distancias = pd.merge(distancia_dias, df_con_top_semanas, on=\"person\", how=\"inner\") \n",
    "df_train = pd.merge(df_con_distancias, labels, on=\"person\", how=\"inner\")\\\n",
    "            .drop(columns = ['person','viewed product', 'visited site', 'staticpage', 'lead', 'viewed product',\\\n",
    "                             'visited site', 'staticpage mes 5', 'lead mes 5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 597,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veo cuantas personas a predecir pierdo\n",
    "distancia_dias_predecir = pd.merge(distancia_dias, df_persons, on=\"person\", how=\"inner\")\n",
    "distancia_dias_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cantidad de modelos distintos vistos por cada usuario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 545,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>modelos_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008ed71</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091926</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00091a7a</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000ba417</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000c79fe</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  modelos_dist\n",
       "0  0008ed71             3\n",
       "1  00091926            36\n",
       "2  00091a7a             3\n",
       "3  000ba417            26\n",
       "4  000c79fe             1"
      ]
     },
     "execution_count": 545,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelos_df = df[[\"person\", \"model\"]]\n",
    "cant_modelos = modelos_df.groupby(\"person\")[\"model\"].nunique().rename(\"modelos_dist\").reset_index()\n",
    "cant_modelos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge \n",
    "#df_con_distancias\n",
    "df_con_modelos = pd.merge(df_con_top_semanas, cant_modelos, on=\"person\", how=\"inner\") \n",
    "df_train = pd.merge(df_con_modelos, labels, on=\"person\", how=\"inner\")\\\n",
    "            .drop(columns = ['person','viewed product', 'visited site', 'staticpage', 'lead', 'viewed product',\\\n",
    "                             'visited site', 'staticpage mes 5', 'lead mes 5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 610,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veo cuantas personas a predecir pierdo\n",
    "cant_modelos_predecir = pd.merge(cant_modelos, df_persons, on=\"person\", how=\"inner\")\n",
    "cant_modelos_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cantidad de días distintos de entrada al sitio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seba\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>cant_dias_dist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0008ed71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00091926</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00091a7a</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000ba417</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000c79fe</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  cant_dias_dist\n",
       "0  0008ed71               1\n",
       "1  00091926              22\n",
       "2  00091a7a               1\n",
       "3  000ba417               3\n",
       "4  000c79fe               1"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dias = df[[\"person\", \"timestamp\"]]\n",
    "df_dias[\"day_of_year\"] = df_dias[\"timestamp\"].dt.dayofyear\n",
    "cant_dias_dist = df_dias.groupby(\"person\")[\"day_of_year\"].nunique().rename(\"cant_dias_dist\").reset_index()\n",
    "cant_dias_dist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 637,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([  'ad campaign hit mes 5',     'brand listing mes 5',\n",
       "                'checkout mes 5',        'conversion mes 5',\n",
       "         'generic listing mes 5', 'search engine hit mes 5',\n",
       "       'searched products mes 5',    'viewed product mes 5',\n",
       "            'visited site mes 5',         'ad campaign hit',\n",
       "                 'brand listing',                'checkout',\n",
       "                    'conversion',         'generic listing',\n",
       "             'search engine hit',       'searched products',\n",
       "                         'dia_1',                   'dia_2',\n",
       "                         'dia_3',                   'dia_4',\n",
       "                         'dia_5',                   'dia_6',\n",
       "                         'dia_7',                   'dia_8',\n",
       "                         'dia_9',                  'dia_10',\n",
       "                        'dia_11',                  'dia_12',\n",
       "                        'dia_13',                  'dia_14',\n",
       "                        'dia_15',                  'dia_16',\n",
       "                        'dia_17',                  'dia_18',\n",
       "                        'dia_19',                  'dia_20',\n",
       "                        'dia_21',                  'dia_22',\n",
       "                        'dia_23',                  'dia_24',\n",
       "                        'dia_25',                  'dia_26',\n",
       "                        'dia_27',                  'dia_28',\n",
       "                        'dia_29',                  'dia_30',\n",
       "                        'dia_31',                        21,\n",
       "                              20,                        22,\n",
       "                              19,                        18,\n",
       "                              17,                        16,\n",
       "                              15,                        14,\n",
       "                              13,          'cant_dias_dist',\n",
       "                         'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 637,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge df_con_modelos\n",
    "\n",
    "df_con_dias_dist = pd.merge(df_con_top_semanas, cant_dias_dist, on=\"person\", how=\"inner\") \n",
    "df_train = pd.merge(df_con_dias_dist, labels, on=\"person\", how=\"inner\")\\\n",
    "            .drop(columns = ['person','viewed product', 'visited site', 'staticpage', 'lead', 'viewed product',\\\n",
    "                             'visited site', 'staticpage mes 5', 'lead mes 5'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 619,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veo cuantas personas a predecir pierdo\n",
    "cant_dias_dist_predecir = pd.merge(cant_dias_dist, df_persons, on=\"person\", how=\"inner\")\n",
    "cant_dias_dist_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entro como 'new' en el mes 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person</th>\n",
       "      <th>nuevo_mes_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c0f2beb1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9ff9d5d2</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ae9e5fa3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bbbe368d</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0b7a3edd</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     person  nuevo_mes_5\n",
       "0  c0f2beb1          1.0\n",
       "1  9ff9d5d2          1.0\n",
       "2  ae9e5fa3          1.0\n",
       "3  bbbe368d          1.0\n",
       "4  0b7a3edd          1.0"
      ]
     },
     "execution_count": 653,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mes_5 = df[[\"person\", \"month\", \"new_vs_returning\"]].loc[df[\"month\"] == 5]\n",
    "df_mes_5[\"nuevo_mes_5\"] = (df_mes_5[\"new_vs_returning\"] == \"New\") * 1\n",
    "df_mew_5 = df_mes_5[[\"person\", \"nuevo_mes_5\"]]\n",
    "df_mew_5 = df_mew_5.sort_values(\"nuevo_mes_5\", ascending=False)\n",
    "df_mew_5 = df_mew_5.drop_duplicates(subset=['person'], keep='first')\n",
    "df_mew_5 = pd.merge(df_mew_5, todas_las_personas, on=\"person\", how=\"right\").fillna(0)\n",
    "df_mew_5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 654,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Veo cuantas personas a predecir pierdo\n",
    "df_mew_5_predecir = pd.merge(df_mew_5, df_persons, on=\"person\", how=\"inner\")\n",
    "df_mew_5_predecir[\"person\"].count() - df_persons[\"person\"].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    14789\n",
       "0.0     4625\n",
       "Name: nuevo_mes_5, dtype: int64"
      ]
     },
     "execution_count": 655,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge\n",
    "\n",
    "df_con_new_mes5 = pd.merge(df_con_top_semanas, df_mew_5, on=\"person\", how=\"inner\") \n",
    "df_train = pd.merge(df_con_new_mes5, labels, on=\"person\", how=\"inner\")\\\n",
    "            .drop(columns = ['person','viewed product', 'visited site', 'staticpage', 'lead', 'viewed product',\\\n",
    "                             'visited site', 'staticpage mes 5', 'lead mes 5'])\n",
    "df_train['nuevo_mes_5'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
